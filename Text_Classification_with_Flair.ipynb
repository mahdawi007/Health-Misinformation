{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification with Flair.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPN3Aw9ER9l4bOn5LFuPAhh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl4KG92JNQUg"
      },
      "source": [
        "#Text Classification With Flair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9li6VUPOLFEG"
      },
      "source": [
        "##Reliability Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "W2CNZ-brjbXr",
        "outputId": "477e25cf-f668-44ea-dafd-015d83f3844f"
      },
      "source": [
        "import pandas as pd\n",
        "Ann_full= pd.read_csv('trainDF_more2.csv',header=0)\n",
        "\n",
        "Ann_full.drop_duplicates(subset =\"text2\",keep = False, inplace = True)\n",
        "Ann_full"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sample_annotated</th>\n",
              "      <th>labelnew</th>\n",
              "      <th>scory</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Put it towards my heart transplant so I can see my kids grow older</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>Put it towards my heart transplant so I can see my kids grow older</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I havent had a transplant yet. Just waiting, 5 years and counting, but thankfully I am stable. My fir</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>I havent had a transplant yet. Just waiting, 5 years and counting, but thankfully I am stable. My fir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"I have to say it was the right thing to go through with Henry's open heart surgery because even\" Steven Crosio</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>\"I have to say it was the right thing to go through with Henry's open heart surgery because even\" Steven Crosio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>All those turncoats? Did they have heart transplant? (Hriday Parivartan)</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>All those turncoats? Did they have heart transplant? (Hriday Parivartan)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In a 70-page document, the panel stated that Maradona, who succumbed to a heart attack on November 25 at the age of</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>In a 70-page document, the panel stated that Maradona, who succumbed to a heart attack on November 25 at the age of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19113</th>\n",
              "      <td>take your prescribed medicines every day, even when you’re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>take your prescribed medicines every day, even when you’re feeling great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19114</th>\n",
              "      <td>you should keep your blood pressure under control – that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999976</td>\n",
              "      <td>you should keep your blood pressure under control – that is less than 130/80 mmHg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19115</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999959</td>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19116</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19117</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18704 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                       text  ...                                                                                                                 text2\n",
              "2                                                        Put it towards my heart transplant so I can see my kids grow older  ...                                                    Put it towards my heart transplant so I can see my kids grow older\n",
              "4                    I havent had a transplant yet. Just waiting, 5 years and counting, but thankfully I am stable. My fir   ...                I havent had a transplant yet. Just waiting, 5 years and counting, but thankfully I am stable. My fir \n",
              "5          \"I have to say it was the right thing to go through with Henry's open heart surgery because even\" Steven Crosio   ...      \"I have to say it was the right thing to go through with Henry's open heart surgery because even\" Steven Crosio \n",
              "6                                                  All those turncoats? Did they have heart transplant? (Hriday Parivartan)  ...                                              All those turncoats? Did they have heart transplant? (Hriday Parivartan)\n",
              "7      In a 70-page document, the panel stated that Maradona, who succumbed to a heart attack on November 25 at the age of   ...  In a 70-page document, the panel stated that Maradona, who succumbed to a heart attack on November 25 at the age of \n",
              "...                                                                                                                     ...  ...                                                                                                                   ...\n",
              "19113                                              take your prescribed medicines every day, even when you’re feeling great  ...                                              take your prescribed medicines every day, even when you’re feeling great\n",
              "19114                                     you should keep your blood pressure under control – that is less than 130/80 mmHg  ...                                     you should keep your blood pressure under control – that is less than 130/80 mmHg\n",
              "19115                                                           effects of alcohol consumption on heart health are variable  ...                                                           effects of alcohol consumption on heart health are variable\n",
              "19116                               littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  ...                               littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent\n",
              "19117                 alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  ...                 alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure\n",
              "\n",
              "[18704 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo034mq1j5l8",
        "outputId": "3709295b-1970-4460-e887-c8ced2d51ee5"
      },
      "source": [
        "Ann_full['labelnew'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TRUE    13975\n",
              "FAKE     4729\n",
              "Name: labelnew, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPMDj-4Hjecw",
        "outputId": "2fd73036-4476-4d64-b484-2891f30c15ef"
      },
      "source": [
        "count_class_0, count_class_1 = Ann_full.labelnew.value_counts()\n",
        "count_class_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4729"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhLCNyQEjoAX"
      },
      "source": [
        "df_class_0 = Ann_full[Ann_full['labelnew'] == 'TRUE']\n",
        "df_class_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "obGtNjUsiZGC",
        "outputId": "930baab7-1b82-4684-e990-bb1b53fe92ba"
      },
      "source": [
        "# Class count\n",
        "count_class_0, count_class_1 = Ann_full.labelnew.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_class_0 = Ann_full[Ann_full['labelnew'] == 'TRUE']\n",
        "df_class_1 = Ann_full[Ann_full['labelnew'] == 'FAKE']\n",
        "\n",
        "df_class_0_under = df_class_0.sample(count_class_1)\n",
        "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "\n",
        "print('Random under-sampling:')\n",
        "print(df_test_under.labelnew.value_counts())\n",
        "\n",
        "df_test_under.labelnew.value_counts().plot(kind='bar', title='Count (target)');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random under-sampling:\n",
            "FAKE    4729\n",
            "TRUE    4729\n",
            "Name: labelnew, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEApf0T6uhVE",
        "outputId": "0d4de329-27be-4b58-955c-a34290d4af43"
      },
      "source": [
        "from sklearn import model_selection\n",
        "train_x,test_x,train_y,test_y = model_selection.train_test_split(df_test_under,df_test_under,test_size=0.15,random_state=11)\n",
        "\n",
        "train_x.reset_index(drop=True,inplace=True)\n",
        "test_x.reset_index(drop=True,inplace=True)\n",
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8039, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUV4qhvruhVG"
      },
      "source": [
        "train_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIt4k4SouhVI",
        "outputId": "d41b223c-a641-483d-81dd-98d09799dc77"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import SentenceDataset\n",
        "from flair.data import Sentence\n",
        "\n",
        "train_labeled=[]\n",
        "for i in range(len(train_x['text2'])):\n",
        "    sentence = Sentence(train_x['text2'][i]).add_label('reliability', train_x['labelnew'][i])\n",
        "    train_labeled.append(sentence)\n",
        "\n",
        "test_labeled=[]\n",
        "for i in range(len(test_x['text2'])):\n",
        "    sentence = Sentence(test_x['text2'][i]).add_label('reliability', test_x['labelnew'][i])\n",
        "    test_labeled.append(sentence)\n",
        "\n",
        "\n",
        "train = SentenceDataset(train_labeled)\n",
        "test = SentenceDataset(test_labeled)\n",
        "\n",
        "# make a corpus with train and test split\n",
        "corpus = Corpus(train=train, test=test)\n",
        "\n",
        "print(len(corpus.test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czpv16mXuhVJ",
        "outputId": "04d4ea5f-03d8-4d76-adaa-2ce1d57ccad8"
      },
      "source": [
        "print(len(corpus.test))\n",
        "print(len(corpus.train))\n",
        "\n",
        "print(len(test_labeled))\n",
        "print(len(train_labeled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1419\n",
            "7235\n",
            "1419\n",
            "8039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKf9MN1yuhVK",
        "outputId": "a8f90341-e8c5-44f3-8d98-bef617685daf"
      },
      "source": [
        "corpus.train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence: \"Forty-eight ( 14 %) subjects were identified as ideal risk , 130 ( 38 %) as low risk , and 168 ( 49 %) as moderate / high risk .\"   [− Tokens: 30  − Sentence-Labels: {'reliability': [TRUE (1.0)]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR9UdF2mBjDM"
      },
      "source": [
        "https://huggingface.co/monologg/biobert_v1.1_pubmed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdSNMU6_GfYO"
      },
      "source": [
        "https://huggingface.co/dmis-lab/biobert-v1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1MuksHo5xhJ"
      },
      "source": [
        "from flair.data import Corpus\n",
        "#from flair.datasets import TREC_6\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUwg0aLsyltV",
        "outputId": "3cdd4db5-8882-433f-d482-9c45d275a05e"
      },
      "source": [
        "from torch.optim.adam import Adam\n",
        "\n",
        "from flair.data import Corpus\n",
        "#from flair.datasets import TREC_6\n",
        "from flair.embeddings import TransformerDocumentEmbeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 2. create the label dictionary\n",
        "label_dict = corpus.make_label_dictionary()\n",
        "\n",
        "document_embeddings = TransformerDocumentEmbeddings('dmis-lab/biobert-v1.1', fine_tune=True)\n",
        "\n",
        "# 4. create the text classifier\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "\n",
        "# 5. initialize the text classifier trainer with Adam optimizer\n",
        "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
        "\n",
        "# 6. start the training\n",
        "trainer.train('result/misinformation3/',\n",
        "              learning_rate=3e-5, # use very small learning rate\n",
        "              mini_batch_size=32,\n",
        "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
        "              max_epochs=5, # terminate after 5 epochs\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-06 20:49:24,168 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8654/8654 [00:00<00:00, 51239.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-06 20:49:24,343 [b'TRUE', b'FAKE']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-06 20:49:28,986 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:28,989 Model: \"TextClassifier(\n",
            "  (document_embeddings): TransformerDocumentEmbeddings(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-07-06 20:49:28,991 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:28,993 Corpus: \"Corpus: 7235 train + 804 dev + 1419 test sentences\"\n",
            "2021-07-06 20:49:28,995 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:28,997 Parameters:\n",
            "2021-07-06 20:49:28,998  - learning_rate: \"3e-05\"\n",
            "2021-07-06 20:49:29,001  - mini_batch_size: \"32\"\n",
            "2021-07-06 20:49:29,002  - patience: \"3\"\n",
            "2021-07-06 20:49:29,003  - anneal_factor: \"0.5\"\n",
            "2021-07-06 20:49:29,004  - max_epochs: \"5\"\n",
            "2021-07-06 20:49:29,006  - shuffle: \"True\"\n",
            "2021-07-06 20:49:29,007  - train_with_dev: \"False\"\n",
            "2021-07-06 20:49:29,008  - batch_growth_annealing: \"False\"\n",
            "2021-07-06 20:49:29,011 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:29,013 Model training base path: \"result/misinformation3\"\n",
            "2021-07-06 20:49:29,014 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:29,015 Device: cuda:0\n",
            "2021-07-06 20:49:29,018 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:29,019 Embeddings storage mode: cpu\n",
            "2021-07-06 20:49:29,026 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:49:52,444 epoch 1 - iter 22/227 - loss 0.24132828 - samples/sec: 30.07 - lr: 0.000030\n",
            "2021-07-06 20:50:15,714 epoch 1 - iter 44/227 - loss 0.15191873 - samples/sec: 30.26 - lr: 0.000030\n",
            "2021-07-06 20:50:38,807 epoch 1 - iter 66/227 - loss 0.13425866 - samples/sec: 30.49 - lr: 0.000030\n",
            "2021-07-06 20:51:01,863 epoch 1 - iter 88/227 - loss 0.10725185 - samples/sec: 30.54 - lr: 0.000030\n",
            "2021-07-06 20:51:25,904 epoch 1 - iter 110/227 - loss 0.11527731 - samples/sec: 29.29 - lr: 0.000030\n",
            "2021-07-06 20:51:48,467 epoch 1 - iter 132/227 - loss 0.10796391 - samples/sec: 31.20 - lr: 0.000030\n",
            "2021-07-06 20:52:11,064 epoch 1 - iter 154/227 - loss 0.10422377 - samples/sec: 31.16 - lr: 0.000030\n",
            "2021-07-06 20:52:33,666 epoch 1 - iter 176/227 - loss 0.10071636 - samples/sec: 31.15 - lr: 0.000030\n",
            "2021-07-06 20:52:55,917 epoch 1 - iter 198/227 - loss 0.10422674 - samples/sec: 31.64 - lr: 0.000030\n",
            "2021-07-06 20:53:18,244 epoch 1 - iter 220/227 - loss 0.10496989 - samples/sec: 31.53 - lr: 0.000030\n",
            "2021-07-06 20:53:24,459 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:53:24,461 EPOCH 1 done: loss 0.1022 - lr 0.0000300\n",
            "2021-07-06 20:53:34,592 DEV : loss 0.09946069121360779 - score 0.9689\n",
            "2021-07-06 20:53:34,615 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-06 20:53:35,898 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:54:00,368 epoch 2 - iter 22/227 - loss 0.06831137 - samples/sec: 28.78 - lr: 0.000030\n",
            "2021-07-06 20:54:24,770 epoch 2 - iter 44/227 - loss 0.05069557 - samples/sec: 28.85 - lr: 0.000030\n",
            "2021-07-06 20:54:49,380 epoch 2 - iter 66/227 - loss 0.03610132 - samples/sec: 28.61 - lr: 0.000030\n",
            "2021-07-06 20:55:14,426 epoch 2 - iter 88/227 - loss 0.02837998 - samples/sec: 28.11 - lr: 0.000030\n",
            "2021-07-06 20:55:38,819 epoch 2 - iter 110/227 - loss 0.03825851 - samples/sec: 28.86 - lr: 0.000030\n",
            "2021-07-06 20:56:03,389 epoch 2 - iter 132/227 - loss 0.03286502 - samples/sec: 28.66 - lr: 0.000030\n",
            "2021-07-06 20:56:27,684 epoch 2 - iter 154/227 - loss 0.03431760 - samples/sec: 28.98 - lr: 0.000030\n",
            "2021-07-06 20:56:51,746 epoch 2 - iter 176/227 - loss 0.03424564 - samples/sec: 29.26 - lr: 0.000030\n",
            "2021-07-06 20:57:15,945 epoch 2 - iter 198/227 - loss 0.03061333 - samples/sec: 29.10 - lr: 0.000030\n",
            "2021-07-06 20:57:40,248 epoch 2 - iter 220/227 - loss 0.02779205 - samples/sec: 28.97 - lr: 0.000030\n",
            "2021-07-06 20:57:46,978 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:57:46,979 EPOCH 2 done: loss 0.0270 - lr 0.0000300\n",
            "2021-07-06 20:57:58,526 DEV : loss 0.13370302319526672 - score 0.9664\n",
            "2021-07-06 20:57:58,549 BAD EPOCHS (no improvement): 1\n",
            "2021-07-06 20:57:58,551 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 20:58:22,671 epoch 3 - iter 22/227 - loss 0.00033873 - samples/sec: 29.19 - lr: 0.000030\n",
            "2021-07-06 20:58:47,112 epoch 3 - iter 44/227 - loss 0.00045516 - samples/sec: 28.81 - lr: 0.000030\n",
            "2021-07-06 20:59:11,466 epoch 3 - iter 66/227 - loss 0.00119354 - samples/sec: 28.91 - lr: 0.000030\n",
            "2021-07-06 20:59:34,577 epoch 3 - iter 88/227 - loss 0.00112521 - samples/sec: 30.47 - lr: 0.000030\n",
            "2021-07-06 20:59:58,712 epoch 3 - iter 110/227 - loss 0.00090865 - samples/sec: 29.17 - lr: 0.000030\n",
            "2021-07-06 21:00:22,700 epoch 3 - iter 132/227 - loss 0.00584012 - samples/sec: 29.35 - lr: 0.000030\n",
            "2021-07-06 21:00:45,729 epoch 3 - iter 154/227 - loss 0.01624865 - samples/sec: 30.57 - lr: 0.000030\n",
            "2021-07-06 21:01:09,381 epoch 3 - iter 176/227 - loss 0.01673709 - samples/sec: 29.77 - lr: 0.000030\n",
            "2021-07-06 21:01:33,808 epoch 3 - iter 198/227 - loss 0.01490337 - samples/sec: 28.82 - lr: 0.000030\n",
            "2021-07-06 21:01:58,084 epoch 3 - iter 220/227 - loss 0.02055731 - samples/sec: 29.00 - lr: 0.000030\n",
            "2021-07-06 21:02:04,848 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 21:02:04,849 EPOCH 3 done: loss 0.0199 - lr 0.0000300\n",
            "2021-07-06 21:02:16,167 DEV : loss 0.1329623907804489 - score 0.9726\n",
            "2021-07-06 21:02:16,189 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-06 21:02:17,930 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 21:02:42,159 epoch 4 - iter 22/227 - loss 0.00001061 - samples/sec: 29.06 - lr: 0.000030\n",
            "2021-07-06 21:03:05,634 epoch 4 - iter 44/227 - loss 0.00006517 - samples/sec: 29.99 - lr: 0.000030\n",
            "2021-07-06 21:03:29,825 epoch 4 - iter 66/227 - loss 0.00013240 - samples/sec: 29.11 - lr: 0.000030\n",
            "2021-07-06 21:03:53,301 epoch 4 - iter 88/227 - loss 0.00011076 - samples/sec: 29.99 - lr: 0.000030\n",
            "2021-07-06 21:04:17,189 epoch 4 - iter 110/227 - loss 0.00354423 - samples/sec: 29.47 - lr: 0.000030\n",
            "2021-07-06 21:04:40,729 epoch 4 - iter 132/227 - loss 0.00295469 - samples/sec: 29.91 - lr: 0.000030\n",
            "2021-07-06 21:05:04,076 epoch 4 - iter 154/227 - loss 0.00258952 - samples/sec: 30.16 - lr: 0.000030\n",
            "2021-07-06 21:05:28,495 epoch 4 - iter 176/227 - loss 0.00226654 - samples/sec: 28.83 - lr: 0.000030\n",
            "2021-07-06 21:05:53,744 epoch 4 - iter 198/227 - loss 0.00202013 - samples/sec: 27.89 - lr: 0.000030\n",
            "2021-07-06 21:06:18,986 epoch 4 - iter 220/227 - loss 0.00183014 - samples/sec: 27.89 - lr: 0.000030\n",
            "2021-07-06 21:06:25,859 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 21:06:25,860 EPOCH 4 done: loss 0.0018 - lr 0.0000300\n",
            "2021-07-06 21:06:37,451 DEV : loss 0.21395991742610931 - score 0.9677\n",
            "2021-07-06 21:06:37,473 BAD EPOCHS (no improvement): 1\n",
            "2021-07-06 21:06:37,475 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 21:07:01,768 epoch 5 - iter 22/227 - loss 0.00002869 - samples/sec: 28.99 - lr: 0.000030\n",
            "2021-07-06 21:07:25,706 epoch 5 - iter 44/227 - loss 0.00001548 - samples/sec: 29.41 - lr: 0.000030\n",
            "2021-07-06 21:07:50,636 epoch 5 - iter 66/227 - loss 0.00001093 - samples/sec: 28.24 - lr: 0.000030\n",
            "2021-07-06 21:08:15,773 epoch 5 - iter 88/227 - loss 0.00001236 - samples/sec: 28.01 - lr: 0.000030\n",
            "2021-07-06 21:08:39,144 epoch 5 - iter 110/227 - loss 0.00001221 - samples/sec: 30.13 - lr: 0.000030\n",
            "2021-07-06 21:09:02,922 epoch 5 - iter 132/227 - loss 0.00174371 - samples/sec: 29.61 - lr: 0.000030\n",
            "2021-07-06 21:09:27,355 epoch 5 - iter 154/227 - loss 0.00149504 - samples/sec: 28.82 - lr: 0.000030\n",
            "2021-07-06 21:09:51,715 epoch 5 - iter 176/227 - loss 0.00130846 - samples/sec: 28.90 - lr: 0.000030\n",
            "2021-07-06 21:10:16,248 epoch 5 - iter 198/227 - loss 0.00116332 - samples/sec: 28.70 - lr: 0.000030\n",
            "2021-07-06 21:10:40,440 epoch 5 - iter 220/227 - loss 0.00104742 - samples/sec: 29.10 - lr: 0.000030\n",
            "2021-07-06 21:10:47,125 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 21:10:47,127 EPOCH 5 done: loss 0.0010 - lr 0.0000300\n",
            "2021-07-06 21:10:58,059 DEV : loss 0.21572962403297424 - score 0.9714\n",
            "2021-07-06 21:10:58,082 BAD EPOCHS (no improvement): 2\n",
            "2021-07-06 21:10:59,433 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-06 21:10:59,434 Testing using best model ...\n",
            "2021-07-06 21:10:59,437 loading file result/misinformation3/best-model.pt\n",
            "2021-07-06 21:11:21,228 \t0.9796\n",
            "2021-07-06 21:11:21,230 \n",
            "Results:\n",
            "- F-score (micro) 0.9796\n",
            "- F-score (macro) 0.9796\n",
            "- Accuracy 0.9796\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        TRUE     0.9844    0.9748    0.9796       714\n",
            "        FAKE     0.9747    0.9844    0.9795       705\n",
            "\n",
            "   micro avg     0.9796    0.9796    0.9796      1419\n",
            "   macro avg     0.9796    0.9796    0.9796      1419\n",
            "weighted avg     0.9796    0.9796    0.9796      1419\n",
            " samples avg     0.9796    0.9796    0.9796      1419\n",
            "\n",
            "2021-07-06 21:11:21,231 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.09946069121360779,\n",
              "  0.13370302319526672,\n",
              "  0.1329623907804489,\n",
              "  0.21395991742610931,\n",
              "  0.21572962403297424],\n",
              " 'dev_score_history': [0.9689, 0.9664, 0.9726, 0.9677, 0.9714],\n",
              " 'test_score': 0.9796,\n",
              " 'train_loss_history': [0.10224316799954848,\n",
              "  0.02695970654047671,\n",
              "  0.019928589739106703,\n",
              "  0.0017740810055980668,\n",
              "  0.001015372949048831]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lQb15zIMrl2"
      },
      "source": [
        "##Category Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwM7wQoZiQrr"
      },
      "source": [
        "**Build the corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URg68cZJiUZf",
        "outputId": "9b22533b-b909-454c-c3be-27b4075fd9e0"
      },
      "source": [
        "from sklearn import model_selection\n",
        "train_x,test_x,train_y,test_y = model_selection.train_test_split(result_all,result_all,test_size=0.20,random_state=11)\n",
        "\n",
        "train_x.reset_index(drop=True,inplace=True)\n",
        "test_x.reset_index(drop=True,inplace=True)\n",
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13790, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJYWShVniUZi",
        "outputId": "7a4cd2ed-09e0-4d12-b4aa-0b70cce639a7"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import SentenceDataset\n",
        "from flair.data import Sentence\n",
        "\n",
        "train_labeled=[]\n",
        "for i in range(len(train_x['text2'])):\n",
        "    sentence = Sentence(train_x['text2'][i]).add_label('type', train_x['source'][i]) #-->change label to source if you want all labels\n",
        "    train_labeled.append(sentence)\n",
        "\n",
        "test_labeled=[]\n",
        "for i in range(len(test_x['text2'])):\n",
        "    sentence = Sentence(test_x['text2'][i]).add_label('type', test_x['source'][i]) #-->change label to source if you want all labels\n",
        "    test_labeled.append(sentence)\n",
        "\n",
        "\n",
        "train = SentenceDataset(train_labeled)\n",
        "test = SentenceDataset(test_labeled)\n",
        "\n",
        "# make a corpus with train and test split\n",
        "corpus = Corpus(train=train, test=test)\n",
        "\n",
        "print(len(corpus.test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWWjP04OiUZm",
        "outputId": "1f084a24-e7e3-4575-cfc5-57f4532dd625"
      },
      "source": [
        "print(len(corpus.test))\n",
        "print(len(corpus.train))\n",
        "\n",
        "print(len(test_labeled))\n",
        "print(len(train_labeled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3448\n",
            "12411\n",
            "3448\n",
            "13790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vccR90sRiUZn",
        "outputId": "e5e93572-00a9-47b0-9dc6-c0f1195c92ba"
      },
      "source": [
        "corpus.train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence: \"To mark the 1 year anniversary of her life-saving heart transplant , Hayley is taking to the skydives and jumping 13\"   [− Tokens: 21  − Sentence-Labels: {'type': [Heart transplant (1.0)]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SevRnVeYls_J"
      },
      "source": [
        "from flair.data import Corpus\n",
        "#from flair.datasets import TREC_6\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qyCnVhLljCR",
        "outputId": "bf490420-c2b9-4877-fd80-93732a1734d0"
      },
      "source": [
        "# 1. get the corpus -->already loaded\n",
        "#corpus: Corpus = TREC_6()\n",
        "\n",
        "# 2. create the label dictionary\n",
        "label_dict = corpus.make_label_dictionary()\n",
        "\n",
        "# 3. make a list of word embeddings\n",
        "word_embeddings = [WordEmbeddings('pubmed')]\n",
        "\n",
        "# 4. initialize document embedding by passing list of word embeddings\n",
        "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)\n",
        "\n",
        "# 5. create the text classifier\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "\n",
        "# 6. initialize the text classifier trainer\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "\n",
        "# 7. start the training\n",
        "trainer.train('result2/type_disease_trans_more2',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              anneal_factor=0.5,\n",
        "              patience=5,\n",
        "              max_epochs=150)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:53:13,407 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14796/14796 [00:00<00:00, 37691.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:53:13,805 [b'heart disease treatment', b'heart attack symptoms', b'Coronary artery disease treatment', b'Coronary artery disease', b'heart disease causes', b'heart disease symptoms', b'heart disease', b'heart attack', b'Coronary artery disease symptoms', b'heart attack causes', b'heart attack treatment']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:53:41,566 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:41,568 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('pubmed')\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=200, out_features=200, bias=True)\n",
            "    (rnn): GRU(200, 256, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=256, out_features=11, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-07-01 23:53:41,569 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:41,570 Corpus: \"Corpus: 11579 train + 1287 dev + 3217 test sentences\"\n",
            "2021-07-01 23:53:41,571 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:41,573 Parameters:\n",
            "2021-07-01 23:53:41,574  - learning_rate: \"0.1\"\n",
            "2021-07-01 23:53:41,576  - mini_batch_size: \"32\"\n",
            "2021-07-01 23:53:41,578  - patience: \"5\"\n",
            "2021-07-01 23:53:41,580  - anneal_factor: \"0.5\"\n",
            "2021-07-01 23:53:41,582  - max_epochs: \"150\"\n",
            "2021-07-01 23:53:41,583  - shuffle: \"True\"\n",
            "2021-07-01 23:53:41,584  - train_with_dev: \"False\"\n",
            "2021-07-01 23:53:41,586  - batch_growth_annealing: \"False\"\n",
            "2021-07-01 23:53:41,587 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:41,588 Model training base path: \"result2/type_disease_trans_more2\"\n",
            "2021-07-01 23:53:41,590 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:41,591 Device: cuda:0\n",
            "2021-07-01 23:53:41,594 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:41,596 Embeddings storage mode: cpu\n",
            "2021-07-01 23:53:41,600 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:53:43,776 epoch 1 - iter 36/362 - loss 2.16661402 - samples/sec: 530.44 - lr: 0.100000\n",
            "2021-07-01 23:53:45,766 epoch 1 - iter 72/362 - loss 2.12395211 - samples/sec: 579.70 - lr: 0.100000\n",
            "2021-07-01 23:53:47,729 epoch 1 - iter 108/362 - loss 2.11038433 - samples/sec: 587.87 - lr: 0.100000\n",
            "2021-07-01 23:53:49,717 epoch 1 - iter 144/362 - loss 2.10597632 - samples/sec: 580.34 - lr: 0.100000\n",
            "2021-07-01 23:53:51,603 epoch 1 - iter 180/362 - loss 2.09324122 - samples/sec: 611.79 - lr: 0.100000\n",
            "2021-07-01 23:53:53,528 epoch 1 - iter 216/362 - loss 2.08878324 - samples/sec: 599.31 - lr: 0.100000\n",
            "2021-07-01 23:53:55,450 epoch 1 - iter 252/362 - loss 2.07868801 - samples/sec: 600.30 - lr: 0.100000\n",
            "2021-07-01 23:53:57,405 epoch 1 - iter 288/362 - loss 2.06963322 - samples/sec: 590.22 - lr: 0.100000\n",
            "2021-07-01 23:54:00,985 epoch 1 - iter 324/362 - loss 2.06313197 - samples/sec: 322.03 - lr: 0.100000\n",
            "2021-07-01 23:54:02,917 epoch 1 - iter 360/362 - loss 2.05434648 - samples/sec: 597.28 - lr: 0.100000\n",
            "2021-07-01 23:54:03,035 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:54:03,036 EPOCH 1 done: loss 2.0536 - lr 0.1000000\n",
            "2021-07-01 23:54:05,244 DEV : loss 1.9398726224899292 - score 0.3232\n",
            "2021-07-01 23:54:05,332 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:54:14,893 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:54:16,275 epoch 2 - iter 36/362 - loss 1.96470221 - samples/sec: 837.07 - lr: 0.100000\n",
            "2021-07-01 23:54:17,621 epoch 2 - iter 72/362 - loss 1.96208016 - samples/sec: 858.54 - lr: 0.100000\n",
            "2021-07-01 23:54:18,998 epoch 2 - iter 108/362 - loss 1.93570405 - samples/sec: 838.66 - lr: 0.100000\n",
            "2021-07-01 23:54:20,374 epoch 2 - iter 144/362 - loss 1.94203544 - samples/sec: 839.45 - lr: 0.100000\n",
            "2021-07-01 23:54:21,741 epoch 2 - iter 180/362 - loss 1.94152824 - samples/sec: 844.71 - lr: 0.100000\n",
            "2021-07-01 23:54:23,105 epoch 2 - iter 216/362 - loss 1.93337796 - samples/sec: 846.73 - lr: 0.100000\n",
            "2021-07-01 23:54:24,478 epoch 2 - iter 252/362 - loss 1.92869774 - samples/sec: 841.53 - lr: 0.100000\n",
            "2021-07-01 23:54:25,844 epoch 2 - iter 288/362 - loss 1.92649135 - samples/sec: 845.47 - lr: 0.100000\n",
            "2021-07-01 23:54:27,192 epoch 2 - iter 324/362 - loss 1.92131793 - samples/sec: 856.34 - lr: 0.100000\n",
            "2021-07-01 23:54:28,639 epoch 2 - iter 360/362 - loss 1.91512392 - samples/sec: 798.55 - lr: 0.100000\n",
            "2021-07-01 23:54:28,715 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:54:28,716 EPOCH 2 done: loss 1.9145 - lr 0.1000000\n",
            "2021-07-01 23:54:30,141 DEV : loss 1.746006965637207 - score 0.4126\n",
            "2021-07-01 23:54:30,230 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:54:38,871 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:54:40,327 epoch 3 - iter 36/362 - loss 1.85328707 - samples/sec: 794.33 - lr: 0.100000\n",
            "2021-07-01 23:54:41,737 epoch 3 - iter 72/362 - loss 1.84729201 - samples/sec: 819.27 - lr: 0.100000\n",
            "2021-07-01 23:54:43,070 epoch 3 - iter 108/362 - loss 1.84422620 - samples/sec: 866.60 - lr: 0.100000\n",
            "2021-07-01 23:54:44,443 epoch 3 - iter 144/362 - loss 1.85433360 - samples/sec: 840.96 - lr: 0.100000\n",
            "2021-07-01 23:54:45,796 epoch 3 - iter 180/362 - loss 1.84930593 - samples/sec: 854.08 - lr: 0.100000\n",
            "2021-07-01 23:54:47,174 epoch 3 - iter 216/362 - loss 1.83651229 - samples/sec: 837.35 - lr: 0.100000\n",
            "2021-07-01 23:54:48,589 epoch 3 - iter 252/362 - loss 1.84027489 - samples/sec: 816.37 - lr: 0.100000\n",
            "2021-07-01 23:54:49,917 epoch 3 - iter 288/362 - loss 1.83179238 - samples/sec: 869.27 - lr: 0.100000\n",
            "2021-07-01 23:54:51,305 epoch 3 - iter 324/362 - loss 1.82367399 - samples/sec: 832.18 - lr: 0.100000\n",
            "2021-07-01 23:54:52,654 epoch 3 - iter 360/362 - loss 1.82394520 - samples/sec: 856.69 - lr: 0.100000\n",
            "2021-07-01 23:54:52,734 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:54:52,735 EPOCH 3 done: loss 1.8238 - lr 0.1000000\n",
            "2021-07-01 23:54:54,165 DEV : loss 1.6646513938903809 - score 0.4343\n",
            "2021-07-01 23:54:54,252 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:55:02,829 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:55:04,270 epoch 4 - iter 36/362 - loss 1.77825042 - samples/sec: 802.78 - lr: 0.100000\n",
            "2021-07-01 23:55:05,670 epoch 4 - iter 72/362 - loss 1.76479167 - samples/sec: 824.91 - lr: 0.100000\n",
            "2021-07-01 23:55:07,041 epoch 4 - iter 108/362 - loss 1.76058848 - samples/sec: 842.52 - lr: 0.100000\n",
            "2021-07-01 23:55:08,433 epoch 4 - iter 144/362 - loss 1.76889025 - samples/sec: 830.06 - lr: 0.100000\n",
            "2021-07-01 23:55:09,828 epoch 4 - iter 180/362 - loss 1.76610477 - samples/sec: 827.63 - lr: 0.100000\n",
            "2021-07-01 23:55:11,171 epoch 4 - iter 216/362 - loss 1.75614710 - samples/sec: 859.62 - lr: 0.100000\n",
            "2021-07-01 23:55:12,579 epoch 4 - iter 252/362 - loss 1.75304548 - samples/sec: 820.52 - lr: 0.100000\n",
            "2021-07-01 23:55:13,970 epoch 4 - iter 288/362 - loss 1.75303636 - samples/sec: 830.00 - lr: 0.100000\n",
            "2021-07-01 23:55:15,353 epoch 4 - iter 324/362 - loss 1.75291808 - samples/sec: 835.19 - lr: 0.100000\n",
            "2021-07-01 23:55:16,767 epoch 4 - iter 360/362 - loss 1.75279138 - samples/sec: 816.37 - lr: 0.100000\n",
            "2021-07-01 23:55:16,860 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:55:16,862 EPOCH 4 done: loss 1.7533 - lr 0.1000000\n",
            "2021-07-01 23:55:18,294 DEV : loss 2.0038962364196777 - score 0.3504\n",
            "2021-07-01 23:55:18,381 BAD EPOCHS (no improvement): 1\n",
            "2021-07-01 23:55:18,382 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:55:19,761 epoch 5 - iter 36/362 - loss 1.72812270 - samples/sec: 838.67 - lr: 0.100000\n",
            "2021-07-01 23:55:21,112 epoch 5 - iter 72/362 - loss 1.73982578 - samples/sec: 855.40 - lr: 0.100000\n",
            "2021-07-01 23:55:22,491 epoch 5 - iter 108/362 - loss 1.73042643 - samples/sec: 837.23 - lr: 0.100000\n",
            "2021-07-01 23:55:23,830 epoch 5 - iter 144/362 - loss 1.70998018 - samples/sec: 862.68 - lr: 0.100000\n",
            "2021-07-01 23:55:25,222 epoch 5 - iter 180/362 - loss 1.70660259 - samples/sec: 829.33 - lr: 0.100000\n",
            "2021-07-01 23:55:26,607 epoch 5 - iter 216/362 - loss 1.69780010 - samples/sec: 834.02 - lr: 0.100000\n",
            "2021-07-01 23:55:27,973 epoch 5 - iter 252/362 - loss 1.69657451 - samples/sec: 845.22 - lr: 0.100000\n",
            "2021-07-01 23:55:29,315 epoch 5 - iter 288/362 - loss 1.69435142 - samples/sec: 860.53 - lr: 0.100000\n",
            "2021-07-01 23:55:30,652 epoch 5 - iter 324/362 - loss 1.69120001 - samples/sec: 863.98 - lr: 0.100000\n",
            "2021-07-01 23:55:32,087 epoch 5 - iter 360/362 - loss 1.68520722 - samples/sec: 804.33 - lr: 0.100000\n",
            "2021-07-01 23:55:32,177 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:55:32,178 EPOCH 5 done: loss 1.6838 - lr 0.1000000\n",
            "2021-07-01 23:55:33,619 DEV : loss 1.5489041805267334 - score 0.4887\n",
            "2021-07-01 23:55:33,707 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:55:42,366 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:55:43,838 epoch 6 - iter 36/362 - loss 1.60715713 - samples/sec: 785.29 - lr: 0.100000\n",
            "2021-07-01 23:55:45,207 epoch 6 - iter 72/362 - loss 1.62501682 - samples/sec: 843.86 - lr: 0.100000\n",
            "2021-07-01 23:55:46,658 epoch 6 - iter 108/362 - loss 1.63522907 - samples/sec: 796.04 - lr: 0.100000\n",
            "2021-07-01 23:55:48,062 epoch 6 - iter 144/362 - loss 1.65044302 - samples/sec: 822.83 - lr: 0.100000\n",
            "2021-07-01 23:55:49,442 epoch 6 - iter 180/362 - loss 1.64272798 - samples/sec: 836.93 - lr: 0.100000\n",
            "2021-07-01 23:55:50,788 epoch 6 - iter 216/362 - loss 1.63571228 - samples/sec: 858.06 - lr: 0.100000\n",
            "2021-07-01 23:55:52,136 epoch 6 - iter 252/362 - loss 1.63559484 - samples/sec: 856.50 - lr: 0.100000\n",
            "2021-07-01 23:55:53,500 epoch 6 - iter 288/362 - loss 1.63198881 - samples/sec: 846.75 - lr: 0.100000\n",
            "2021-07-01 23:55:54,851 epoch 6 - iter 324/362 - loss 1.62088324 - samples/sec: 854.80 - lr: 0.100000\n",
            "2021-07-01 23:55:56,266 epoch 6 - iter 360/362 - loss 1.62298597 - samples/sec: 816.17 - lr: 0.100000\n",
            "2021-07-01 23:55:56,341 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:55:56,342 EPOCH 6 done: loss 1.6232 - lr 0.1000000\n",
            "2021-07-01 23:55:57,801 DEV : loss 1.483956217765808 - score 0.5035\n",
            "2021-07-01 23:55:57,888 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:56:06,975 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:56:08,359 epoch 7 - iter 36/362 - loss 1.56507960 - samples/sec: 835.70 - lr: 0.100000\n",
            "2021-07-01 23:56:09,763 epoch 7 - iter 72/362 - loss 1.55547041 - samples/sec: 822.81 - lr: 0.100000\n",
            "2021-07-01 23:56:11,244 epoch 7 - iter 108/362 - loss 1.54685262 - samples/sec: 779.94 - lr: 0.100000\n",
            "2021-07-01 23:56:12,627 epoch 7 - iter 144/362 - loss 1.54637832 - samples/sec: 834.92 - lr: 0.100000\n",
            "2021-07-01 23:56:13,989 epoch 7 - iter 180/362 - loss 1.54257908 - samples/sec: 848.15 - lr: 0.100000\n",
            "2021-07-01 23:56:15,356 epoch 7 - iter 216/362 - loss 1.54581182 - samples/sec: 844.60 - lr: 0.100000\n",
            "2021-07-01 23:56:16,756 epoch 7 - iter 252/362 - loss 1.53937484 - samples/sec: 824.68 - lr: 0.100000\n",
            "2021-07-01 23:56:18,138 epoch 7 - iter 288/362 - loss 1.53557541 - samples/sec: 835.82 - lr: 0.100000\n",
            "2021-07-01 23:56:19,516 epoch 7 - iter 324/362 - loss 1.53774041 - samples/sec: 838.04 - lr: 0.100000\n",
            "2021-07-01 23:56:20,901 epoch 7 - iter 360/362 - loss 1.52803040 - samples/sec: 833.30 - lr: 0.100000\n",
            "2021-07-01 23:56:20,974 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:56:20,976 EPOCH 7 done: loss 1.5278 - lr 0.1000000\n",
            "2021-07-01 23:56:22,421 DEV : loss 1.4494092464447021 - score 0.5315\n",
            "2021-07-01 23:56:22,508 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:56:31,136 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:56:32,630 epoch 8 - iter 36/362 - loss 1.49624719 - samples/sec: 774.11 - lr: 0.100000\n",
            "2021-07-01 23:56:34,017 epoch 8 - iter 72/362 - loss 1.47470600 - samples/sec: 832.50 - lr: 0.100000\n",
            "2021-07-01 23:56:35,365 epoch 8 - iter 108/362 - loss 1.47260364 - samples/sec: 856.65 - lr: 0.100000\n",
            "2021-07-01 23:56:36,720 epoch 8 - iter 144/362 - loss 1.46152085 - samples/sec: 852.34 - lr: 0.100000\n",
            "2021-07-01 23:56:38,142 epoch 8 - iter 180/362 - loss 1.47201068 - samples/sec: 812.00 - lr: 0.100000\n",
            "2021-07-01 23:56:39,487 epoch 8 - iter 216/362 - loss 1.46523928 - samples/sec: 859.11 - lr: 0.100000\n",
            "2021-07-01 23:56:40,880 epoch 8 - iter 252/362 - loss 1.46949917 - samples/sec: 828.60 - lr: 0.100000\n",
            "2021-07-01 23:56:42,268 epoch 8 - iter 288/362 - loss 1.46791401 - samples/sec: 832.13 - lr: 0.100000\n",
            "2021-07-01 23:56:43,677 epoch 8 - iter 324/362 - loss 1.46700848 - samples/sec: 819.62 - lr: 0.100000\n",
            "2021-07-01 23:56:45,036 epoch 8 - iter 360/362 - loss 1.46188365 - samples/sec: 849.85 - lr: 0.100000\n",
            "2021-07-01 23:56:45,120 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:56:45,121 EPOCH 8 done: loss 1.4635 - lr 0.1000000\n",
            "2021-07-01 23:56:46,566 DEV : loss 1.348284125328064 - score 0.5664\n",
            "2021-07-01 23:56:46,655 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:56:55,269 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:56:56,698 epoch 9 - iter 36/362 - loss 1.44490716 - samples/sec: 809.65 - lr: 0.100000\n",
            "2021-07-01 23:56:58,056 epoch 9 - iter 72/362 - loss 1.41319844 - samples/sec: 850.44 - lr: 0.100000\n",
            "2021-07-01 23:56:59,428 epoch 9 - iter 108/362 - loss 1.41654093 - samples/sec: 841.72 - lr: 0.100000\n",
            "2021-07-01 23:57:00,779 epoch 9 - iter 144/362 - loss 1.41957524 - samples/sec: 854.41 - lr: 0.100000\n",
            "2021-07-01 23:57:02,183 epoch 9 - iter 180/362 - loss 1.43110360 - samples/sec: 822.26 - lr: 0.100000\n",
            "2021-07-01 23:57:03,544 epoch 9 - iter 216/362 - loss 1.42778512 - samples/sec: 849.03 - lr: 0.100000\n",
            "2021-07-01 23:57:04,918 epoch 9 - iter 252/362 - loss 1.42276748 - samples/sec: 840.21 - lr: 0.100000\n",
            "2021-07-01 23:57:06,279 epoch 9 - iter 288/362 - loss 1.42414746 - samples/sec: 849.13 - lr: 0.100000\n",
            "2021-07-01 23:57:07,667 epoch 9 - iter 324/362 - loss 1.42433635 - samples/sec: 831.69 - lr: 0.100000\n",
            "2021-07-01 23:57:09,068 epoch 9 - iter 360/362 - loss 1.42446519 - samples/sec: 824.53 - lr: 0.100000\n",
            "2021-07-01 23:57:09,144 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:57:09,145 EPOCH 9 done: loss 1.4242 - lr 0.1000000\n",
            "2021-07-01 23:57:10,591 DEV : loss 1.355925440788269 - score 0.5392\n",
            "2021-07-01 23:57:10,678 BAD EPOCHS (no improvement): 1\n",
            "2021-07-01 23:57:10,681 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:57:12,033 epoch 10 - iter 36/362 - loss 1.42039166 - samples/sec: 855.01 - lr: 0.100000\n",
            "2021-07-01 23:57:13,417 epoch 10 - iter 72/362 - loss 1.43859018 - samples/sec: 834.10 - lr: 0.100000\n",
            "2021-07-01 23:57:14,782 epoch 10 - iter 108/362 - loss 1.42180418 - samples/sec: 846.57 - lr: 0.100000\n",
            "2021-07-01 23:57:16,228 epoch 10 - iter 144/362 - loss 1.41564251 - samples/sec: 798.38 - lr: 0.100000\n",
            "2021-07-01 23:57:17,670 epoch 10 - iter 180/362 - loss 1.40033873 - samples/sec: 801.30 - lr: 0.100000\n",
            "2021-07-01 23:57:19,092 epoch 10 - iter 216/362 - loss 1.40350776 - samples/sec: 812.10 - lr: 0.100000\n",
            "2021-07-01 23:57:20,464 epoch 10 - iter 252/362 - loss 1.39702310 - samples/sec: 842.49 - lr: 0.100000\n",
            "2021-07-01 23:57:21,857 epoch 10 - iter 288/362 - loss 1.39186225 - samples/sec: 828.78 - lr: 0.100000\n",
            "2021-07-01 23:57:23,218 epoch 10 - iter 324/362 - loss 1.39446991 - samples/sec: 848.81 - lr: 0.100000\n",
            "2021-07-01 23:57:24,626 epoch 10 - iter 360/362 - loss 1.39052671 - samples/sec: 819.75 - lr: 0.100000\n",
            "2021-07-01 23:57:24,721 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:57:24,723 EPOCH 10 done: loss 1.3905 - lr 0.1000000\n",
            "2021-07-01 23:57:26,154 DEV : loss 1.298179030418396 - score 0.5843\n",
            "2021-07-01 23:57:26,242 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:57:34,928 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:57:36,299 epoch 11 - iter 36/362 - loss 1.36173007 - samples/sec: 844.14 - lr: 0.100000\n",
            "2021-07-01 23:57:37,719 epoch 11 - iter 72/362 - loss 1.37723262 - samples/sec: 813.57 - lr: 0.100000\n",
            "2021-07-01 23:57:39,103 epoch 11 - iter 108/362 - loss 1.38094433 - samples/sec: 834.23 - lr: 0.100000\n",
            "2021-07-01 23:57:40,519 epoch 11 - iter 144/362 - loss 1.36906266 - samples/sec: 815.24 - lr: 0.100000\n",
            "2021-07-01 23:57:41,891 epoch 11 - iter 180/362 - loss 1.37314785 - samples/sec: 841.90 - lr: 0.100000\n",
            "2021-07-01 23:57:43,257 epoch 11 - iter 216/362 - loss 1.36415395 - samples/sec: 845.30 - lr: 0.100000\n",
            "2021-07-01 23:57:44,644 epoch 11 - iter 252/362 - loss 1.36526528 - samples/sec: 832.73 - lr: 0.100000\n",
            "2021-07-01 23:57:45,978 epoch 11 - iter 288/362 - loss 1.36449479 - samples/sec: 866.07 - lr: 0.100000\n",
            "2021-07-01 23:57:47,390 epoch 11 - iter 324/362 - loss 1.36469640 - samples/sec: 817.64 - lr: 0.100000\n",
            "2021-07-01 23:57:48,795 epoch 11 - iter 360/362 - loss 1.36465875 - samples/sec: 821.92 - lr: 0.100000\n",
            "2021-07-01 23:57:48,885 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:57:48,886 EPOCH 11 done: loss 1.3646 - lr 0.1000000\n",
            "2021-07-01 23:57:50,370 DEV : loss 1.246789813041687 - score 0.6014\n",
            "2021-07-01 23:57:50,461 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:57:59,195 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:58:00,579 epoch 12 - iter 36/362 - loss 1.31404095 - samples/sec: 835.93 - lr: 0.100000\n",
            "2021-07-01 23:58:01,961 epoch 12 - iter 72/362 - loss 1.31139356 - samples/sec: 835.26 - lr: 0.100000\n",
            "2021-07-01 23:58:03,302 epoch 12 - iter 108/362 - loss 1.32839816 - samples/sec: 861.55 - lr: 0.100000\n",
            "2021-07-01 23:58:04,650 epoch 12 - iter 144/362 - loss 1.33145595 - samples/sec: 857.12 - lr: 0.100000\n",
            "2021-07-01 23:58:06,016 epoch 12 - iter 180/362 - loss 1.33446241 - samples/sec: 845.50 - lr: 0.100000\n",
            "2021-07-01 23:58:07,422 epoch 12 - iter 216/362 - loss 1.34349143 - samples/sec: 821.13 - lr: 0.100000\n",
            "2021-07-01 23:58:08,801 epoch 12 - iter 252/362 - loss 1.33282598 - samples/sec: 837.66 - lr: 0.100000\n",
            "2021-07-01 23:58:10,181 epoch 12 - iter 288/362 - loss 1.33342673 - samples/sec: 836.41 - lr: 0.100000\n",
            "2021-07-01 23:58:11,578 epoch 12 - iter 324/362 - loss 1.33146294 - samples/sec: 826.98 - lr: 0.100000\n",
            "2021-07-01 23:58:12,999 epoch 12 - iter 360/362 - loss 1.33494682 - samples/sec: 812.32 - lr: 0.100000\n",
            "2021-07-01 23:58:13,084 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:58:13,086 EPOCH 12 done: loss 1.3352 - lr 0.1000000\n",
            "2021-07-01 23:58:14,527 DEV : loss 1.253495454788208 - score 0.5921\n",
            "2021-07-01 23:58:14,615 BAD EPOCHS (no improvement): 1\n",
            "2021-07-01 23:58:14,617 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:58:15,958 epoch 13 - iter 36/362 - loss 1.31885400 - samples/sec: 862.72 - lr: 0.100000\n",
            "2021-07-01 23:58:17,322 epoch 13 - iter 72/362 - loss 1.29740589 - samples/sec: 846.19 - lr: 0.100000\n",
            "2021-07-01 23:58:18,694 epoch 13 - iter 108/362 - loss 1.31663537 - samples/sec: 841.77 - lr: 0.100000\n",
            "2021-07-01 23:58:20,062 epoch 13 - iter 144/362 - loss 1.31794818 - samples/sec: 844.06 - lr: 0.100000\n",
            "2021-07-01 23:58:21,486 epoch 13 - iter 180/362 - loss 1.32461269 - samples/sec: 810.83 - lr: 0.100000\n",
            "2021-07-01 23:58:22,911 epoch 13 - iter 216/362 - loss 1.32827145 - samples/sec: 810.43 - lr: 0.100000\n",
            "2021-07-01 23:58:24,257 epoch 13 - iter 252/362 - loss 1.32718861 - samples/sec: 858.12 - lr: 0.100000\n",
            "2021-07-01 23:58:25,611 epoch 13 - iter 288/362 - loss 1.32759732 - samples/sec: 852.88 - lr: 0.100000\n",
            "2021-07-01 23:58:27,010 epoch 13 - iter 324/362 - loss 1.33088192 - samples/sec: 825.20 - lr: 0.100000\n",
            "2021-07-01 23:58:28,406 epoch 13 - iter 360/362 - loss 1.32554748 - samples/sec: 827.44 - lr: 0.100000\n",
            "2021-07-01 23:58:28,491 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:58:28,492 EPOCH 13 done: loss 1.3249 - lr 0.1000000\n",
            "2021-07-01 23:58:29,938 DEV : loss 1.2359247207641602 - score 0.6014\n",
            "2021-07-01 23:58:30,025 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:58:38,627 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:58:40,014 epoch 14 - iter 36/362 - loss 1.29077009 - samples/sec: 834.22 - lr: 0.100000\n",
            "2021-07-01 23:58:41,462 epoch 14 - iter 72/362 - loss 1.31745744 - samples/sec: 797.09 - lr: 0.100000\n",
            "2021-07-01 23:58:42,876 epoch 14 - iter 108/362 - loss 1.30828269 - samples/sec: 816.75 - lr: 0.100000\n",
            "2021-07-01 23:58:44,247 epoch 14 - iter 144/362 - loss 1.31089959 - samples/sec: 842.12 - lr: 0.100000\n",
            "2021-07-01 23:58:45,638 epoch 14 - iter 180/362 - loss 1.30584667 - samples/sec: 830.89 - lr: 0.100000\n",
            "2021-07-01 23:58:47,076 epoch 14 - iter 216/362 - loss 1.30594891 - samples/sec: 803.11 - lr: 0.100000\n",
            "2021-07-01 23:58:48,456 epoch 14 - iter 252/362 - loss 1.30026178 - samples/sec: 836.82 - lr: 0.100000\n",
            "2021-07-01 23:58:49,821 epoch 14 - iter 288/362 - loss 1.29647258 - samples/sec: 846.17 - lr: 0.100000\n",
            "2021-07-01 23:58:51,195 epoch 14 - iter 324/362 - loss 1.30609238 - samples/sec: 840.55 - lr: 0.100000\n",
            "2021-07-01 23:58:52,612 epoch 14 - iter 360/362 - loss 1.30435670 - samples/sec: 815.17 - lr: 0.100000\n",
            "2021-07-01 23:58:52,690 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:58:52,691 EPOCH 14 done: loss 1.3044 - lr 0.1000000\n",
            "2021-07-01 23:58:54,134 DEV : loss 1.1955465078353882 - score 0.6099\n",
            "2021-07-01 23:58:54,222 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:59:02,958 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:59:04,366 epoch 15 - iter 36/362 - loss 1.25217111 - samples/sec: 821.60 - lr: 0.100000\n",
            "2021-07-01 23:59:05,697 epoch 15 - iter 72/362 - loss 1.27513444 - samples/sec: 867.35 - lr: 0.100000\n",
            "2021-07-01 23:59:07,100 epoch 15 - iter 108/362 - loss 1.27199164 - samples/sec: 823.72 - lr: 0.100000\n",
            "2021-07-01 23:59:08,463 epoch 15 - iter 144/362 - loss 1.27833102 - samples/sec: 847.21 - lr: 0.100000\n",
            "2021-07-01 23:59:09,841 epoch 15 - iter 180/362 - loss 1.28632770 - samples/sec: 837.87 - lr: 0.100000\n",
            "2021-07-01 23:59:11,208 epoch 15 - iter 216/362 - loss 1.28396127 - samples/sec: 844.78 - lr: 0.100000\n",
            "2021-07-01 23:59:12,629 epoch 15 - iter 252/362 - loss 1.27605772 - samples/sec: 813.12 - lr: 0.100000\n",
            "2021-07-01 23:59:14,003 epoch 15 - iter 288/362 - loss 1.27555015 - samples/sec: 840.07 - lr: 0.100000\n",
            "2021-07-01 23:59:15,377 epoch 15 - iter 324/362 - loss 1.28152711 - samples/sec: 840.91 - lr: 0.100000\n",
            "2021-07-01 23:59:17,849 epoch 15 - iter 360/362 - loss 1.28054382 - samples/sec: 466.58 - lr: 0.100000\n",
            "2021-07-01 23:59:17,927 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:59:17,928 EPOCH 15 done: loss 1.2799 - lr 0.1000000\n",
            "2021-07-01 23:59:19,375 DEV : loss 1.2415273189544678 - score 0.6076\n",
            "2021-07-01 23:59:19,464 BAD EPOCHS (no improvement): 1\n",
            "2021-07-01 23:59:19,466 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:59:20,861 epoch 16 - iter 36/362 - loss 1.28579697 - samples/sec: 829.37 - lr: 0.100000\n",
            "2021-07-01 23:59:22,178 epoch 16 - iter 72/362 - loss 1.28371436 - samples/sec: 876.56 - lr: 0.100000\n",
            "2021-07-01 23:59:23,578 epoch 16 - iter 108/362 - loss 1.28759408 - samples/sec: 825.13 - lr: 0.100000\n",
            "2021-07-01 23:59:24,894 epoch 16 - iter 144/362 - loss 1.29307332 - samples/sec: 877.87 - lr: 0.100000\n",
            "2021-07-01 23:59:26,244 epoch 16 - iter 180/362 - loss 1.29174617 - samples/sec: 855.39 - lr: 0.100000\n",
            "2021-07-01 23:59:27,623 epoch 16 - iter 216/362 - loss 1.27285944 - samples/sec: 837.87 - lr: 0.100000\n",
            "2021-07-01 23:59:29,028 epoch 16 - iter 252/362 - loss 1.27045387 - samples/sec: 821.87 - lr: 0.100000\n",
            "2021-07-01 23:59:30,430 epoch 16 - iter 288/362 - loss 1.27017250 - samples/sec: 823.72 - lr: 0.100000\n",
            "2021-07-01 23:59:31,823 epoch 16 - iter 324/362 - loss 1.27799435 - samples/sec: 828.90 - lr: 0.100000\n",
            "2021-07-01 23:59:33,228 epoch 16 - iter 360/362 - loss 1.27787983 - samples/sec: 821.88 - lr: 0.100000\n",
            "2021-07-01 23:59:33,326 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:59:33,327 EPOCH 16 done: loss 1.2792 - lr 0.1000000\n",
            "2021-07-01 23:59:34,775 DEV : loss 1.1884955167770386 - score 0.6045\n",
            "2021-07-01 23:59:34,864 BAD EPOCHS (no improvement): 2\n",
            "2021-07-01 23:59:34,866 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:59:36,260 epoch 17 - iter 36/362 - loss 1.23216217 - samples/sec: 829.28 - lr: 0.100000\n",
            "2021-07-01 23:59:37,665 epoch 17 - iter 72/362 - loss 1.22699498 - samples/sec: 822.37 - lr: 0.100000\n",
            "2021-07-01 23:59:38,989 epoch 17 - iter 108/362 - loss 1.21628298 - samples/sec: 871.86 - lr: 0.100000\n",
            "2021-07-01 23:59:40,336 epoch 17 - iter 144/362 - loss 1.22815911 - samples/sec: 857.64 - lr: 0.100000\n",
            "2021-07-01 23:59:41,762 epoch 17 - iter 180/362 - loss 1.24028334 - samples/sec: 810.20 - lr: 0.100000\n",
            "2021-07-01 23:59:43,142 epoch 17 - iter 216/362 - loss 1.24424211 - samples/sec: 836.90 - lr: 0.100000\n",
            "2021-07-01 23:59:44,543 epoch 17 - iter 252/362 - loss 1.25915390 - samples/sec: 824.43 - lr: 0.100000\n",
            "2021-07-01 23:59:45,880 epoch 17 - iter 288/362 - loss 1.26119637 - samples/sec: 863.33 - lr: 0.100000\n",
            "2021-07-01 23:59:47,362 epoch 17 - iter 324/362 - loss 1.26089137 - samples/sec: 779.20 - lr: 0.100000\n",
            "2021-07-01 23:59:48,770 epoch 17 - iter 360/362 - loss 1.25604958 - samples/sec: 820.81 - lr: 0.100000\n",
            "2021-07-01 23:59:48,853 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:59:48,854 EPOCH 17 done: loss 1.2570 - lr 0.1000000\n",
            "2021-07-01 23:59:50,341 DEV : loss 1.1972590684890747 - score 0.6169\n",
            "2021-07-01 23:59:50,432 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:59:59,195 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:00,652 epoch 18 - iter 36/362 - loss 1.19364214 - samples/sec: 793.98 - lr: 0.100000\n",
            "2021-07-02 00:00:02,145 epoch 18 - iter 72/362 - loss 1.23229649 - samples/sec: 773.87 - lr: 0.100000\n",
            "2021-07-02 00:00:03,529 epoch 18 - iter 108/362 - loss 1.24086442 - samples/sec: 834.90 - lr: 0.100000\n",
            "2021-07-02 00:00:04,958 epoch 18 - iter 144/362 - loss 1.24522728 - samples/sec: 808.61 - lr: 0.100000\n",
            "2021-07-02 00:00:06,339 epoch 18 - iter 180/362 - loss 1.23717902 - samples/sec: 836.68 - lr: 0.100000\n",
            "2021-07-02 00:00:07,784 epoch 18 - iter 216/362 - loss 1.24454842 - samples/sec: 798.83 - lr: 0.100000\n",
            "2021-07-02 00:00:09,183 epoch 18 - iter 252/362 - loss 1.25538415 - samples/sec: 825.99 - lr: 0.100000\n",
            "2021-07-02 00:00:10,507 epoch 18 - iter 288/362 - loss 1.25368221 - samples/sec: 872.09 - lr: 0.100000\n",
            "2021-07-02 00:00:11,979 epoch 18 - iter 324/362 - loss 1.25313437 - samples/sec: 784.45 - lr: 0.100000\n",
            "2021-07-02 00:00:13,511 epoch 18 - iter 360/362 - loss 1.25058245 - samples/sec: 754.12 - lr: 0.100000\n",
            "2021-07-02 00:00:13,594 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:13,596 EPOCH 18 done: loss 1.2506 - lr 0.1000000\n",
            "2021-07-02 00:00:15,111 DEV : loss 1.2240028381347656 - score 0.6037\n",
            "2021-07-02 00:00:15,200 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:00:15,202 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:16,677 epoch 19 - iter 36/362 - loss 1.15856228 - samples/sec: 784.28 - lr: 0.100000\n",
            "2021-07-02 00:00:18,102 epoch 19 - iter 72/362 - loss 1.18833561 - samples/sec: 810.21 - lr: 0.100000\n",
            "2021-07-02 00:00:19,545 epoch 19 - iter 108/362 - loss 1.19402710 - samples/sec: 800.91 - lr: 0.100000\n",
            "2021-07-02 00:00:20,955 epoch 19 - iter 144/362 - loss 1.21360379 - samples/sec: 819.11 - lr: 0.100000\n",
            "2021-07-02 00:00:22,349 epoch 19 - iter 180/362 - loss 1.22425000 - samples/sec: 828.93 - lr: 0.100000\n",
            "2021-07-02 00:00:23,741 epoch 19 - iter 216/362 - loss 1.21722496 - samples/sec: 829.13 - lr: 0.100000\n",
            "2021-07-02 00:00:25,128 epoch 19 - iter 252/362 - loss 1.23260565 - samples/sec: 833.05 - lr: 0.100000\n",
            "2021-07-02 00:00:26,498 epoch 19 - iter 288/362 - loss 1.23005110 - samples/sec: 843.06 - lr: 0.100000\n",
            "2021-07-02 00:00:27,853 epoch 19 - iter 324/362 - loss 1.23490951 - samples/sec: 852.08 - lr: 0.100000\n",
            "2021-07-02 00:00:29,233 epoch 19 - iter 360/362 - loss 1.23755531 - samples/sec: 836.98 - lr: 0.100000\n",
            "2021-07-02 00:00:29,320 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:29,321 EPOCH 19 done: loss 1.2373 - lr 0.1000000\n",
            "2021-07-02 00:00:30,776 DEV : loss 1.2093459367752075 - score 0.6115\n",
            "2021-07-02 00:00:30,864 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:00:30,866 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:32,236 epoch 20 - iter 36/362 - loss 1.19246552 - samples/sec: 843.90 - lr: 0.100000\n",
            "2021-07-02 00:00:33,601 epoch 20 - iter 72/362 - loss 1.19240109 - samples/sec: 846.31 - lr: 0.100000\n",
            "2021-07-02 00:00:34,996 epoch 20 - iter 108/362 - loss 1.20287116 - samples/sec: 828.11 - lr: 0.100000\n",
            "2021-07-02 00:00:36,396 epoch 20 - iter 144/362 - loss 1.20925064 - samples/sec: 824.53 - lr: 0.100000\n",
            "2021-07-02 00:00:37,809 epoch 20 - iter 180/362 - loss 1.21332780 - samples/sec: 817.97 - lr: 0.100000\n",
            "2021-07-02 00:00:39,228 epoch 20 - iter 216/362 - loss 1.21350921 - samples/sec: 814.17 - lr: 0.100000\n",
            "2021-07-02 00:00:40,665 epoch 20 - iter 252/362 - loss 1.20872384 - samples/sec: 803.51 - lr: 0.100000\n",
            "2021-07-02 00:00:42,148 epoch 20 - iter 288/362 - loss 1.22138362 - samples/sec: 778.94 - lr: 0.100000\n",
            "2021-07-02 00:00:43,554 epoch 20 - iter 324/362 - loss 1.22814280 - samples/sec: 821.32 - lr: 0.100000\n",
            "2021-07-02 00:00:44,999 epoch 20 - iter 360/362 - loss 1.22798204 - samples/sec: 799.11 - lr: 0.100000\n",
            "2021-07-02 00:00:45,083 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:45,084 EPOCH 20 done: loss 1.2286 - lr 0.1000000\n",
            "2021-07-02 00:00:46,565 DEV : loss 1.1689499616622925 - score 0.6232\n",
            "2021-07-02 00:00:46,654 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:00:56,165 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:00:57,621 epoch 21 - iter 36/362 - loss 1.18278543 - samples/sec: 794.56 - lr: 0.100000\n",
            "2021-07-02 00:00:58,982 epoch 21 - iter 72/362 - loss 1.19569659 - samples/sec: 848.44 - lr: 0.100000\n",
            "2021-07-02 00:01:00,373 epoch 21 - iter 108/362 - loss 1.18745574 - samples/sec: 829.99 - lr: 0.100000\n",
            "2021-07-02 00:01:01,756 epoch 21 - iter 144/362 - loss 1.19945652 - samples/sec: 835.07 - lr: 0.100000\n",
            "2021-07-02 00:01:03,105 epoch 21 - iter 180/362 - loss 1.20642560 - samples/sec: 855.98 - lr: 0.100000\n",
            "2021-07-02 00:01:04,512 epoch 21 - iter 216/362 - loss 1.21143868 - samples/sec: 820.48 - lr: 0.100000\n",
            "2021-07-02 00:01:05,828 epoch 21 - iter 252/362 - loss 1.21718846 - samples/sec: 877.71 - lr: 0.100000\n",
            "2021-07-02 00:01:07,226 epoch 21 - iter 288/362 - loss 1.22291429 - samples/sec: 826.01 - lr: 0.100000\n",
            "2021-07-02 00:01:08,652 epoch 21 - iter 324/362 - loss 1.22078546 - samples/sec: 810.08 - lr: 0.100000\n",
            "2021-07-02 00:01:10,055 epoch 21 - iter 360/362 - loss 1.21794288 - samples/sec: 823.14 - lr: 0.100000\n",
            "2021-07-02 00:01:10,130 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:01:10,131 EPOCH 21 done: loss 1.2172 - lr 0.1000000\n",
            "2021-07-02 00:01:11,576 DEV : loss 1.197001576423645 - score 0.6154\n",
            "2021-07-02 00:01:11,664 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:01:11,666 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:01:13,017 epoch 22 - iter 36/362 - loss 1.18449161 - samples/sec: 855.49 - lr: 0.100000\n",
            "2021-07-02 00:01:14,370 epoch 22 - iter 72/362 - loss 1.18717534 - samples/sec: 853.91 - lr: 0.100000\n",
            "2021-07-02 00:01:15,760 epoch 22 - iter 108/362 - loss 1.20499660 - samples/sec: 830.96 - lr: 0.100000\n",
            "2021-07-02 00:01:17,132 epoch 22 - iter 144/362 - loss 1.20642439 - samples/sec: 841.29 - lr: 0.100000\n",
            "2021-07-02 00:01:18,540 epoch 22 - iter 180/362 - loss 1.21447949 - samples/sec: 820.24 - lr: 0.100000\n",
            "2021-07-02 00:01:19,914 epoch 22 - iter 216/362 - loss 1.21269081 - samples/sec: 840.22 - lr: 0.100000\n",
            "2021-07-02 00:01:21,271 epoch 22 - iter 252/362 - loss 1.21255739 - samples/sec: 851.58 - lr: 0.100000\n",
            "2021-07-02 00:01:22,666 epoch 22 - iter 288/362 - loss 1.20887875 - samples/sec: 827.42 - lr: 0.100000\n",
            "2021-07-02 00:01:24,036 epoch 22 - iter 324/362 - loss 1.20852129 - samples/sec: 843.34 - lr: 0.100000\n",
            "2021-07-02 00:01:25,411 epoch 22 - iter 360/362 - loss 1.20233219 - samples/sec: 839.84 - lr: 0.100000\n",
            "2021-07-02 00:01:25,498 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:01:25,499 EPOCH 22 done: loss 1.2025 - lr 0.1000000\n",
            "2021-07-02 00:01:26,934 DEV : loss 1.167676329612732 - score 0.6348\n",
            "2021-07-02 00:01:27,024 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:01:35,897 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:01:37,326 epoch 23 - iter 36/362 - loss 1.21418727 - samples/sec: 809.54 - lr: 0.100000\n",
            "2021-07-02 00:01:38,705 epoch 23 - iter 72/362 - loss 1.21190025 - samples/sec: 837.03 - lr: 0.100000\n",
            "2021-07-02 00:01:40,094 epoch 23 - iter 108/362 - loss 1.18890839 - samples/sec: 831.48 - lr: 0.100000\n",
            "2021-07-02 00:01:41,509 epoch 23 - iter 144/362 - loss 1.19578306 - samples/sec: 816.31 - lr: 0.100000\n",
            "2021-07-02 00:01:42,896 epoch 23 - iter 180/362 - loss 1.19621623 - samples/sec: 832.29 - lr: 0.100000\n",
            "2021-07-02 00:01:44,294 epoch 23 - iter 216/362 - loss 1.19371078 - samples/sec: 826.19 - lr: 0.100000\n",
            "2021-07-02 00:01:45,662 epoch 23 - iter 252/362 - loss 1.19067032 - samples/sec: 844.09 - lr: 0.100000\n",
            "2021-07-02 00:01:47,044 epoch 23 - iter 288/362 - loss 1.19012194 - samples/sec: 836.09 - lr: 0.100000\n",
            "2021-07-02 00:01:48,401 epoch 23 - iter 324/362 - loss 1.18860266 - samples/sec: 851.02 - lr: 0.100000\n",
            "2021-07-02 00:01:49,771 epoch 23 - iter 360/362 - loss 1.18664692 - samples/sec: 842.95 - lr: 0.100000\n",
            "2021-07-02 00:01:49,856 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:01:49,858 EPOCH 23 done: loss 1.1882 - lr 0.1000000\n",
            "2021-07-02 00:01:51,294 DEV : loss 1.1566675901412964 - score 0.6309\n",
            "2021-07-02 00:01:51,383 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:01:51,387 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:01:52,797 epoch 24 - iter 36/362 - loss 1.18438556 - samples/sec: 820.34 - lr: 0.100000\n",
            "2021-07-02 00:01:54,154 epoch 24 - iter 72/362 - loss 1.15698840 - samples/sec: 851.18 - lr: 0.100000\n",
            "2021-07-02 00:01:55,544 epoch 24 - iter 108/362 - loss 1.14695764 - samples/sec: 831.04 - lr: 0.100000\n",
            "2021-07-02 00:01:56,969 epoch 24 - iter 144/362 - loss 1.16303269 - samples/sec: 810.37 - lr: 0.100000\n",
            "2021-07-02 00:01:58,339 epoch 24 - iter 180/362 - loss 1.17823573 - samples/sec: 842.91 - lr: 0.100000\n",
            "2021-07-02 00:01:59,753 epoch 24 - iter 216/362 - loss 1.17775825 - samples/sec: 817.18 - lr: 0.100000\n",
            "2021-07-02 00:02:01,195 epoch 24 - iter 252/362 - loss 1.18181450 - samples/sec: 800.37 - lr: 0.100000\n",
            "2021-07-02 00:02:02,532 epoch 24 - iter 288/362 - loss 1.18637916 - samples/sec: 863.74 - lr: 0.100000\n",
            "2021-07-02 00:02:03,896 epoch 24 - iter 324/362 - loss 1.19383240 - samples/sec: 846.61 - lr: 0.100000\n",
            "2021-07-02 00:02:05,300 epoch 24 - iter 360/362 - loss 1.18804547 - samples/sec: 822.34 - lr: 0.100000\n",
            "2021-07-02 00:02:05,378 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:05,379 EPOCH 24 done: loss 1.1890 - lr 0.1000000\n",
            "2021-07-02 00:02:06,817 DEV : loss 1.1460100412368774 - score 0.6317\n",
            "2021-07-02 00:02:06,906 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:02:06,909 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:08,298 epoch 25 - iter 36/362 - loss 1.18607585 - samples/sec: 832.18 - lr: 0.100000\n",
            "2021-07-02 00:02:09,664 epoch 25 - iter 72/362 - loss 1.18372599 - samples/sec: 845.98 - lr: 0.100000\n",
            "2021-07-02 00:02:11,067 epoch 25 - iter 108/362 - loss 1.16217588 - samples/sec: 822.85 - lr: 0.100000\n",
            "2021-07-02 00:02:12,435 epoch 25 - iter 144/362 - loss 1.17272703 - samples/sec: 844.43 - lr: 0.100000\n",
            "2021-07-02 00:02:13,945 epoch 25 - iter 180/362 - loss 1.17223103 - samples/sec: 764.79 - lr: 0.100000\n",
            "2021-07-02 00:02:15,350 epoch 25 - iter 216/362 - loss 1.17222315 - samples/sec: 822.08 - lr: 0.100000\n",
            "2021-07-02 00:02:16,727 epoch 25 - iter 252/362 - loss 1.17484030 - samples/sec: 838.87 - lr: 0.100000\n",
            "2021-07-02 00:02:18,081 epoch 25 - iter 288/362 - loss 1.17354609 - samples/sec: 852.98 - lr: 0.100000\n",
            "2021-07-02 00:02:19,490 epoch 25 - iter 324/362 - loss 1.17158995 - samples/sec: 819.70 - lr: 0.100000\n",
            "2021-07-02 00:02:20,883 epoch 25 - iter 360/362 - loss 1.17081666 - samples/sec: 829.31 - lr: 0.100000\n",
            "2021-07-02 00:02:20,970 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:20,972 EPOCH 25 done: loss 1.1715 - lr 0.1000000\n",
            "2021-07-02 00:02:22,409 DEV : loss 1.1691254377365112 - score 0.6278\n",
            "2021-07-02 00:02:22,498 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:02:22,500 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:23,897 epoch 26 - iter 36/362 - loss 1.17594231 - samples/sec: 827.09 - lr: 0.100000\n",
            "2021-07-02 00:02:25,235 epoch 26 - iter 72/362 - loss 1.16941667 - samples/sec: 862.57 - lr: 0.100000\n",
            "2021-07-02 00:02:26,608 epoch 26 - iter 108/362 - loss 1.18751600 - samples/sec: 841.03 - lr: 0.100000\n",
            "2021-07-02 00:02:27,978 epoch 26 - iter 144/362 - loss 1.18006402 - samples/sec: 843.24 - lr: 0.100000\n",
            "2021-07-02 00:02:29,350 epoch 26 - iter 180/362 - loss 1.17597764 - samples/sec: 841.95 - lr: 0.100000\n",
            "2021-07-02 00:02:30,716 epoch 26 - iter 216/362 - loss 1.18309484 - samples/sec: 845.58 - lr: 0.100000\n",
            "2021-07-02 00:02:32,106 epoch 26 - iter 252/362 - loss 1.17246269 - samples/sec: 830.83 - lr: 0.100000\n",
            "2021-07-02 00:02:33,471 epoch 26 - iter 288/362 - loss 1.17392120 - samples/sec: 845.75 - lr: 0.100000\n",
            "2021-07-02 00:02:34,878 epoch 26 - iter 324/362 - loss 1.17058262 - samples/sec: 820.76 - lr: 0.100000\n",
            "2021-07-02 00:02:36,269 epoch 26 - iter 360/362 - loss 1.16845165 - samples/sec: 830.33 - lr: 0.100000\n",
            "2021-07-02 00:02:36,352 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:36,353 EPOCH 26 done: loss 1.1682 - lr 0.1000000\n",
            "2021-07-02 00:02:37,806 DEV : loss 1.1636170148849487 - score 0.6263\n",
            "2021-07-02 00:02:37,894 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:02:37,895 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:39,253 epoch 27 - iter 36/362 - loss 1.17034942 - samples/sec: 851.24 - lr: 0.100000\n",
            "2021-07-02 00:02:40,611 epoch 27 - iter 72/362 - loss 1.15054913 - samples/sec: 850.43 - lr: 0.100000\n",
            "2021-07-02 00:02:42,004 epoch 27 - iter 108/362 - loss 1.15448289 - samples/sec: 829.89 - lr: 0.100000\n",
            "2021-07-02 00:02:43,372 epoch 27 - iter 144/362 - loss 1.15457816 - samples/sec: 844.23 - lr: 0.100000\n",
            "2021-07-02 00:02:44,731 epoch 27 - iter 180/362 - loss 1.15939165 - samples/sec: 849.59 - lr: 0.100000\n",
            "2021-07-02 00:02:46,061 epoch 27 - iter 216/362 - loss 1.15263327 - samples/sec: 868.39 - lr: 0.100000\n",
            "2021-07-02 00:02:47,565 epoch 27 - iter 252/362 - loss 1.15962566 - samples/sec: 767.95 - lr: 0.100000\n",
            "2021-07-02 00:02:48,978 epoch 27 - iter 288/362 - loss 1.15956553 - samples/sec: 817.25 - lr: 0.100000\n",
            "2021-07-02 00:02:50,381 epoch 27 - iter 324/362 - loss 1.16348648 - samples/sec: 822.67 - lr: 0.100000\n",
            "2021-07-02 00:02:51,781 epoch 27 - iter 360/362 - loss 1.16081921 - samples/sec: 825.01 - lr: 0.100000\n",
            "2021-07-02 00:02:51,867 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:51,868 EPOCH 27 done: loss 1.1620 - lr 0.1000000\n",
            "2021-07-02 00:02:53,298 DEV : loss 1.1686890125274658 - score 0.627\n",
            "2021-07-02 00:02:53,387 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:02:53,391 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:02:54,803 epoch 28 - iter 36/362 - loss 1.18068007 - samples/sec: 818.86 - lr: 0.100000\n",
            "2021-07-02 00:02:56,172 epoch 28 - iter 72/362 - loss 1.17339215 - samples/sec: 843.37 - lr: 0.100000\n",
            "2021-07-02 00:02:57,516 epoch 28 - iter 108/362 - loss 1.17298679 - samples/sec: 859.86 - lr: 0.100000\n",
            "2021-07-02 00:02:58,873 epoch 28 - iter 144/362 - loss 1.16240900 - samples/sec: 851.25 - lr: 0.100000\n",
            "2021-07-02 00:03:00,232 epoch 28 - iter 180/362 - loss 1.14267251 - samples/sec: 849.60 - lr: 0.100000\n",
            "2021-07-02 00:03:01,618 epoch 28 - iter 216/362 - loss 1.14086003 - samples/sec: 832.96 - lr: 0.100000\n",
            "2021-07-02 00:03:02,948 epoch 28 - iter 252/362 - loss 1.13632000 - samples/sec: 868.54 - lr: 0.100000\n",
            "2021-07-02 00:03:04,331 epoch 28 - iter 288/362 - loss 1.14302547 - samples/sec: 834.75 - lr: 0.100000\n",
            "2021-07-02 00:03:05,688 epoch 28 - iter 324/362 - loss 1.14442206 - samples/sec: 851.09 - lr: 0.100000\n",
            "2021-07-02 00:03:07,095 epoch 28 - iter 360/362 - loss 1.14796131 - samples/sec: 820.70 - lr: 0.100000\n",
            "2021-07-02 00:03:07,183 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:03:07,185 EPOCH 28 done: loss 1.1492 - lr 0.1000000\n",
            "2021-07-02 00:03:08,627 DEV : loss 1.1462483406066895 - score 0.6356\n",
            "2021-07-02 00:03:08,716 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:03:17,512 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:03:18,948 epoch 29 - iter 36/362 - loss 1.10517522 - samples/sec: 805.29 - lr: 0.100000\n",
            "2021-07-02 00:03:20,374 epoch 29 - iter 72/362 - loss 1.11173177 - samples/sec: 809.80 - lr: 0.100000\n",
            "2021-07-02 00:03:21,738 epoch 29 - iter 108/362 - loss 1.11452633 - samples/sec: 846.47 - lr: 0.100000\n",
            "2021-07-02 00:03:23,204 epoch 29 - iter 144/362 - loss 1.12135242 - samples/sec: 787.70 - lr: 0.100000\n",
            "2021-07-02 00:03:24,583 epoch 29 - iter 180/362 - loss 1.12293157 - samples/sec: 837.78 - lr: 0.100000\n",
            "2021-07-02 00:03:25,940 epoch 29 - iter 216/362 - loss 1.12960472 - samples/sec: 851.38 - lr: 0.100000\n",
            "2021-07-02 00:03:27,281 epoch 29 - iter 252/362 - loss 1.13257816 - samples/sec: 861.25 - lr: 0.100000\n",
            "2021-07-02 00:03:28,654 epoch 29 - iter 288/362 - loss 1.13480551 - samples/sec: 841.05 - lr: 0.100000\n",
            "2021-07-02 00:03:29,988 epoch 29 - iter 324/362 - loss 1.14065712 - samples/sec: 866.05 - lr: 0.100000\n",
            "2021-07-02 00:03:31,396 epoch 29 - iter 360/362 - loss 1.14553136 - samples/sec: 819.91 - lr: 0.100000\n",
            "2021-07-02 00:03:31,478 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:03:31,480 EPOCH 29 done: loss 1.1438 - lr 0.1000000\n",
            "2021-07-02 00:03:32,916 DEV : loss 1.16313636302948 - score 0.6301\n",
            "2021-07-02 00:03:33,003 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:03:33,005 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:03:34,388 epoch 30 - iter 36/362 - loss 1.06901745 - samples/sec: 835.74 - lr: 0.100000\n",
            "2021-07-02 00:03:35,754 epoch 30 - iter 72/362 - loss 1.07372208 - samples/sec: 845.66 - lr: 0.100000\n",
            "2021-07-02 00:03:37,172 epoch 30 - iter 108/362 - loss 1.08727569 - samples/sec: 814.09 - lr: 0.100000\n",
            "2021-07-02 00:03:38,562 epoch 30 - iter 144/362 - loss 1.09206461 - samples/sec: 830.68 - lr: 0.100000\n",
            "2021-07-02 00:03:39,933 epoch 30 - iter 180/362 - loss 1.09192785 - samples/sec: 842.31 - lr: 0.100000\n",
            "2021-07-02 00:03:41,345 epoch 30 - iter 216/362 - loss 1.10211772 - samples/sec: 818.35 - lr: 0.100000\n",
            "2021-07-02 00:03:42,754 epoch 30 - iter 252/362 - loss 1.11600880 - samples/sec: 819.64 - lr: 0.100000\n",
            "2021-07-02 00:03:44,139 epoch 30 - iter 288/362 - loss 1.12798563 - samples/sec: 833.91 - lr: 0.100000\n",
            "2021-07-02 00:03:45,500 epoch 30 - iter 324/362 - loss 1.12884279 - samples/sec: 848.64 - lr: 0.100000\n",
            "2021-07-02 00:03:46,904 epoch 30 - iter 360/362 - loss 1.13152524 - samples/sec: 822.87 - lr: 0.100000\n",
            "2021-07-02 00:03:46,989 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:03:46,990 EPOCH 30 done: loss 1.1315 - lr 0.1000000\n",
            "2021-07-02 00:03:48,420 DEV : loss 1.1826997995376587 - score 0.6247\n",
            "2021-07-02 00:03:48,508 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:03:48,510 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:03:49,925 epoch 31 - iter 36/362 - loss 1.09362717 - samples/sec: 817.07 - lr: 0.100000\n",
            "2021-07-02 00:03:51,283 epoch 31 - iter 72/362 - loss 1.11343726 - samples/sec: 850.25 - lr: 0.100000\n",
            "2021-07-02 00:03:52,739 epoch 31 - iter 108/362 - loss 1.10741048 - samples/sec: 792.97 - lr: 0.100000\n",
            "2021-07-02 00:03:54,130 epoch 31 - iter 144/362 - loss 1.11142081 - samples/sec: 830.55 - lr: 0.100000\n",
            "2021-07-02 00:03:55,485 epoch 31 - iter 180/362 - loss 1.11311001 - samples/sec: 852.07 - lr: 0.100000\n",
            "2021-07-02 00:03:56,836 epoch 31 - iter 216/362 - loss 1.12078363 - samples/sec: 855.21 - lr: 0.100000\n",
            "2021-07-02 00:03:58,215 epoch 31 - iter 252/362 - loss 1.11945368 - samples/sec: 837.42 - lr: 0.100000\n",
            "2021-07-02 00:03:59,588 epoch 31 - iter 288/362 - loss 1.11726128 - samples/sec: 841.23 - lr: 0.100000\n",
            "2021-07-02 00:04:01,007 epoch 31 - iter 324/362 - loss 1.12060289 - samples/sec: 813.66 - lr: 0.100000\n",
            "2021-07-02 00:04:02,397 epoch 31 - iter 360/362 - loss 1.11865131 - samples/sec: 831.09 - lr: 0.100000\n",
            "2021-07-02 00:04:02,477 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:02,478 EPOCH 31 done: loss 1.1179 - lr 0.1000000\n",
            "2021-07-02 00:04:03,915 DEV : loss 1.147223711013794 - score 0.6441\n",
            "2021-07-02 00:04:04,003 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:04:12,761 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:14,159 epoch 32 - iter 36/362 - loss 1.12273738 - samples/sec: 827.62 - lr: 0.100000\n",
            "2021-07-02 00:04:15,517 epoch 32 - iter 72/362 - loss 1.12123083 - samples/sec: 850.07 - lr: 0.100000\n",
            "2021-07-02 00:04:16,883 epoch 32 - iter 108/362 - loss 1.12276996 - samples/sec: 845.54 - lr: 0.100000\n",
            "2021-07-02 00:04:18,280 epoch 32 - iter 144/362 - loss 1.11907874 - samples/sec: 826.75 - lr: 0.100000\n",
            "2021-07-02 00:04:19,664 epoch 32 - iter 180/362 - loss 1.11963003 - samples/sec: 834.41 - lr: 0.100000\n",
            "2021-07-02 00:04:21,029 epoch 32 - iter 216/362 - loss 1.11647986 - samples/sec: 845.88 - lr: 0.100000\n",
            "2021-07-02 00:04:22,428 epoch 32 - iter 252/362 - loss 1.11320954 - samples/sec: 825.54 - lr: 0.100000\n",
            "2021-07-02 00:04:23,809 epoch 32 - iter 288/362 - loss 1.11517181 - samples/sec: 836.66 - lr: 0.100000\n",
            "2021-07-02 00:04:25,200 epoch 32 - iter 324/362 - loss 1.11596947 - samples/sec: 830.22 - lr: 0.100000\n",
            "2021-07-02 00:04:26,627 epoch 32 - iter 360/362 - loss 1.11356162 - samples/sec: 809.38 - lr: 0.100000\n",
            "2021-07-02 00:04:26,715 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:26,716 EPOCH 32 done: loss 1.1145 - lr 0.1000000\n",
            "2021-07-02 00:04:28,169 DEV : loss 1.1191024780273438 - score 0.6333\n",
            "2021-07-02 00:04:28,256 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:04:28,258 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:29,652 epoch 33 - iter 36/362 - loss 1.10606731 - samples/sec: 829.30 - lr: 0.100000\n",
            "2021-07-02 00:04:31,030 epoch 33 - iter 72/362 - loss 1.09821633 - samples/sec: 838.26 - lr: 0.100000\n",
            "2021-07-02 00:04:32,385 epoch 33 - iter 108/362 - loss 1.10547659 - samples/sec: 852.55 - lr: 0.100000\n",
            "2021-07-02 00:04:33,722 epoch 33 - iter 144/362 - loss 1.11414304 - samples/sec: 863.92 - lr: 0.100000\n",
            "2021-07-02 00:04:35,076 epoch 33 - iter 180/362 - loss 1.10288131 - samples/sec: 852.95 - lr: 0.100000\n",
            "2021-07-02 00:04:36,454 epoch 33 - iter 216/362 - loss 1.10128322 - samples/sec: 838.13 - lr: 0.100000\n",
            "2021-07-02 00:04:37,836 epoch 33 - iter 252/362 - loss 1.08961591 - samples/sec: 835.71 - lr: 0.100000\n",
            "2021-07-02 00:04:39,251 epoch 33 - iter 288/362 - loss 1.09231649 - samples/sec: 816.10 - lr: 0.100000\n",
            "2021-07-02 00:04:40,635 epoch 33 - iter 324/362 - loss 1.09324342 - samples/sec: 834.04 - lr: 0.100000\n",
            "2021-07-02 00:04:42,088 epoch 33 - iter 360/362 - loss 1.09417022 - samples/sec: 794.90 - lr: 0.100000\n",
            "2021-07-02 00:04:42,170 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:42,171 EPOCH 33 done: loss 1.0957 - lr 0.1000000\n",
            "2021-07-02 00:04:43,645 DEV : loss 1.1130013465881348 - score 0.6356\n",
            "2021-07-02 00:04:43,734 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:04:43,736 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:45,083 epoch 34 - iter 36/362 - loss 1.13099864 - samples/sec: 858.41 - lr: 0.100000\n",
            "2021-07-02 00:04:46,517 epoch 34 - iter 72/362 - loss 1.08305603 - samples/sec: 805.35 - lr: 0.100000\n",
            "2021-07-02 00:04:47,854 epoch 34 - iter 108/362 - loss 1.11554671 - samples/sec: 863.74 - lr: 0.100000\n",
            "2021-07-02 00:04:49,232 epoch 34 - iter 144/362 - loss 1.11413014 - samples/sec: 838.38 - lr: 0.100000\n",
            "2021-07-02 00:04:50,591 epoch 34 - iter 180/362 - loss 1.10987513 - samples/sec: 849.45 - lr: 0.100000\n",
            "2021-07-02 00:04:51,983 epoch 34 - iter 216/362 - loss 1.10459100 - samples/sec: 829.42 - lr: 0.100000\n",
            "2021-07-02 00:04:53,351 epoch 34 - iter 252/362 - loss 1.10251174 - samples/sec: 844.93 - lr: 0.100000\n",
            "2021-07-02 00:04:54,701 epoch 34 - iter 288/362 - loss 1.09536847 - samples/sec: 855.32 - lr: 0.100000\n",
            "2021-07-02 00:04:56,105 epoch 34 - iter 324/362 - loss 1.10202367 - samples/sec: 822.58 - lr: 0.100000\n",
            "2021-07-02 00:04:58,593 epoch 34 - iter 360/362 - loss 1.09906872 - samples/sec: 463.73 - lr: 0.100000\n",
            "2021-07-02 00:04:58,701 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:04:58,703 EPOCH 34 done: loss 1.1000 - lr 0.1000000\n",
            "2021-07-02 00:05:00,183 DEV : loss 1.1397002935409546 - score 0.6278\n",
            "2021-07-02 00:05:00,270 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:05:00,272 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:01,659 epoch 35 - iter 36/362 - loss 1.02506728 - samples/sec: 833.46 - lr: 0.100000\n",
            "2021-07-02 00:05:03,006 epoch 35 - iter 72/362 - loss 1.07813780 - samples/sec: 857.45 - lr: 0.100000\n",
            "2021-07-02 00:05:04,382 epoch 35 - iter 108/362 - loss 1.09436484 - samples/sec: 839.40 - lr: 0.100000\n",
            "2021-07-02 00:05:05,762 epoch 35 - iter 144/362 - loss 1.09908259 - samples/sec: 836.71 - lr: 0.100000\n",
            "2021-07-02 00:05:07,188 epoch 35 - iter 180/362 - loss 1.10047548 - samples/sec: 809.68 - lr: 0.100000\n",
            "2021-07-02 00:05:08,551 epoch 35 - iter 216/362 - loss 1.09744705 - samples/sec: 847.62 - lr: 0.100000\n",
            "2021-07-02 00:05:09,918 epoch 35 - iter 252/362 - loss 1.09603765 - samples/sec: 844.97 - lr: 0.100000\n",
            "2021-07-02 00:05:11,313 epoch 35 - iter 288/362 - loss 1.09001556 - samples/sec: 828.04 - lr: 0.100000\n",
            "2021-07-02 00:05:12,693 epoch 35 - iter 324/362 - loss 1.09072749 - samples/sec: 836.77 - lr: 0.100000\n",
            "2021-07-02 00:05:14,106 epoch 35 - iter 360/362 - loss 1.09137920 - samples/sec: 817.71 - lr: 0.100000\n",
            "2021-07-02 00:05:14,189 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:14,190 EPOCH 35 done: loss 1.0920 - lr 0.1000000\n",
            "2021-07-02 00:05:15,637 DEV : loss 1.1224716901779175 - score 0.641\n",
            "2021-07-02 00:05:15,727 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:05:15,729 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:17,137 epoch 36 - iter 36/362 - loss 1.08347056 - samples/sec: 821.07 - lr: 0.100000\n",
            "2021-07-02 00:05:18,516 epoch 36 - iter 72/362 - loss 1.05359400 - samples/sec: 837.42 - lr: 0.100000\n",
            "2021-07-02 00:05:19,895 epoch 36 - iter 108/362 - loss 1.06720649 - samples/sec: 837.14 - lr: 0.100000\n",
            "2021-07-02 00:05:21,272 epoch 36 - iter 144/362 - loss 1.06384211 - samples/sec: 839.23 - lr: 0.100000\n",
            "2021-07-02 00:05:22,624 epoch 36 - iter 180/362 - loss 1.07299382 - samples/sec: 853.87 - lr: 0.100000\n",
            "2021-07-02 00:05:24,023 epoch 36 - iter 216/362 - loss 1.06878313 - samples/sec: 825.69 - lr: 0.100000\n",
            "2021-07-02 00:05:25,376 epoch 36 - iter 252/362 - loss 1.06846171 - samples/sec: 853.36 - lr: 0.100000\n",
            "2021-07-02 00:05:26,740 epoch 36 - iter 288/362 - loss 1.07615547 - samples/sec: 846.52 - lr: 0.100000\n",
            "2021-07-02 00:05:28,111 epoch 36 - iter 324/362 - loss 1.07745301 - samples/sec: 842.55 - lr: 0.100000\n",
            "2021-07-02 00:05:29,478 epoch 36 - iter 360/362 - loss 1.08123313 - samples/sec: 844.57 - lr: 0.100000\n",
            "2021-07-02 00:05:29,563 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:29,564 EPOCH 36 done: loss 1.0810 - lr 0.1000000\n",
            "2021-07-02 00:05:31,009 DEV : loss 1.1221801042556763 - score 0.6441\n",
            "2021-07-02 00:05:31,101 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:05:39,852 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:41,315 epoch 37 - iter 36/362 - loss 1.06011345 - samples/sec: 790.51 - lr: 0.100000\n",
            "2021-07-02 00:05:42,733 epoch 37 - iter 72/362 - loss 1.08252389 - samples/sec: 814.25 - lr: 0.100000\n",
            "2021-07-02 00:05:44,111 epoch 37 - iter 108/362 - loss 1.08350964 - samples/sec: 837.96 - lr: 0.100000\n",
            "2021-07-02 00:05:45,438 epoch 37 - iter 144/362 - loss 1.08106570 - samples/sec: 870.92 - lr: 0.100000\n",
            "2021-07-02 00:05:46,852 epoch 37 - iter 180/362 - loss 1.07557419 - samples/sec: 816.37 - lr: 0.100000\n",
            "2021-07-02 00:05:48,217 epoch 37 - iter 216/362 - loss 1.07397677 - samples/sec: 846.09 - lr: 0.100000\n",
            "2021-07-02 00:05:49,571 epoch 37 - iter 252/362 - loss 1.07221919 - samples/sec: 852.95 - lr: 0.100000\n",
            "2021-07-02 00:05:50,912 epoch 37 - iter 288/362 - loss 1.07416161 - samples/sec: 861.23 - lr: 0.100000\n",
            "2021-07-02 00:05:52,260 epoch 37 - iter 324/362 - loss 1.07170609 - samples/sec: 856.52 - lr: 0.100000\n",
            "2021-07-02 00:05:53,698 epoch 37 - iter 360/362 - loss 1.07305912 - samples/sec: 803.33 - lr: 0.100000\n",
            "2021-07-02 00:05:53,779 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:53,780 EPOCH 37 done: loss 1.0725 - lr 0.1000000\n",
            "2021-07-02 00:05:55,215 DEV : loss 1.1188210248947144 - score 0.6395\n",
            "2021-07-02 00:05:55,304 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:05:55,306 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:05:56,689 epoch 38 - iter 36/362 - loss 1.08620453 - samples/sec: 836.57 - lr: 0.100000\n",
            "2021-07-02 00:05:58,054 epoch 38 - iter 72/362 - loss 1.10187454 - samples/sec: 846.09 - lr: 0.100000\n",
            "2021-07-02 00:05:59,453 epoch 38 - iter 108/362 - loss 1.10683400 - samples/sec: 825.48 - lr: 0.100000\n",
            "2021-07-02 00:06:00,822 epoch 38 - iter 144/362 - loss 1.08629053 - samples/sec: 843.28 - lr: 0.100000\n",
            "2021-07-02 00:06:02,364 epoch 38 - iter 180/362 - loss 1.08786997 - samples/sec: 749.07 - lr: 0.100000\n",
            "2021-07-02 00:06:03,762 epoch 38 - iter 216/362 - loss 1.07786877 - samples/sec: 825.52 - lr: 0.100000\n",
            "2021-07-02 00:06:05,164 epoch 38 - iter 252/362 - loss 1.07721412 - samples/sec: 824.33 - lr: 0.100000\n",
            "2021-07-02 00:06:06,549 epoch 38 - iter 288/362 - loss 1.07218000 - samples/sec: 833.65 - lr: 0.100000\n",
            "2021-07-02 00:06:07,908 epoch 38 - iter 324/362 - loss 1.07052926 - samples/sec: 849.96 - lr: 0.100000\n",
            "2021-07-02 00:06:09,336 epoch 38 - iter 360/362 - loss 1.06886310 - samples/sec: 808.56 - lr: 0.100000\n",
            "2021-07-02 00:06:09,433 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:06:09,435 EPOCH 38 done: loss 1.0707 - lr 0.1000000\n",
            "2021-07-02 00:06:10,879 DEV : loss 1.1723276376724243 - score 0.6263\n",
            "2021-07-02 00:06:10,966 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:06:10,967 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:06:12,387 epoch 39 - iter 36/362 - loss 1.08806207 - samples/sec: 814.83 - lr: 0.100000\n",
            "2021-07-02 00:06:13,702 epoch 39 - iter 72/362 - loss 1.08496764 - samples/sec: 878.33 - lr: 0.100000\n",
            "2021-07-02 00:06:15,094 epoch 39 - iter 108/362 - loss 1.06324535 - samples/sec: 829.27 - lr: 0.100000\n",
            "2021-07-02 00:06:16,446 epoch 39 - iter 144/362 - loss 1.05314565 - samples/sec: 854.65 - lr: 0.100000\n",
            "2021-07-02 00:06:17,857 epoch 39 - iter 180/362 - loss 1.05355255 - samples/sec: 818.69 - lr: 0.100000\n",
            "2021-07-02 00:06:19,205 epoch 39 - iter 216/362 - loss 1.05151145 - samples/sec: 856.57 - lr: 0.100000\n",
            "2021-07-02 00:06:20,598 epoch 39 - iter 252/362 - loss 1.04859994 - samples/sec: 828.79 - lr: 0.100000\n",
            "2021-07-02 00:06:21,959 epoch 39 - iter 288/362 - loss 1.05304977 - samples/sec: 849.04 - lr: 0.100000\n",
            "2021-07-02 00:06:23,306 epoch 39 - iter 324/362 - loss 1.05941529 - samples/sec: 857.17 - lr: 0.100000\n",
            "2021-07-02 00:06:24,726 epoch 39 - iter 360/362 - loss 1.05683637 - samples/sec: 812.93 - lr: 0.100000\n",
            "2021-07-02 00:06:24,816 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:06:24,818 EPOCH 39 done: loss 1.0571 - lr 0.1000000\n",
            "2021-07-02 00:06:26,258 DEV : loss 1.141560673713684 - score 0.6418\n",
            "2021-07-02 00:06:26,345 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:06:26,348 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:06:27,744 epoch 40 - iter 36/362 - loss 1.04065535 - samples/sec: 827.85 - lr: 0.100000\n",
            "2021-07-02 00:06:29,087 epoch 40 - iter 72/362 - loss 1.02001591 - samples/sec: 860.69 - lr: 0.100000\n",
            "2021-07-02 00:06:30,451 epoch 40 - iter 108/362 - loss 1.02891972 - samples/sec: 846.58 - lr: 0.100000\n",
            "2021-07-02 00:06:31,769 epoch 40 - iter 144/362 - loss 1.01580478 - samples/sec: 875.86 - lr: 0.100000\n",
            "2021-07-02 00:06:33,167 epoch 40 - iter 180/362 - loss 1.01590418 - samples/sec: 826.84 - lr: 0.100000\n",
            "2021-07-02 00:06:34,535 epoch 40 - iter 216/362 - loss 1.02518651 - samples/sec: 843.85 - lr: 0.100000\n",
            "2021-07-02 00:06:35,931 epoch 40 - iter 252/362 - loss 1.03705558 - samples/sec: 827.08 - lr: 0.100000\n",
            "2021-07-02 00:06:37,282 epoch 40 - iter 288/362 - loss 1.03486333 - samples/sec: 855.47 - lr: 0.100000\n",
            "2021-07-02 00:06:38,694 epoch 40 - iter 324/362 - loss 1.03314655 - samples/sec: 817.73 - lr: 0.100000\n",
            "2021-07-02 00:06:40,153 epoch 40 - iter 360/362 - loss 1.04150557 - samples/sec: 791.50 - lr: 0.100000\n",
            "2021-07-02 00:06:40,238 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:06:40,239 EPOCH 40 done: loss 1.0403 - lr 0.1000000\n",
            "2021-07-02 00:06:41,751 DEV : loss 1.1323083639144897 - score 0.6457\n",
            "2021-07-02 00:06:41,841 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:06:50,612 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:06:51,994 epoch 41 - iter 36/362 - loss 1.04049514 - samples/sec: 836.99 - lr: 0.100000\n",
            "2021-07-02 00:06:53,376 epoch 41 - iter 72/362 - loss 1.04776942 - samples/sec: 835.61 - lr: 0.100000\n",
            "2021-07-02 00:06:54,766 epoch 41 - iter 108/362 - loss 1.05478790 - samples/sec: 831.20 - lr: 0.100000\n",
            "2021-07-02 00:06:56,080 epoch 41 - iter 144/362 - loss 1.04156482 - samples/sec: 878.67 - lr: 0.100000\n",
            "2021-07-02 00:06:57,442 epoch 41 - iter 180/362 - loss 1.04365169 - samples/sec: 847.88 - lr: 0.100000\n",
            "2021-07-02 00:06:58,845 epoch 41 - iter 216/362 - loss 1.03735170 - samples/sec: 822.93 - lr: 0.100000\n",
            "2021-07-02 00:07:00,209 epoch 41 - iter 252/362 - loss 1.03378944 - samples/sec: 846.66 - lr: 0.100000\n",
            "2021-07-02 00:07:01,609 epoch 41 - iter 288/362 - loss 1.04142559 - samples/sec: 825.10 - lr: 0.100000\n",
            "2021-07-02 00:07:02,970 epoch 41 - iter 324/362 - loss 1.04279436 - samples/sec: 848.54 - lr: 0.100000\n",
            "2021-07-02 00:07:04,371 epoch 41 - iter 360/362 - loss 1.04093633 - samples/sec: 823.99 - lr: 0.100000\n",
            "2021-07-02 00:07:04,460 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:04,461 EPOCH 41 done: loss 1.0409 - lr 0.1000000\n",
            "2021-07-02 00:07:05,897 DEV : loss 1.1455167531967163 - score 0.655\n",
            "2021-07-02 00:07:05,984 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-02 00:07:14,855 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:16,312 epoch 42 - iter 36/362 - loss 1.04138955 - samples/sec: 796.79 - lr: 0.100000\n",
            "2021-07-02 00:07:17,700 epoch 42 - iter 72/362 - loss 1.02858853 - samples/sec: 831.96 - lr: 0.100000\n",
            "2021-07-02 00:07:19,069 epoch 42 - iter 108/362 - loss 1.05491884 - samples/sec: 843.82 - lr: 0.100000\n",
            "2021-07-02 00:07:20,469 epoch 42 - iter 144/362 - loss 1.04346530 - samples/sec: 825.25 - lr: 0.100000\n",
            "2021-07-02 00:07:21,863 epoch 42 - iter 180/362 - loss 1.03818567 - samples/sec: 828.12 - lr: 0.100000\n",
            "2021-07-02 00:07:23,224 epoch 42 - iter 216/362 - loss 1.04490751 - samples/sec: 848.94 - lr: 0.100000\n",
            "2021-07-02 00:07:24,600 epoch 42 - iter 252/362 - loss 1.04323844 - samples/sec: 839.50 - lr: 0.100000\n",
            "2021-07-02 00:07:26,002 epoch 42 - iter 288/362 - loss 1.04526844 - samples/sec: 823.72 - lr: 0.100000\n",
            "2021-07-02 00:07:27,338 epoch 42 - iter 324/362 - loss 1.04252185 - samples/sec: 864.41 - lr: 0.100000\n",
            "2021-07-02 00:07:28,807 epoch 42 - iter 360/362 - loss 1.04349000 - samples/sec: 785.96 - lr: 0.100000\n",
            "2021-07-02 00:07:28,885 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:28,887 EPOCH 42 done: loss 1.0444 - lr 0.1000000\n",
            "2021-07-02 00:07:30,323 DEV : loss 1.1808514595031738 - score 0.6309\n",
            "2021-07-02 00:07:30,413 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:07:30,415 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:31,826 epoch 43 - iter 36/362 - loss 1.00252743 - samples/sec: 818.97 - lr: 0.100000\n",
            "2021-07-02 00:07:33,171 epoch 43 - iter 72/362 - loss 1.01634701 - samples/sec: 858.80 - lr: 0.100000\n",
            "2021-07-02 00:07:34,524 epoch 43 - iter 108/362 - loss 1.01376452 - samples/sec: 853.30 - lr: 0.100000\n",
            "2021-07-02 00:07:35,892 epoch 43 - iter 144/362 - loss 1.01366119 - samples/sec: 844.61 - lr: 0.100000\n",
            "2021-07-02 00:07:37,312 epoch 43 - iter 180/362 - loss 1.02117113 - samples/sec: 813.26 - lr: 0.100000\n",
            "2021-07-02 00:07:38,684 epoch 43 - iter 216/362 - loss 1.02877474 - samples/sec: 841.40 - lr: 0.100000\n",
            "2021-07-02 00:07:40,041 epoch 43 - iter 252/362 - loss 1.01604425 - samples/sec: 851.11 - lr: 0.100000\n",
            "2021-07-02 00:07:41,455 epoch 43 - iter 288/362 - loss 1.02147575 - samples/sec: 816.58 - lr: 0.100000\n",
            "2021-07-02 00:07:42,779 epoch 43 - iter 324/362 - loss 1.02175931 - samples/sec: 872.80 - lr: 0.100000\n",
            "2021-07-02 00:07:44,261 epoch 43 - iter 360/362 - loss 1.02282162 - samples/sec: 779.32 - lr: 0.100000\n",
            "2021-07-02 00:07:44,338 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:44,339 EPOCH 43 done: loss 1.0235 - lr 0.1000000\n",
            "2021-07-02 00:07:45,775 DEV : loss 1.1256544589996338 - score 0.6511\n",
            "2021-07-02 00:07:45,864 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:07:45,866 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:47,258 epoch 44 - iter 36/362 - loss 0.93729469 - samples/sec: 830.41 - lr: 0.100000\n",
            "2021-07-02 00:07:48,627 epoch 44 - iter 72/362 - loss 0.98699324 - samples/sec: 843.96 - lr: 0.100000\n",
            "2021-07-02 00:07:49,994 epoch 44 - iter 108/362 - loss 0.98635055 - samples/sec: 844.28 - lr: 0.100000\n",
            "2021-07-02 00:07:51,349 epoch 44 - iter 144/362 - loss 0.99165539 - samples/sec: 852.19 - lr: 0.100000\n",
            "2021-07-02 00:07:52,727 epoch 44 - iter 180/362 - loss 1.00186511 - samples/sec: 838.34 - lr: 0.100000\n",
            "2021-07-02 00:07:54,115 epoch 44 - iter 216/362 - loss 1.00566204 - samples/sec: 831.96 - lr: 0.100000\n",
            "2021-07-02 00:07:55,457 epoch 44 - iter 252/362 - loss 1.01255023 - samples/sec: 861.02 - lr: 0.100000\n",
            "2021-07-02 00:07:56,823 epoch 44 - iter 288/362 - loss 1.00867547 - samples/sec: 845.30 - lr: 0.100000\n",
            "2021-07-02 00:07:58,192 epoch 44 - iter 324/362 - loss 1.01633679 - samples/sec: 843.35 - lr: 0.100000\n",
            "2021-07-02 00:07:59,575 epoch 44 - iter 360/362 - loss 1.01787897 - samples/sec: 834.98 - lr: 0.100000\n",
            "2021-07-02 00:07:59,659 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:07:59,660 EPOCH 44 done: loss 1.0173 - lr 0.1000000\n",
            "2021-07-02 00:08:01,112 DEV : loss 1.1510930061340332 - score 0.6371\n",
            "2021-07-02 00:08:01,200 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:08:01,201 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:02,574 epoch 45 - iter 36/362 - loss 0.96416466 - samples/sec: 842.28 - lr: 0.100000\n",
            "2021-07-02 00:08:03,933 epoch 45 - iter 72/362 - loss 0.98799418 - samples/sec: 850.26 - lr: 0.100000\n",
            "2021-07-02 00:08:05,370 epoch 45 - iter 108/362 - loss 0.98761093 - samples/sec: 803.84 - lr: 0.100000\n",
            "2021-07-02 00:08:06,729 epoch 45 - iter 144/362 - loss 0.99263761 - samples/sec: 849.17 - lr: 0.100000\n",
            "2021-07-02 00:08:08,117 epoch 45 - iter 180/362 - loss 1.00181527 - samples/sec: 832.07 - lr: 0.100000\n",
            "2021-07-02 00:08:09,511 epoch 45 - iter 216/362 - loss 1.00727131 - samples/sec: 828.51 - lr: 0.100000\n",
            "2021-07-02 00:08:10,912 epoch 45 - iter 252/362 - loss 1.00995788 - samples/sec: 824.39 - lr: 0.100000\n",
            "2021-07-02 00:08:12,320 epoch 45 - iter 288/362 - loss 1.00480404 - samples/sec: 820.50 - lr: 0.100000\n",
            "2021-07-02 00:08:13,690 epoch 45 - iter 324/362 - loss 1.01097324 - samples/sec: 843.60 - lr: 0.100000\n",
            "2021-07-02 00:08:15,050 epoch 45 - iter 360/362 - loss 1.01596003 - samples/sec: 848.91 - lr: 0.100000\n",
            "2021-07-02 00:08:15,141 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:15,142 EPOCH 45 done: loss 1.0155 - lr 0.1000000\n",
            "2021-07-02 00:08:16,618 DEV : loss 1.1402772665023804 - score 0.6519\n",
            "2021-07-02 00:08:16,717 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:08:16,720 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:18,178 epoch 46 - iter 36/362 - loss 1.03370037 - samples/sec: 793.39 - lr: 0.100000\n",
            "2021-07-02 00:08:19,550 epoch 46 - iter 72/362 - loss 1.01486471 - samples/sec: 841.78 - lr: 0.100000\n",
            "2021-07-02 00:08:20,917 epoch 46 - iter 108/362 - loss 1.00318462 - samples/sec: 845.29 - lr: 0.100000\n",
            "2021-07-02 00:08:22,296 epoch 46 - iter 144/362 - loss 0.99814188 - samples/sec: 837.20 - lr: 0.100000\n",
            "2021-07-02 00:08:23,677 epoch 46 - iter 180/362 - loss 1.00321878 - samples/sec: 836.32 - lr: 0.100000\n",
            "2021-07-02 00:08:25,038 epoch 46 - iter 216/362 - loss 0.99823901 - samples/sec: 848.40 - lr: 0.100000\n",
            "2021-07-02 00:08:26,432 epoch 46 - iter 252/362 - loss 0.99979397 - samples/sec: 828.46 - lr: 0.100000\n",
            "2021-07-02 00:08:27,807 epoch 46 - iter 288/362 - loss 1.00072606 - samples/sec: 839.89 - lr: 0.100000\n",
            "2021-07-02 00:08:29,173 epoch 46 - iter 324/362 - loss 0.99623832 - samples/sec: 845.33 - lr: 0.100000\n",
            "2021-07-02 00:08:30,583 epoch 46 - iter 360/362 - loss 1.00336055 - samples/sec: 818.97 - lr: 0.100000\n",
            "2021-07-02 00:08:30,655 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:30,656 EPOCH 46 done: loss 1.0033 - lr 0.1000000\n",
            "2021-07-02 00:08:32,098 DEV : loss 1.1540648937225342 - score 0.6348\n",
            "2021-07-02 00:08:32,187 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:08:32,189 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:33,609 epoch 47 - iter 36/362 - loss 0.99653646 - samples/sec: 814.41 - lr: 0.100000\n",
            "2021-07-02 00:08:34,978 epoch 47 - iter 72/362 - loss 0.98650031 - samples/sec: 844.04 - lr: 0.100000\n",
            "2021-07-02 00:08:36,351 epoch 47 - iter 108/362 - loss 0.99136974 - samples/sec: 841.04 - lr: 0.100000\n",
            "2021-07-02 00:08:37,740 epoch 47 - iter 144/362 - loss 0.99407563 - samples/sec: 830.97 - lr: 0.100000\n",
            "2021-07-02 00:08:39,089 epoch 47 - iter 180/362 - loss 1.00249578 - samples/sec: 856.81 - lr: 0.100000\n",
            "2021-07-02 00:08:40,484 epoch 47 - iter 216/362 - loss 0.99773630 - samples/sec: 828.13 - lr: 0.100000\n",
            "2021-07-02 00:08:41,912 epoch 47 - iter 252/362 - loss 0.99681146 - samples/sec: 808.71 - lr: 0.100000\n",
            "2021-07-02 00:08:43,290 epoch 47 - iter 288/362 - loss 1.00192945 - samples/sec: 838.04 - lr: 0.100000\n",
            "2021-07-02 00:08:44,658 epoch 47 - iter 324/362 - loss 1.00105086 - samples/sec: 843.97 - lr: 0.100000\n",
            "2021-07-02 00:08:46,065 epoch 47 - iter 360/362 - loss 1.00540634 - samples/sec: 820.93 - lr: 0.100000\n",
            "2021-07-02 00:08:46,147 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:46,149 EPOCH 47 done: loss 1.0053 - lr 0.1000000\n",
            "2021-07-02 00:08:47,606 DEV : loss 1.1321563720703125 - score 0.6402\n",
            "Epoch    47: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2021-07-02 00:08:47,694 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:08:47,696 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:08:49,043 epoch 48 - iter 36/362 - loss 0.96477280 - samples/sec: 858.36 - lr: 0.050000\n",
            "2021-07-02 00:08:50,534 epoch 48 - iter 72/362 - loss 0.95782664 - samples/sec: 774.49 - lr: 0.050000\n",
            "2021-07-02 00:08:51,947 epoch 48 - iter 108/362 - loss 0.96824120 - samples/sec: 817.35 - lr: 0.050000\n",
            "2021-07-02 00:08:53,324 epoch 48 - iter 144/362 - loss 0.95337458 - samples/sec: 838.57 - lr: 0.050000\n",
            "2021-07-02 00:08:54,704 epoch 48 - iter 180/362 - loss 0.96084196 - samples/sec: 837.18 - lr: 0.050000\n",
            "2021-07-02 00:08:56,058 epoch 48 - iter 216/362 - loss 0.95302034 - samples/sec: 852.91 - lr: 0.050000\n",
            "2021-07-02 00:08:57,437 epoch 48 - iter 252/362 - loss 0.95848817 - samples/sec: 836.93 - lr: 0.050000\n",
            "2021-07-02 00:08:58,791 epoch 48 - iter 288/362 - loss 0.96147972 - samples/sec: 853.36 - lr: 0.050000\n",
            "2021-07-02 00:09:00,120 epoch 48 - iter 324/362 - loss 0.95285408 - samples/sec: 868.50 - lr: 0.050000\n",
            "2021-07-02 00:09:01,539 epoch 48 - iter 360/362 - loss 0.94879253 - samples/sec: 814.08 - lr: 0.050000\n",
            "2021-07-02 00:09:01,621 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:01,622 EPOCH 48 done: loss 0.9490 - lr 0.0500000\n",
            "2021-07-02 00:09:03,054 DEV : loss 1.1503472328186035 - score 0.6441\n",
            "2021-07-02 00:09:03,144 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:09:03,146 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:04,535 epoch 49 - iter 36/362 - loss 0.94763966 - samples/sec: 832.54 - lr: 0.050000\n",
            "2021-07-02 00:09:05,908 epoch 49 - iter 72/362 - loss 0.94308133 - samples/sec: 841.23 - lr: 0.050000\n",
            "2021-07-02 00:09:07,292 epoch 49 - iter 108/362 - loss 0.95423768 - samples/sec: 834.47 - lr: 0.050000\n",
            "2021-07-02 00:09:08,631 epoch 49 - iter 144/362 - loss 0.93996641 - samples/sec: 862.26 - lr: 0.050000\n",
            "2021-07-02 00:09:09,959 epoch 49 - iter 180/362 - loss 0.95681814 - samples/sec: 869.67 - lr: 0.050000\n",
            "2021-07-02 00:09:11,332 epoch 49 - iter 216/362 - loss 0.94383108 - samples/sec: 840.99 - lr: 0.050000\n",
            "2021-07-02 00:09:12,664 epoch 49 - iter 252/362 - loss 0.94017018 - samples/sec: 867.03 - lr: 0.050000\n",
            "2021-07-02 00:09:14,059 epoch 49 - iter 288/362 - loss 0.93829725 - samples/sec: 828.02 - lr: 0.050000\n",
            "2021-07-02 00:09:15,475 epoch 49 - iter 324/362 - loss 0.94164377 - samples/sec: 815.44 - lr: 0.050000\n",
            "2021-07-02 00:09:16,850 epoch 49 - iter 360/362 - loss 0.93951007 - samples/sec: 839.67 - lr: 0.050000\n",
            "2021-07-02 00:09:16,926 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:16,927 EPOCH 49 done: loss 0.9386 - lr 0.0500000\n",
            "2021-07-02 00:09:18,365 DEV : loss 1.1398735046386719 - score 0.6519\n",
            "2021-07-02 00:09:18,452 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:09:18,454 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:19,833 epoch 50 - iter 36/362 - loss 0.89046411 - samples/sec: 839.23 - lr: 0.050000\n",
            "2021-07-02 00:09:21,184 epoch 50 - iter 72/362 - loss 0.89112429 - samples/sec: 854.41 - lr: 0.050000\n",
            "2021-07-02 00:09:22,592 epoch 50 - iter 108/362 - loss 0.91517655 - samples/sec: 820.20 - lr: 0.050000\n",
            "2021-07-02 00:09:24,025 epoch 50 - iter 144/362 - loss 0.90755332 - samples/sec: 806.03 - lr: 0.050000\n",
            "2021-07-02 00:09:25,395 epoch 50 - iter 180/362 - loss 0.91142358 - samples/sec: 843.48 - lr: 0.050000\n",
            "2021-07-02 00:09:26,763 epoch 50 - iter 216/362 - loss 0.91517887 - samples/sec: 843.81 - lr: 0.050000\n",
            "2021-07-02 00:09:28,110 epoch 50 - iter 252/362 - loss 0.91947582 - samples/sec: 857.41 - lr: 0.050000\n",
            "2021-07-02 00:09:29,455 epoch 50 - iter 288/362 - loss 0.92416668 - samples/sec: 858.50 - lr: 0.050000\n",
            "2021-07-02 00:09:30,847 epoch 50 - iter 324/362 - loss 0.92705137 - samples/sec: 829.55 - lr: 0.050000\n",
            "2021-07-02 00:09:32,234 epoch 50 - iter 360/362 - loss 0.93178425 - samples/sec: 832.72 - lr: 0.050000\n",
            "2021-07-02 00:09:32,327 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:32,328 EPOCH 50 done: loss 0.9317 - lr 0.0500000\n",
            "2021-07-02 00:09:33,779 DEV : loss 1.135258436203003 - score 0.6457\n",
            "2021-07-02 00:09:33,868 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:09:33,869 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:35,262 epoch 51 - iter 36/362 - loss 0.93328794 - samples/sec: 831.42 - lr: 0.050000\n",
            "2021-07-02 00:09:36,580 epoch 51 - iter 72/362 - loss 0.93328909 - samples/sec: 876.28 - lr: 0.050000\n",
            "2021-07-02 00:09:37,975 epoch 51 - iter 108/362 - loss 0.91838606 - samples/sec: 827.25 - lr: 0.050000\n",
            "2021-07-02 00:09:39,388 epoch 51 - iter 144/362 - loss 0.93186820 - samples/sec: 817.94 - lr: 0.050000\n",
            "2021-07-02 00:09:40,768 epoch 51 - iter 180/362 - loss 0.93034694 - samples/sec: 836.78 - lr: 0.050000\n",
            "2021-07-02 00:09:42,214 epoch 51 - iter 216/362 - loss 0.92333012 - samples/sec: 798.58 - lr: 0.050000\n",
            "2021-07-02 00:09:43,599 epoch 51 - iter 252/362 - loss 0.92789339 - samples/sec: 834.19 - lr: 0.050000\n",
            "2021-07-02 00:09:44,948 epoch 51 - iter 288/362 - loss 0.92712986 - samples/sec: 855.98 - lr: 0.050000\n",
            "2021-07-02 00:09:46,303 epoch 51 - iter 324/362 - loss 0.93509440 - samples/sec: 851.99 - lr: 0.050000\n",
            "2021-07-02 00:09:47,739 epoch 51 - iter 360/362 - loss 0.93147987 - samples/sec: 804.17 - lr: 0.050000\n",
            "2021-07-02 00:09:47,826 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:47,828 EPOCH 51 done: loss 0.9311 - lr 0.0500000\n",
            "2021-07-02 00:09:49,263 DEV : loss 1.1634728908538818 - score 0.641\n",
            "2021-07-02 00:09:49,350 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:09:49,352 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:09:50,736 epoch 52 - iter 36/362 - loss 0.91581129 - samples/sec: 836.29 - lr: 0.050000\n",
            "2021-07-02 00:09:52,065 epoch 52 - iter 72/362 - loss 0.90623755 - samples/sec: 868.84 - lr: 0.050000\n",
            "2021-07-02 00:09:53,460 epoch 52 - iter 108/362 - loss 0.91271586 - samples/sec: 827.84 - lr: 0.050000\n",
            "2021-07-02 00:09:54,897 epoch 52 - iter 144/362 - loss 0.91250674 - samples/sec: 803.91 - lr: 0.050000\n",
            "2021-07-02 00:09:56,290 epoch 52 - iter 180/362 - loss 0.90865815 - samples/sec: 828.49 - lr: 0.050000\n",
            "2021-07-02 00:09:57,670 epoch 52 - iter 216/362 - loss 0.91063678 - samples/sec: 837.22 - lr: 0.050000\n",
            "2021-07-02 00:09:59,048 epoch 52 - iter 252/362 - loss 0.91187613 - samples/sec: 838.47 - lr: 0.050000\n",
            "2021-07-02 00:10:00,449 epoch 52 - iter 288/362 - loss 0.90433489 - samples/sec: 824.34 - lr: 0.050000\n",
            "2021-07-02 00:10:01,853 epoch 52 - iter 324/362 - loss 0.90461361 - samples/sec: 822.50 - lr: 0.050000\n",
            "2021-07-02 00:10:03,266 epoch 52 - iter 360/362 - loss 0.90333815 - samples/sec: 817.62 - lr: 0.050000\n",
            "2021-07-02 00:10:03,361 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:03,362 EPOCH 52 done: loss 0.9034 - lr 0.0500000\n",
            "2021-07-02 00:10:04,818 DEV : loss 1.1731055974960327 - score 0.6519\n",
            "2021-07-02 00:10:04,907 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:10:04,909 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:06,315 epoch 53 - iter 36/362 - loss 0.84756535 - samples/sec: 822.54 - lr: 0.050000\n",
            "2021-07-02 00:10:07,678 epoch 53 - iter 72/362 - loss 0.87878536 - samples/sec: 847.35 - lr: 0.050000\n",
            "2021-07-02 00:10:09,070 epoch 53 - iter 108/362 - loss 0.88610838 - samples/sec: 829.74 - lr: 0.050000\n",
            "2021-07-02 00:10:10,470 epoch 53 - iter 144/362 - loss 0.88770518 - samples/sec: 824.89 - lr: 0.050000\n",
            "2021-07-02 00:10:11,851 epoch 53 - iter 180/362 - loss 0.89224600 - samples/sec: 836.21 - lr: 0.050000\n",
            "2021-07-02 00:10:13,226 epoch 53 - iter 216/362 - loss 0.90234208 - samples/sec: 839.72 - lr: 0.050000\n",
            "2021-07-02 00:10:14,560 epoch 53 - iter 252/362 - loss 0.90530502 - samples/sec: 865.99 - lr: 0.050000\n",
            "2021-07-02 00:10:15,952 epoch 53 - iter 288/362 - loss 0.90340119 - samples/sec: 829.11 - lr: 0.050000\n",
            "2021-07-02 00:10:18,405 epoch 53 - iter 324/362 - loss 0.90430052 - samples/sec: 470.29 - lr: 0.050000\n",
            "2021-07-02 00:10:19,784 epoch 53 - iter 360/362 - loss 0.90037842 - samples/sec: 837.47 - lr: 0.050000\n",
            "2021-07-02 00:10:19,857 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:19,858 EPOCH 53 done: loss 0.9012 - lr 0.0500000\n",
            "2021-07-02 00:10:21,309 DEV : loss 1.1510170698165894 - score 0.6434\n",
            "Epoch    53: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2021-07-02 00:10:21,397 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:10:21,400 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:22,782 epoch 54 - iter 36/362 - loss 0.90871707 - samples/sec: 836.45 - lr: 0.025000\n",
            "2021-07-02 00:10:24,171 epoch 54 - iter 72/362 - loss 0.89926767 - samples/sec: 831.28 - lr: 0.025000\n",
            "2021-07-02 00:10:25,532 epoch 54 - iter 108/362 - loss 0.88382416 - samples/sec: 849.19 - lr: 0.025000\n",
            "2021-07-02 00:10:26,883 epoch 54 - iter 144/362 - loss 0.87817716 - samples/sec: 854.86 - lr: 0.025000\n",
            "2021-07-02 00:10:28,272 epoch 54 - iter 180/362 - loss 0.88280753 - samples/sec: 832.04 - lr: 0.025000\n",
            "2021-07-02 00:10:29,732 epoch 54 - iter 216/362 - loss 0.87759276 - samples/sec: 791.12 - lr: 0.025000\n",
            "2021-07-02 00:10:31,076 epoch 54 - iter 252/362 - loss 0.87340237 - samples/sec: 859.21 - lr: 0.025000\n",
            "2021-07-02 00:10:32,450 epoch 54 - iter 288/362 - loss 0.87485712 - samples/sec: 840.47 - lr: 0.025000\n",
            "2021-07-02 00:10:33,834 epoch 54 - iter 324/362 - loss 0.88272671 - samples/sec: 834.48 - lr: 0.025000\n",
            "2021-07-02 00:10:35,298 epoch 54 - iter 360/362 - loss 0.88750657 - samples/sec: 788.56 - lr: 0.025000\n",
            "2021-07-02 00:10:35,385 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:35,386 EPOCH 54 done: loss 0.8872 - lr 0.0250000\n",
            "2021-07-02 00:10:36,847 DEV : loss 1.1426982879638672 - score 0.6503\n",
            "2021-07-02 00:10:36,936 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:10:36,939 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:38,394 epoch 55 - iter 36/362 - loss 0.85464375 - samples/sec: 794.99 - lr: 0.025000\n",
            "2021-07-02 00:10:39,787 epoch 55 - iter 72/362 - loss 0.89213796 - samples/sec: 829.03 - lr: 0.025000\n",
            "2021-07-02 00:10:41,147 epoch 55 - iter 108/362 - loss 0.84779478 - samples/sec: 848.84 - lr: 0.025000\n",
            "2021-07-02 00:10:42,512 epoch 55 - iter 144/362 - loss 0.84633876 - samples/sec: 845.99 - lr: 0.025000\n",
            "2021-07-02 00:10:43,945 epoch 55 - iter 180/362 - loss 0.85360429 - samples/sec: 806.00 - lr: 0.025000\n",
            "2021-07-02 00:10:45,260 epoch 55 - iter 216/362 - loss 0.85205833 - samples/sec: 877.91 - lr: 0.025000\n",
            "2021-07-02 00:10:46,623 epoch 55 - iter 252/362 - loss 0.85935301 - samples/sec: 847.46 - lr: 0.025000\n",
            "2021-07-02 00:10:48,023 epoch 55 - iter 288/362 - loss 0.85861543 - samples/sec: 825.30 - lr: 0.025000\n",
            "2021-07-02 00:10:49,381 epoch 55 - iter 324/362 - loss 0.86532403 - samples/sec: 850.53 - lr: 0.025000\n",
            "2021-07-02 00:10:50,819 epoch 55 - iter 360/362 - loss 0.86434132 - samples/sec: 802.97 - lr: 0.025000\n",
            "2021-07-02 00:10:50,908 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:50,910 EPOCH 55 done: loss 0.8643 - lr 0.0250000\n",
            "2021-07-02 00:10:52,361 DEV : loss 1.1627602577209473 - score 0.648\n",
            "2021-07-02 00:10:52,451 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:10:52,452 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:10:53,856 epoch 56 - iter 36/362 - loss 0.85301605 - samples/sec: 823.96 - lr: 0.025000\n",
            "2021-07-02 00:10:55,212 epoch 56 - iter 72/362 - loss 0.85586901 - samples/sec: 851.76 - lr: 0.025000\n",
            "2021-07-02 00:10:56,742 epoch 56 - iter 108/362 - loss 0.84829754 - samples/sec: 755.02 - lr: 0.025000\n",
            "2021-07-02 00:10:58,093 epoch 56 - iter 144/362 - loss 0.86416374 - samples/sec: 855.69 - lr: 0.025000\n",
            "2021-07-02 00:10:59,545 epoch 56 - iter 180/362 - loss 0.85595231 - samples/sec: 794.93 - lr: 0.025000\n",
            "2021-07-02 00:11:00,925 epoch 56 - iter 216/362 - loss 0.84355201 - samples/sec: 837.09 - lr: 0.025000\n",
            "2021-07-02 00:11:02,345 epoch 56 - iter 252/362 - loss 0.84487285 - samples/sec: 813.58 - lr: 0.025000\n",
            "2021-07-02 00:11:03,791 epoch 56 - iter 288/362 - loss 0.84967845 - samples/sec: 798.29 - lr: 0.025000\n",
            "2021-07-02 00:11:05,195 epoch 56 - iter 324/362 - loss 0.85334440 - samples/sec: 822.90 - lr: 0.025000\n",
            "2021-07-02 00:11:06,612 epoch 56 - iter 360/362 - loss 0.85886715 - samples/sec: 814.77 - lr: 0.025000\n",
            "2021-07-02 00:11:06,689 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:06,691 EPOCH 56 done: loss 0.8575 - lr 0.0250000\n",
            "2021-07-02 00:11:08,177 DEV : loss 1.157585620880127 - score 0.6472\n",
            "2021-07-02 00:11:08,268 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:11:08,270 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:09,717 epoch 57 - iter 36/362 - loss 0.88752660 - samples/sec: 799.33 - lr: 0.025000\n",
            "2021-07-02 00:11:11,127 epoch 57 - iter 72/362 - loss 0.87024089 - samples/sec: 819.07 - lr: 0.025000\n",
            "2021-07-02 00:11:12,554 epoch 57 - iter 108/362 - loss 0.86491202 - samples/sec: 809.95 - lr: 0.025000\n",
            "2021-07-02 00:11:13,984 epoch 57 - iter 144/362 - loss 0.86167209 - samples/sec: 807.37 - lr: 0.025000\n",
            "2021-07-02 00:11:15,410 epoch 57 - iter 180/362 - loss 0.86142538 - samples/sec: 809.93 - lr: 0.025000\n",
            "2021-07-02 00:11:16,803 epoch 57 - iter 216/362 - loss 0.86004704 - samples/sec: 829.29 - lr: 0.025000\n",
            "2021-07-02 00:11:18,134 epoch 57 - iter 252/362 - loss 0.85929990 - samples/sec: 867.61 - lr: 0.025000\n",
            "2021-07-02 00:11:19,523 epoch 57 - iter 288/362 - loss 0.86106346 - samples/sec: 831.15 - lr: 0.025000\n",
            "2021-07-02 00:11:20,912 epoch 57 - iter 324/362 - loss 0.85927368 - samples/sec: 832.08 - lr: 0.025000\n",
            "2021-07-02 00:11:22,372 epoch 57 - iter 360/362 - loss 0.86215597 - samples/sec: 790.68 - lr: 0.025000\n",
            "2021-07-02 00:11:22,470 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:22,471 EPOCH 57 done: loss 0.8627 - lr 0.0250000\n",
            "2021-07-02 00:11:23,947 DEV : loss 1.1286332607269287 - score 0.6418\n",
            "2021-07-02 00:11:24,037 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:11:24,039 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:25,452 epoch 58 - iter 36/362 - loss 0.84922913 - samples/sec: 818.61 - lr: 0.025000\n",
            "2021-07-02 00:11:26,820 epoch 58 - iter 72/362 - loss 0.83252650 - samples/sec: 843.88 - lr: 0.025000\n",
            "2021-07-02 00:11:28,231 epoch 58 - iter 108/362 - loss 0.84009041 - samples/sec: 818.78 - lr: 0.025000\n",
            "2021-07-02 00:11:29,650 epoch 58 - iter 144/362 - loss 0.85068281 - samples/sec: 814.00 - lr: 0.025000\n",
            "2021-07-02 00:11:31,089 epoch 58 - iter 180/362 - loss 0.83770435 - samples/sec: 802.21 - lr: 0.025000\n",
            "2021-07-02 00:11:32,515 epoch 58 - iter 216/362 - loss 0.83946567 - samples/sec: 810.28 - lr: 0.025000\n",
            "2021-07-02 00:11:33,874 epoch 58 - iter 252/362 - loss 0.84022813 - samples/sec: 849.35 - lr: 0.025000\n",
            "2021-07-02 00:11:35,357 epoch 58 - iter 288/362 - loss 0.84772196 - samples/sec: 778.92 - lr: 0.025000\n",
            "2021-07-02 00:11:36,757 epoch 58 - iter 324/362 - loss 0.85520168 - samples/sec: 825.12 - lr: 0.025000\n",
            "2021-07-02 00:11:38,158 epoch 58 - iter 360/362 - loss 0.86287385 - samples/sec: 824.17 - lr: 0.025000\n",
            "2021-07-02 00:11:38,240 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:38,241 EPOCH 58 done: loss 0.8636 - lr 0.0250000\n",
            "2021-07-02 00:11:39,716 DEV : loss 1.1356871128082275 - score 0.6488\n",
            "2021-07-02 00:11:39,806 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:11:39,808 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:41,241 epoch 59 - iter 36/362 - loss 0.81315765 - samples/sec: 807.15 - lr: 0.025000\n",
            "2021-07-02 00:11:42,727 epoch 59 - iter 72/362 - loss 0.82205495 - samples/sec: 777.27 - lr: 0.025000\n",
            "2021-07-02 00:11:44,113 epoch 59 - iter 108/362 - loss 0.84198189 - samples/sec: 833.52 - lr: 0.025000\n",
            "2021-07-02 00:11:45,519 epoch 59 - iter 144/362 - loss 0.84989585 - samples/sec: 821.14 - lr: 0.025000\n",
            "2021-07-02 00:11:46,913 epoch 59 - iter 180/362 - loss 0.84614137 - samples/sec: 828.46 - lr: 0.025000\n",
            "2021-07-02 00:11:48,295 epoch 59 - iter 216/362 - loss 0.84736831 - samples/sec: 836.23 - lr: 0.025000\n",
            "2021-07-02 00:11:49,680 epoch 59 - iter 252/362 - loss 0.85713451 - samples/sec: 833.71 - lr: 0.025000\n",
            "2021-07-02 00:11:51,039 epoch 59 - iter 288/362 - loss 0.85667859 - samples/sec: 849.98 - lr: 0.025000\n",
            "2021-07-02 00:11:52,375 epoch 59 - iter 324/362 - loss 0.85971405 - samples/sec: 863.96 - lr: 0.025000\n",
            "2021-07-02 00:11:53,768 epoch 59 - iter 360/362 - loss 0.85967505 - samples/sec: 829.77 - lr: 0.025000\n",
            "2021-07-02 00:11:53,857 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:53,859 EPOCH 59 done: loss 0.8590 - lr 0.0250000\n",
            "2021-07-02 00:11:55,308 DEV : loss 1.1374859809875488 - score 0.6519\n",
            "Epoch    59: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2021-07-02 00:11:55,398 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:11:55,400 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:11:56,745 epoch 60 - iter 36/362 - loss 0.83543873 - samples/sec: 860.46 - lr: 0.012500\n",
            "2021-07-02 00:11:58,099 epoch 60 - iter 72/362 - loss 0.81920168 - samples/sec: 853.48 - lr: 0.012500\n",
            "2021-07-02 00:11:59,461 epoch 60 - iter 108/362 - loss 0.84943141 - samples/sec: 847.57 - lr: 0.012500\n",
            "2021-07-02 00:12:00,868 epoch 60 - iter 144/362 - loss 0.84015266 - samples/sec: 821.43 - lr: 0.012500\n",
            "2021-07-02 00:12:02,258 epoch 60 - iter 180/362 - loss 0.84161472 - samples/sec: 830.53 - lr: 0.012500\n",
            "2021-07-02 00:12:03,654 epoch 60 - iter 216/362 - loss 0.84076427 - samples/sec: 827.66 - lr: 0.012500\n",
            "2021-07-02 00:12:05,052 epoch 60 - iter 252/362 - loss 0.83857638 - samples/sec: 826.27 - lr: 0.012500\n",
            "2021-07-02 00:12:06,445 epoch 60 - iter 288/362 - loss 0.83804032 - samples/sec: 828.63 - lr: 0.012500\n",
            "2021-07-02 00:12:07,886 epoch 60 - iter 324/362 - loss 0.84288547 - samples/sec: 801.79 - lr: 0.012500\n",
            "2021-07-02 00:12:09,407 epoch 60 - iter 360/362 - loss 0.84605219 - samples/sec: 759.14 - lr: 0.012500\n",
            "2021-07-02 00:12:09,493 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:09,495 EPOCH 60 done: loss 0.8457 - lr 0.0125000\n",
            "2021-07-02 00:12:10,948 DEV : loss 1.1539416313171387 - score 0.648\n",
            "2021-07-02 00:12:11,036 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:12:11,038 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:12,458 epoch 61 - iter 36/362 - loss 0.87255359 - samples/sec: 814.42 - lr: 0.012500\n",
            "2021-07-02 00:12:13,823 epoch 61 - iter 72/362 - loss 0.83894564 - samples/sec: 845.86 - lr: 0.012500\n",
            "2021-07-02 00:12:15,198 epoch 61 - iter 108/362 - loss 0.81840278 - samples/sec: 839.67 - lr: 0.012500\n",
            "2021-07-02 00:12:16,559 epoch 61 - iter 144/362 - loss 0.82203891 - samples/sec: 848.82 - lr: 0.012500\n",
            "2021-07-02 00:12:17,915 epoch 61 - iter 180/362 - loss 0.82733947 - samples/sec: 851.20 - lr: 0.012500\n",
            "2021-07-02 00:12:19,291 epoch 61 - iter 216/362 - loss 0.83063493 - samples/sec: 839.48 - lr: 0.012500\n",
            "2021-07-02 00:12:20,641 epoch 61 - iter 252/362 - loss 0.83885886 - samples/sec: 855.59 - lr: 0.012500\n",
            "2021-07-02 00:12:22,047 epoch 61 - iter 288/362 - loss 0.83206259 - samples/sec: 821.57 - lr: 0.012500\n",
            "2021-07-02 00:12:23,399 epoch 61 - iter 324/362 - loss 0.83003536 - samples/sec: 853.78 - lr: 0.012500\n",
            "2021-07-02 00:12:24,825 epoch 61 - iter 360/362 - loss 0.83219645 - samples/sec: 809.96 - lr: 0.012500\n",
            "2021-07-02 00:12:24,910 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:24,911 EPOCH 61 done: loss 0.8321 - lr 0.0125000\n",
            "2021-07-02 00:12:26,354 DEV : loss 1.1460933685302734 - score 0.6496\n",
            "2021-07-02 00:12:26,445 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:12:26,449 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:27,831 epoch 62 - iter 36/362 - loss 0.79262923 - samples/sec: 836.71 - lr: 0.012500\n",
            "2021-07-02 00:12:29,214 epoch 62 - iter 72/362 - loss 0.81269416 - samples/sec: 835.09 - lr: 0.012500\n",
            "2021-07-02 00:12:30,581 epoch 62 - iter 108/362 - loss 0.82622804 - samples/sec: 844.76 - lr: 0.012500\n",
            "2021-07-02 00:12:31,961 epoch 62 - iter 144/362 - loss 0.82874093 - samples/sec: 836.93 - lr: 0.012500\n",
            "2021-07-02 00:12:33,353 epoch 62 - iter 180/362 - loss 0.82700099 - samples/sec: 829.38 - lr: 0.012500\n",
            "2021-07-02 00:12:34,764 epoch 62 - iter 216/362 - loss 0.82886447 - samples/sec: 819.14 - lr: 0.012500\n",
            "2021-07-02 00:12:36,150 epoch 62 - iter 252/362 - loss 0.83108811 - samples/sec: 833.20 - lr: 0.012500\n",
            "2021-07-02 00:12:37,532 epoch 62 - iter 288/362 - loss 0.83629343 - samples/sec: 835.36 - lr: 0.012500\n",
            "2021-07-02 00:12:38,933 epoch 62 - iter 324/362 - loss 0.83521853 - samples/sec: 824.97 - lr: 0.012500\n",
            "2021-07-02 00:12:40,370 epoch 62 - iter 360/362 - loss 0.83265320 - samples/sec: 803.57 - lr: 0.012500\n",
            "2021-07-02 00:12:40,463 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:40,464 EPOCH 62 done: loss 0.8329 - lr 0.0125000\n",
            "2021-07-02 00:12:41,948 DEV : loss 1.164973497390747 - score 0.648\n",
            "2021-07-02 00:12:42,039 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:12:42,041 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:43,423 epoch 63 - iter 36/362 - loss 0.82688662 - samples/sec: 836.65 - lr: 0.012500\n",
            "2021-07-02 00:12:44,815 epoch 63 - iter 72/362 - loss 0.82634306 - samples/sec: 829.68 - lr: 0.012500\n",
            "2021-07-02 00:12:46,211 epoch 63 - iter 108/362 - loss 0.83466155 - samples/sec: 827.38 - lr: 0.012500\n",
            "2021-07-02 00:12:47,595 epoch 63 - iter 144/362 - loss 0.82557856 - samples/sec: 834.41 - lr: 0.012500\n",
            "2021-07-02 00:12:48,936 epoch 63 - iter 180/362 - loss 0.81892781 - samples/sec: 861.43 - lr: 0.012500\n",
            "2021-07-02 00:12:50,290 epoch 63 - iter 216/362 - loss 0.83421923 - samples/sec: 852.56 - lr: 0.012500\n",
            "2021-07-02 00:12:51,672 epoch 63 - iter 252/362 - loss 0.84202831 - samples/sec: 835.87 - lr: 0.012500\n",
            "2021-07-02 00:12:53,053 epoch 63 - iter 288/362 - loss 0.83945898 - samples/sec: 836.23 - lr: 0.012500\n",
            "2021-07-02 00:12:54,416 epoch 63 - iter 324/362 - loss 0.84001154 - samples/sec: 846.98 - lr: 0.012500\n",
            "2021-07-02 00:12:55,840 epoch 63 - iter 360/362 - loss 0.83450423 - samples/sec: 812.17 - lr: 0.012500\n",
            "2021-07-02 00:12:55,920 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:55,921 EPOCH 63 done: loss 0.8348 - lr 0.0125000\n",
            "2021-07-02 00:12:57,377 DEV : loss 1.1521670818328857 - score 0.6488\n",
            "2021-07-02 00:12:57,466 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:12:57,467 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:12:58,810 epoch 64 - iter 36/362 - loss 0.79685193 - samples/sec: 861.26 - lr: 0.012500\n",
            "2021-07-02 00:13:00,226 epoch 64 - iter 72/362 - loss 0.85202943 - samples/sec: 815.58 - lr: 0.012500\n",
            "2021-07-02 00:13:01,588 epoch 64 - iter 108/362 - loss 0.86592718 - samples/sec: 847.81 - lr: 0.012500\n",
            "2021-07-02 00:13:03,005 epoch 64 - iter 144/362 - loss 0.84417042 - samples/sec: 815.16 - lr: 0.012500\n",
            "2021-07-02 00:13:04,376 epoch 64 - iter 180/362 - loss 0.82768930 - samples/sec: 842.27 - lr: 0.012500\n",
            "2021-07-02 00:13:05,732 epoch 64 - iter 216/362 - loss 0.82750611 - samples/sec: 852.05 - lr: 0.012500\n",
            "2021-07-02 00:13:07,122 epoch 64 - iter 252/362 - loss 0.83239165 - samples/sec: 830.51 - lr: 0.012500\n",
            "2021-07-02 00:13:08,497 epoch 64 - iter 288/362 - loss 0.83183954 - samples/sec: 839.91 - lr: 0.012500\n",
            "2021-07-02 00:13:09,838 epoch 64 - iter 324/362 - loss 0.82922385 - samples/sec: 861.56 - lr: 0.012500\n",
            "2021-07-02 00:13:11,206 epoch 64 - iter 360/362 - loss 0.82871207 - samples/sec: 844.14 - lr: 0.012500\n",
            "2021-07-02 00:13:11,295 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:11,296 EPOCH 64 done: loss 0.8299 - lr 0.0125000\n",
            "2021-07-02 00:13:12,730 DEV : loss 1.157860279083252 - score 0.6449\n",
            "2021-07-02 00:13:12,818 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:13:12,820 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:14,271 epoch 65 - iter 36/362 - loss 0.80631807 - samples/sec: 797.05 - lr: 0.012500\n",
            "2021-07-02 00:13:15,682 epoch 65 - iter 72/362 - loss 0.82549434 - samples/sec: 818.03 - lr: 0.012500\n",
            "2021-07-02 00:13:17,096 epoch 65 - iter 108/362 - loss 0.79694580 - samples/sec: 817.08 - lr: 0.012500\n",
            "2021-07-02 00:13:18,484 epoch 65 - iter 144/362 - loss 0.81562417 - samples/sec: 832.18 - lr: 0.012500\n",
            "2021-07-02 00:13:19,910 epoch 65 - iter 180/362 - loss 0.81394461 - samples/sec: 810.13 - lr: 0.012500\n",
            "2021-07-02 00:13:21,337 epoch 65 - iter 216/362 - loss 0.81009480 - samples/sec: 809.08 - lr: 0.012500\n",
            "2021-07-02 00:13:22,726 epoch 65 - iter 252/362 - loss 0.81498346 - samples/sec: 831.10 - lr: 0.012500\n",
            "2021-07-02 00:13:24,127 epoch 65 - iter 288/362 - loss 0.82317484 - samples/sec: 824.68 - lr: 0.012500\n",
            "2021-07-02 00:13:25,486 epoch 65 - iter 324/362 - loss 0.82005641 - samples/sec: 849.33 - lr: 0.012500\n",
            "2021-07-02 00:13:26,873 epoch 65 - iter 360/362 - loss 0.81925154 - samples/sec: 832.68 - lr: 0.012500\n",
            "2021-07-02 00:13:26,948 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:26,949 EPOCH 65 done: loss 0.8206 - lr 0.0125000\n",
            "2021-07-02 00:13:28,397 DEV : loss 1.1699578762054443 - score 0.648\n",
            "Epoch    65: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2021-07-02 00:13:28,486 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:13:28,488 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:29,893 epoch 66 - iter 36/362 - loss 0.90749498 - samples/sec: 823.23 - lr: 0.006250\n",
            "2021-07-02 00:13:31,256 epoch 66 - iter 72/362 - loss 0.84721227 - samples/sec: 847.57 - lr: 0.006250\n",
            "2021-07-02 00:13:32,619 epoch 66 - iter 108/362 - loss 0.82063967 - samples/sec: 847.10 - lr: 0.006250\n",
            "2021-07-02 00:13:33,980 epoch 66 - iter 144/362 - loss 0.81067128 - samples/sec: 848.23 - lr: 0.006250\n",
            "2021-07-02 00:13:35,330 epoch 66 - iter 180/362 - loss 0.82065673 - samples/sec: 855.83 - lr: 0.006250\n",
            "2021-07-02 00:13:36,692 epoch 66 - iter 216/362 - loss 0.80954547 - samples/sec: 847.88 - lr: 0.006250\n",
            "2021-07-02 00:13:38,085 epoch 66 - iter 252/362 - loss 0.80949773 - samples/sec: 828.94 - lr: 0.006250\n",
            "2021-07-02 00:13:39,457 epoch 66 - iter 288/362 - loss 0.80753216 - samples/sec: 841.31 - lr: 0.006250\n",
            "2021-07-02 00:13:40,826 epoch 66 - iter 324/362 - loss 0.81519927 - samples/sec: 843.97 - lr: 0.006250\n",
            "2021-07-02 00:13:42,264 epoch 66 - iter 360/362 - loss 0.81226163 - samples/sec: 802.78 - lr: 0.006250\n",
            "2021-07-02 00:13:42,362 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:42,363 EPOCH 66 done: loss 0.8133 - lr 0.0062500\n",
            "2021-07-02 00:13:43,830 DEV : loss 1.1522645950317383 - score 0.6472\n",
            "2021-07-02 00:13:43,917 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:13:43,919 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:45,407 epoch 67 - iter 36/362 - loss 0.78309450 - samples/sec: 776.50 - lr: 0.006250\n",
            "2021-07-02 00:13:46,837 epoch 67 - iter 72/362 - loss 0.81643560 - samples/sec: 807.55 - lr: 0.006250\n",
            "2021-07-02 00:13:48,316 epoch 67 - iter 108/362 - loss 0.81008533 - samples/sec: 780.93 - lr: 0.006250\n",
            "2021-07-02 00:13:49,680 epoch 67 - iter 144/362 - loss 0.80633870 - samples/sec: 846.41 - lr: 0.006250\n",
            "2021-07-02 00:13:51,040 epoch 67 - iter 180/362 - loss 0.80485153 - samples/sec: 849.36 - lr: 0.006250\n",
            "2021-07-02 00:13:52,339 epoch 67 - iter 216/362 - loss 0.79514906 - samples/sec: 889.32 - lr: 0.006250\n",
            "2021-07-02 00:13:53,742 epoch 67 - iter 252/362 - loss 0.79151677 - samples/sec: 822.86 - lr: 0.006250\n",
            "2021-07-02 00:13:55,066 epoch 67 - iter 288/362 - loss 0.79828569 - samples/sec: 872.69 - lr: 0.006250\n",
            "2021-07-02 00:13:56,456 epoch 67 - iter 324/362 - loss 0.79785004 - samples/sec: 830.79 - lr: 0.006250\n",
            "2021-07-02 00:13:57,819 epoch 67 - iter 360/362 - loss 0.79797669 - samples/sec: 847.14 - lr: 0.006250\n",
            "2021-07-02 00:13:57,905 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:13:57,906 EPOCH 67 done: loss 0.7986 - lr 0.0062500\n",
            "2021-07-02 00:13:59,352 DEV : loss 1.1660536527633667 - score 0.6519\n",
            "2021-07-02 00:13:59,440 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:13:59,444 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:00,806 epoch 68 - iter 36/362 - loss 0.88810935 - samples/sec: 848.84 - lr: 0.006250\n",
            "2021-07-02 00:14:02,147 epoch 68 - iter 72/362 - loss 0.83278526 - samples/sec: 861.40 - lr: 0.006250\n",
            "2021-07-02 00:14:03,559 epoch 68 - iter 108/362 - loss 0.82324145 - samples/sec: 817.86 - lr: 0.006250\n",
            "2021-07-02 00:14:04,948 epoch 68 - iter 144/362 - loss 0.82005648 - samples/sec: 831.09 - lr: 0.006250\n",
            "2021-07-02 00:14:06,362 epoch 68 - iter 180/362 - loss 0.81126669 - samples/sec: 816.94 - lr: 0.006250\n",
            "2021-07-02 00:14:07,785 epoch 68 - iter 216/362 - loss 0.81539050 - samples/sec: 812.66 - lr: 0.006250\n",
            "2021-07-02 00:14:09,219 epoch 68 - iter 252/362 - loss 0.81716880 - samples/sec: 805.33 - lr: 0.006250\n",
            "2021-07-02 00:14:10,631 epoch 68 - iter 288/362 - loss 0.81559214 - samples/sec: 818.17 - lr: 0.006250\n",
            "2021-07-02 00:14:12,028 epoch 68 - iter 324/362 - loss 0.81815101 - samples/sec: 826.84 - lr: 0.006250\n",
            "2021-07-02 00:14:13,466 epoch 68 - iter 360/362 - loss 0.81246969 - samples/sec: 803.38 - lr: 0.006250\n",
            "2021-07-02 00:14:13,551 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:13,552 EPOCH 68 done: loss 0.8124 - lr 0.0062500\n",
            "2021-07-02 00:14:15,009 DEV : loss 1.168677568435669 - score 0.6449\n",
            "2021-07-02 00:14:15,099 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:14:15,101 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:16,501 epoch 69 - iter 36/362 - loss 0.81986305 - samples/sec: 825.67 - lr: 0.006250\n",
            "2021-07-02 00:14:17,853 epoch 69 - iter 72/362 - loss 0.80572285 - samples/sec: 854.30 - lr: 0.006250\n",
            "2021-07-02 00:14:19,221 epoch 69 - iter 108/362 - loss 0.79688609 - samples/sec: 844.03 - lr: 0.006250\n",
            "2021-07-02 00:14:20,649 epoch 69 - iter 144/362 - loss 0.80843560 - samples/sec: 809.02 - lr: 0.006250\n",
            "2021-07-02 00:14:22,023 epoch 69 - iter 180/362 - loss 0.82012776 - samples/sec: 840.41 - lr: 0.006250\n",
            "2021-07-02 00:14:23,430 epoch 69 - iter 216/362 - loss 0.80904100 - samples/sec: 820.47 - lr: 0.006250\n",
            "2021-07-02 00:14:24,812 epoch 69 - iter 252/362 - loss 0.80916474 - samples/sec: 836.34 - lr: 0.006250\n",
            "2021-07-02 00:14:26,190 epoch 69 - iter 288/362 - loss 0.80196343 - samples/sec: 838.00 - lr: 0.006250\n",
            "2021-07-02 00:14:27,547 epoch 69 - iter 324/362 - loss 0.79964407 - samples/sec: 850.70 - lr: 0.006250\n",
            "2021-07-02 00:14:28,968 epoch 69 - iter 360/362 - loss 0.80278413 - samples/sec: 812.79 - lr: 0.006250\n",
            "2021-07-02 00:14:29,047 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:29,048 EPOCH 69 done: loss 0.8045 - lr 0.0062500\n",
            "2021-07-02 00:14:30,492 DEV : loss 1.169755458831787 - score 0.648\n",
            "2021-07-02 00:14:30,579 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:14:30,581 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:32,004 epoch 70 - iter 36/362 - loss 0.81866715 - samples/sec: 812.29 - lr: 0.006250\n",
            "2021-07-02 00:14:33,349 epoch 70 - iter 72/362 - loss 0.79649712 - samples/sec: 858.48 - lr: 0.006250\n",
            "2021-07-02 00:14:34,714 epoch 70 - iter 108/362 - loss 0.79571469 - samples/sec: 846.20 - lr: 0.006250\n",
            "2021-07-02 00:14:36,069 epoch 70 - iter 144/362 - loss 0.80478526 - samples/sec: 852.22 - lr: 0.006250\n",
            "2021-07-02 00:14:37,429 epoch 70 - iter 180/362 - loss 0.80886899 - samples/sec: 849.33 - lr: 0.006250\n",
            "2021-07-02 00:14:38,788 epoch 70 - iter 216/362 - loss 0.80679982 - samples/sec: 849.53 - lr: 0.006250\n",
            "2021-07-02 00:14:40,185 epoch 70 - iter 252/362 - loss 0.80514434 - samples/sec: 826.47 - lr: 0.006250\n",
            "2021-07-02 00:14:41,575 epoch 70 - iter 288/362 - loss 0.80597764 - samples/sec: 831.52 - lr: 0.006250\n",
            "2021-07-02 00:14:42,954 epoch 70 - iter 324/362 - loss 0.80341743 - samples/sec: 837.32 - lr: 0.006250\n",
            "2021-07-02 00:14:44,367 epoch 70 - iter 360/362 - loss 0.80778585 - samples/sec: 818.05 - lr: 0.006250\n",
            "2021-07-02 00:14:44,443 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:44,444 EPOCH 70 done: loss 0.8069 - lr 0.0062500\n",
            "2021-07-02 00:14:45,893 DEV : loss 1.1643801927566528 - score 0.6488\n",
            "2021-07-02 00:14:45,989 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:14:45,991 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:14:47,442 epoch 71 - iter 36/362 - loss 0.82126213 - samples/sec: 797.54 - lr: 0.006250\n",
            "2021-07-02 00:14:48,861 epoch 71 - iter 72/362 - loss 0.80782200 - samples/sec: 814.76 - lr: 0.006250\n",
            "2021-07-02 00:14:50,314 epoch 71 - iter 108/362 - loss 0.79152235 - samples/sec: 794.83 - lr: 0.006250\n",
            "2021-07-02 00:14:51,743 epoch 71 - iter 144/362 - loss 0.78781501 - samples/sec: 808.21 - lr: 0.006250\n",
            "2021-07-02 00:14:53,204 epoch 71 - iter 180/362 - loss 0.80076615 - samples/sec: 790.84 - lr: 0.006250\n",
            "2021-07-02 00:14:54,655 epoch 71 - iter 216/362 - loss 0.79839537 - samples/sec: 796.62 - lr: 0.006250\n",
            "2021-07-02 00:14:56,059 epoch 71 - iter 252/362 - loss 0.79886616 - samples/sec: 822.78 - lr: 0.006250\n",
            "2021-07-02 00:14:57,455 epoch 71 - iter 288/362 - loss 0.79644757 - samples/sec: 827.66 - lr: 0.006250\n",
            "2021-07-02 00:14:58,875 epoch 71 - iter 324/362 - loss 0.80180957 - samples/sec: 813.19 - lr: 0.006250\n",
            "2021-07-02 00:15:00,352 epoch 71 - iter 360/362 - loss 0.80049640 - samples/sec: 782.31 - lr: 0.006250\n",
            "2021-07-02 00:15:00,437 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:00,438 EPOCH 71 done: loss 0.8012 - lr 0.0062500\n",
            "2021-07-02 00:15:01,893 DEV : loss 1.1717743873596191 - score 0.6434\n",
            "Epoch    71: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2021-07-02 00:15:01,985 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:15:01,987 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:03,360 epoch 72 - iter 36/362 - loss 0.82477650 - samples/sec: 842.53 - lr: 0.003125\n",
            "2021-07-02 00:15:04,725 epoch 72 - iter 72/362 - loss 0.82078864 - samples/sec: 845.66 - lr: 0.003125\n",
            "2021-07-02 00:15:06,113 epoch 72 - iter 108/362 - loss 0.81865464 - samples/sec: 832.26 - lr: 0.003125\n",
            "2021-07-02 00:15:07,489 epoch 72 - iter 144/362 - loss 0.82474734 - samples/sec: 839.47 - lr: 0.003125\n",
            "2021-07-02 00:15:08,941 epoch 72 - iter 180/362 - loss 0.81219698 - samples/sec: 795.42 - lr: 0.003125\n",
            "2021-07-02 00:15:10,341 epoch 72 - iter 216/362 - loss 0.80462549 - samples/sec: 825.26 - lr: 0.003125\n",
            "2021-07-02 00:15:11,749 epoch 72 - iter 252/362 - loss 0.79999082 - samples/sec: 820.74 - lr: 0.003125\n",
            "2021-07-02 00:15:14,193 epoch 72 - iter 288/362 - loss 0.80622186 - samples/sec: 471.89 - lr: 0.003125\n",
            "2021-07-02 00:15:15,619 epoch 72 - iter 324/362 - loss 0.80544363 - samples/sec: 810.47 - lr: 0.003125\n",
            "2021-07-02 00:15:17,080 epoch 72 - iter 360/362 - loss 0.80502783 - samples/sec: 790.74 - lr: 0.003125\n",
            "2021-07-02 00:15:17,156 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:17,158 EPOCH 72 done: loss 0.8041 - lr 0.0031250\n",
            "2021-07-02 00:15:18,643 DEV : loss 1.1665174961090088 - score 0.6488\n",
            "2021-07-02 00:15:18,735 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:15:18,736 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:20,148 epoch 73 - iter 36/362 - loss 0.75406274 - samples/sec: 819.27 - lr: 0.003125\n",
            "2021-07-02 00:15:21,583 epoch 73 - iter 72/362 - loss 0.75335661 - samples/sec: 805.08 - lr: 0.003125\n",
            "2021-07-02 00:15:23,057 epoch 73 - iter 108/362 - loss 0.77373935 - samples/sec: 783.16 - lr: 0.003125\n",
            "2021-07-02 00:15:24,454 epoch 73 - iter 144/362 - loss 0.78095799 - samples/sec: 827.03 - lr: 0.003125\n",
            "2021-07-02 00:15:25,865 epoch 73 - iter 180/362 - loss 0.77423105 - samples/sec: 818.25 - lr: 0.003125\n",
            "2021-07-02 00:15:27,262 epoch 73 - iter 216/362 - loss 0.78265804 - samples/sec: 826.51 - lr: 0.003125\n",
            "2021-07-02 00:15:28,635 epoch 73 - iter 252/362 - loss 0.79146606 - samples/sec: 841.15 - lr: 0.003125\n",
            "2021-07-02 00:15:30,008 epoch 73 - iter 288/362 - loss 0.79705184 - samples/sec: 841.09 - lr: 0.003125\n",
            "2021-07-02 00:15:31,383 epoch 73 - iter 324/362 - loss 0.79876272 - samples/sec: 840.00 - lr: 0.003125\n",
            "2021-07-02 00:15:32,820 epoch 73 - iter 360/362 - loss 0.80045723 - samples/sec: 803.66 - lr: 0.003125\n",
            "2021-07-02 00:15:32,916 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:32,917 EPOCH 73 done: loss 0.8008 - lr 0.0031250\n",
            "2021-07-02 00:15:34,361 DEV : loss 1.1655527353286743 - score 0.6488\n",
            "2021-07-02 00:15:34,449 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:15:34,451 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:35,848 epoch 74 - iter 36/362 - loss 0.85876703 - samples/sec: 828.79 - lr: 0.003125\n",
            "2021-07-02 00:15:37,216 epoch 74 - iter 72/362 - loss 0.80913986 - samples/sec: 843.68 - lr: 0.003125\n",
            "2021-07-02 00:15:38,613 epoch 74 - iter 108/362 - loss 0.78700223 - samples/sec: 826.94 - lr: 0.003125\n",
            "2021-07-02 00:15:40,013 epoch 74 - iter 144/362 - loss 0.79597039 - samples/sec: 824.90 - lr: 0.003125\n",
            "2021-07-02 00:15:41,363 epoch 74 - iter 180/362 - loss 0.79617792 - samples/sec: 855.36 - lr: 0.003125\n",
            "2021-07-02 00:15:42,812 epoch 74 - iter 216/362 - loss 0.79852804 - samples/sec: 797.71 - lr: 0.003125\n",
            "2021-07-02 00:15:44,157 epoch 74 - iter 252/362 - loss 0.80384689 - samples/sec: 858.37 - lr: 0.003125\n",
            "2021-07-02 00:15:45,555 epoch 74 - iter 288/362 - loss 0.80975735 - samples/sec: 826.70 - lr: 0.003125\n",
            "2021-07-02 00:15:46,911 epoch 74 - iter 324/362 - loss 0.80867447 - samples/sec: 851.77 - lr: 0.003125\n",
            "2021-07-02 00:15:48,338 epoch 74 - iter 360/362 - loss 0.81015294 - samples/sec: 809.62 - lr: 0.003125\n",
            "2021-07-02 00:15:48,423 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:48,424 EPOCH 74 done: loss 0.8097 - lr 0.0031250\n",
            "2021-07-02 00:15:49,892 DEV : loss 1.1639947891235352 - score 0.648\n",
            "2021-07-02 00:15:49,981 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:15:49,982 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:15:51,337 epoch 75 - iter 36/362 - loss 0.80198322 - samples/sec: 854.34 - lr: 0.003125\n",
            "2021-07-02 00:15:52,771 epoch 75 - iter 72/362 - loss 0.79146395 - samples/sec: 805.24 - lr: 0.003125\n",
            "2021-07-02 00:15:54,176 epoch 75 - iter 108/362 - loss 0.78906229 - samples/sec: 822.09 - lr: 0.003125\n",
            "2021-07-02 00:15:55,542 epoch 75 - iter 144/362 - loss 0.78526454 - samples/sec: 845.65 - lr: 0.003125\n",
            "2021-07-02 00:15:57,015 epoch 75 - iter 180/362 - loss 0.78351085 - samples/sec: 783.62 - lr: 0.003125\n",
            "2021-07-02 00:15:58,391 epoch 75 - iter 216/362 - loss 0.79028486 - samples/sec: 839.26 - lr: 0.003125\n",
            "2021-07-02 00:15:59,871 epoch 75 - iter 252/362 - loss 0.79537581 - samples/sec: 780.41 - lr: 0.003125\n",
            "2021-07-02 00:16:01,248 epoch 75 - iter 288/362 - loss 0.79470179 - samples/sec: 838.76 - lr: 0.003125\n",
            "2021-07-02 00:16:02,650 epoch 75 - iter 324/362 - loss 0.79257019 - samples/sec: 824.19 - lr: 0.003125\n",
            "2021-07-02 00:16:04,110 epoch 75 - iter 360/362 - loss 0.79503887 - samples/sec: 791.25 - lr: 0.003125\n",
            "2021-07-02 00:16:04,198 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:04,199 EPOCH 75 done: loss 0.7950 - lr 0.0031250\n",
            "2021-07-02 00:16:05,691 DEV : loss 1.1715048551559448 - score 0.6472\n",
            "2021-07-02 00:16:05,783 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:16:05,784 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:07,198 epoch 76 - iter 36/362 - loss 0.77196821 - samples/sec: 819.13 - lr: 0.003125\n",
            "2021-07-02 00:16:08,560 epoch 76 - iter 72/362 - loss 0.78820318 - samples/sec: 847.61 - lr: 0.003125\n",
            "2021-07-02 00:16:09,953 epoch 76 - iter 108/362 - loss 0.78498238 - samples/sec: 828.96 - lr: 0.003125\n",
            "2021-07-02 00:16:11,316 epoch 76 - iter 144/362 - loss 0.79280347 - samples/sec: 847.50 - lr: 0.003125\n",
            "2021-07-02 00:16:12,672 epoch 76 - iter 180/362 - loss 0.78654150 - samples/sec: 851.60 - lr: 0.003125\n",
            "2021-07-02 00:16:14,027 epoch 76 - iter 216/362 - loss 0.79238538 - samples/sec: 851.96 - lr: 0.003125\n",
            "2021-07-02 00:16:15,383 epoch 76 - iter 252/362 - loss 0.79618356 - samples/sec: 851.60 - lr: 0.003125\n",
            "2021-07-02 00:16:16,793 epoch 76 - iter 288/362 - loss 0.78999160 - samples/sec: 818.88 - lr: 0.003125\n",
            "2021-07-02 00:16:18,128 epoch 76 - iter 324/362 - loss 0.79184457 - samples/sec: 865.09 - lr: 0.003125\n",
            "2021-07-02 00:16:19,513 epoch 76 - iter 360/362 - loss 0.79287592 - samples/sec: 834.10 - lr: 0.003125\n",
            "2021-07-02 00:16:19,599 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:19,600 EPOCH 76 done: loss 0.7940 - lr 0.0031250\n",
            "2021-07-02 00:16:21,047 DEV : loss 1.1679376363754272 - score 0.6457\n",
            "2021-07-02 00:16:21,137 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:16:21,139 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:22,473 epoch 77 - iter 36/362 - loss 0.80160300 - samples/sec: 866.86 - lr: 0.003125\n",
            "2021-07-02 00:16:23,860 epoch 77 - iter 72/362 - loss 0.80772812 - samples/sec: 832.35 - lr: 0.003125\n",
            "2021-07-02 00:16:25,208 epoch 77 - iter 108/362 - loss 0.79049350 - samples/sec: 856.84 - lr: 0.003125\n",
            "2021-07-02 00:16:26,542 epoch 77 - iter 144/362 - loss 0.80996365 - samples/sec: 866.01 - lr: 0.003125\n",
            "2021-07-02 00:16:27,874 epoch 77 - iter 180/362 - loss 0.79949243 - samples/sec: 867.47 - lr: 0.003125\n",
            "2021-07-02 00:16:29,238 epoch 77 - iter 216/362 - loss 0.79137317 - samples/sec: 846.50 - lr: 0.003125\n",
            "2021-07-02 00:16:30,608 epoch 77 - iter 252/362 - loss 0.79532550 - samples/sec: 842.91 - lr: 0.003125\n",
            "2021-07-02 00:16:32,035 epoch 77 - iter 288/362 - loss 0.79887388 - samples/sec: 808.95 - lr: 0.003125\n",
            "2021-07-02 00:16:33,412 epoch 77 - iter 324/362 - loss 0.79924156 - samples/sec: 838.77 - lr: 0.003125\n",
            "2021-07-02 00:16:34,912 epoch 77 - iter 360/362 - loss 0.80067897 - samples/sec: 769.98 - lr: 0.003125\n",
            "2021-07-02 00:16:35,025 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:35,026 EPOCH 77 done: loss 0.8003 - lr 0.0031250\n",
            "2021-07-02 00:16:36,475 DEV : loss 1.1627451181411743 - score 0.6434\n",
            "Epoch    77: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2021-07-02 00:16:36,564 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:16:36,566 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:37,964 epoch 78 - iter 36/362 - loss 0.78284943 - samples/sec: 827.36 - lr: 0.001563\n",
            "2021-07-02 00:16:39,314 epoch 78 - iter 72/362 - loss 0.77010431 - samples/sec: 855.10 - lr: 0.001563\n",
            "2021-07-02 00:16:40,668 epoch 78 - iter 108/362 - loss 0.78931775 - samples/sec: 853.40 - lr: 0.001563\n",
            "2021-07-02 00:16:42,048 epoch 78 - iter 144/362 - loss 0.77680043 - samples/sec: 836.33 - lr: 0.001563\n",
            "2021-07-02 00:16:43,390 epoch 78 - iter 180/362 - loss 0.79014374 - samples/sec: 860.88 - lr: 0.001563\n",
            "2021-07-02 00:16:44,790 epoch 78 - iter 216/362 - loss 0.79355903 - samples/sec: 824.73 - lr: 0.001563\n",
            "2021-07-02 00:16:46,195 epoch 78 - iter 252/362 - loss 0.79490338 - samples/sec: 822.00 - lr: 0.001563\n",
            "2021-07-02 00:16:47,582 epoch 78 - iter 288/362 - loss 0.79395819 - samples/sec: 832.63 - lr: 0.001563\n",
            "2021-07-02 00:16:48,973 epoch 78 - iter 324/362 - loss 0.79950790 - samples/sec: 830.47 - lr: 0.001563\n",
            "2021-07-02 00:16:50,375 epoch 78 - iter 360/362 - loss 0.79406672 - samples/sec: 823.77 - lr: 0.001563\n",
            "2021-07-02 00:16:50,468 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:50,469 EPOCH 78 done: loss 0.7941 - lr 0.0015625\n",
            "2021-07-02 00:16:51,927 DEV : loss 1.1650129556655884 - score 0.6449\n",
            "2021-07-02 00:16:52,017 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:16:52,019 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:16:53,373 epoch 79 - iter 36/362 - loss 0.80074176 - samples/sec: 853.96 - lr: 0.001563\n",
            "2021-07-02 00:16:54,760 epoch 79 - iter 72/362 - loss 0.80830141 - samples/sec: 833.01 - lr: 0.001563\n",
            "2021-07-02 00:16:56,144 epoch 79 - iter 108/362 - loss 0.80653605 - samples/sec: 834.24 - lr: 0.001563\n",
            "2021-07-02 00:16:57,528 epoch 79 - iter 144/362 - loss 0.80923170 - samples/sec: 834.49 - lr: 0.001563\n",
            "2021-07-02 00:16:58,867 epoch 79 - iter 180/362 - loss 0.81218880 - samples/sec: 862.29 - lr: 0.001563\n",
            "2021-07-02 00:17:00,231 epoch 79 - iter 216/362 - loss 0.81577014 - samples/sec: 846.45 - lr: 0.001563\n",
            "2021-07-02 00:17:01,623 epoch 79 - iter 252/362 - loss 0.80540230 - samples/sec: 829.44 - lr: 0.001563\n",
            "2021-07-02 00:17:02,986 epoch 79 - iter 288/362 - loss 0.80282612 - samples/sec: 847.16 - lr: 0.001563\n",
            "2021-07-02 00:17:04,359 epoch 79 - iter 324/362 - loss 0.79890985 - samples/sec: 841.27 - lr: 0.001563\n",
            "2021-07-02 00:17:05,875 epoch 79 - iter 360/362 - loss 0.80293515 - samples/sec: 761.62 - lr: 0.001563\n",
            "2021-07-02 00:17:05,955 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:05,956 EPOCH 79 done: loss 0.8041 - lr 0.0015625\n",
            "2021-07-02 00:17:07,391 DEV : loss 1.167668342590332 - score 0.6472\n",
            "2021-07-02 00:17:07,486 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:17:07,488 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:08,875 epoch 80 - iter 36/362 - loss 0.76646172 - samples/sec: 833.73 - lr: 0.001563\n",
            "2021-07-02 00:17:10,216 epoch 80 - iter 72/362 - loss 0.77528760 - samples/sec: 861.07 - lr: 0.001563\n",
            "2021-07-02 00:17:11,584 epoch 80 - iter 108/362 - loss 0.78620644 - samples/sec: 844.16 - lr: 0.001563\n",
            "2021-07-02 00:17:12,963 epoch 80 - iter 144/362 - loss 0.78424644 - samples/sec: 837.46 - lr: 0.001563\n",
            "2021-07-02 00:17:14,374 epoch 80 - iter 180/362 - loss 0.78280585 - samples/sec: 818.71 - lr: 0.001563\n",
            "2021-07-02 00:17:15,769 epoch 80 - iter 216/362 - loss 0.78702358 - samples/sec: 827.28 - lr: 0.001563\n",
            "2021-07-02 00:17:17,118 epoch 80 - iter 252/362 - loss 0.78250111 - samples/sec: 856.57 - lr: 0.001563\n",
            "2021-07-02 00:17:18,477 epoch 80 - iter 288/362 - loss 0.78636237 - samples/sec: 849.17 - lr: 0.001563\n",
            "2021-07-02 00:17:19,826 epoch 80 - iter 324/362 - loss 0.78644763 - samples/sec: 856.46 - lr: 0.001563\n",
            "2021-07-02 00:17:21,210 epoch 80 - iter 360/362 - loss 0.79038263 - samples/sec: 834.50 - lr: 0.001563\n",
            "2021-07-02 00:17:21,288 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:21,289 EPOCH 80 done: loss 0.7902 - lr 0.0015625\n",
            "2021-07-02 00:17:22,723 DEV : loss 1.1693185567855835 - score 0.6441\n",
            "2021-07-02 00:17:22,817 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:17:22,819 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:24,192 epoch 81 - iter 36/362 - loss 0.77638385 - samples/sec: 842.52 - lr: 0.001563\n",
            "2021-07-02 00:17:25,552 epoch 81 - iter 72/362 - loss 0.76825527 - samples/sec: 849.13 - lr: 0.001563\n",
            "2021-07-02 00:17:26,903 epoch 81 - iter 108/362 - loss 0.78649443 - samples/sec: 855.21 - lr: 0.001563\n",
            "2021-07-02 00:17:28,329 epoch 81 - iter 144/362 - loss 0.79791340 - samples/sec: 810.00 - lr: 0.001563\n",
            "2021-07-02 00:17:29,739 epoch 81 - iter 180/362 - loss 0.80013138 - samples/sec: 818.87 - lr: 0.001563\n",
            "2021-07-02 00:17:31,098 epoch 81 - iter 216/362 - loss 0.79591830 - samples/sec: 849.67 - lr: 0.001563\n",
            "2021-07-02 00:17:32,480 epoch 81 - iter 252/362 - loss 0.79765347 - samples/sec: 835.68 - lr: 0.001563\n",
            "2021-07-02 00:17:33,889 epoch 81 - iter 288/362 - loss 0.80543828 - samples/sec: 819.78 - lr: 0.001563\n",
            "2021-07-02 00:17:35,297 epoch 81 - iter 324/362 - loss 0.80058537 - samples/sec: 820.70 - lr: 0.001563\n",
            "2021-07-02 00:17:36,709 epoch 81 - iter 360/362 - loss 0.79875256 - samples/sec: 817.66 - lr: 0.001563\n",
            "2021-07-02 00:17:36,797 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:36,798 EPOCH 81 done: loss 0.7989 - lr 0.0015625\n",
            "2021-07-02 00:17:38,289 DEV : loss 1.1701351404190063 - score 0.648\n",
            "2021-07-02 00:17:38,380 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:17:38,382 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:39,759 epoch 82 - iter 36/362 - loss 0.76122458 - samples/sec: 840.40 - lr: 0.001563\n",
            "2021-07-02 00:17:41,122 epoch 82 - iter 72/362 - loss 0.78104789 - samples/sec: 847.78 - lr: 0.001563\n",
            "2021-07-02 00:17:42,518 epoch 82 - iter 108/362 - loss 0.80695600 - samples/sec: 826.73 - lr: 0.001563\n",
            "2021-07-02 00:17:43,891 epoch 82 - iter 144/362 - loss 0.79757004 - samples/sec: 841.45 - lr: 0.001563\n",
            "2021-07-02 00:17:45,258 epoch 82 - iter 180/362 - loss 0.78914975 - samples/sec: 844.88 - lr: 0.001563\n",
            "2021-07-02 00:17:46,623 epoch 82 - iter 216/362 - loss 0.79406918 - samples/sec: 846.41 - lr: 0.001563\n",
            "2021-07-02 00:17:48,023 epoch 82 - iter 252/362 - loss 0.79462210 - samples/sec: 824.76 - lr: 0.001563\n",
            "2021-07-02 00:17:49,418 epoch 82 - iter 288/362 - loss 0.78882851 - samples/sec: 827.38 - lr: 0.001563\n",
            "2021-07-02 00:17:50,763 epoch 82 - iter 324/362 - loss 0.78869341 - samples/sec: 858.97 - lr: 0.001563\n",
            "2021-07-02 00:17:52,202 epoch 82 - iter 360/362 - loss 0.79476504 - samples/sec: 802.57 - lr: 0.001563\n",
            "2021-07-02 00:17:52,274 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:52,275 EPOCH 82 done: loss 0.7942 - lr 0.0015625\n",
            "2021-07-02 00:17:53,707 DEV : loss 1.1702378988265991 - score 0.6465\n",
            "2021-07-02 00:17:53,796 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:17:53,798 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:17:55,164 epoch 83 - iter 36/362 - loss 0.81035731 - samples/sec: 846.27 - lr: 0.001563\n",
            "2021-07-02 00:17:56,511 epoch 83 - iter 72/362 - loss 0.78867349 - samples/sec: 857.64 - lr: 0.001563\n",
            "2021-07-02 00:17:57,925 epoch 83 - iter 108/362 - loss 0.79080867 - samples/sec: 816.47 - lr: 0.001563\n",
            "2021-07-02 00:17:59,317 epoch 83 - iter 144/362 - loss 0.79420908 - samples/sec: 829.34 - lr: 0.001563\n",
            "2021-07-02 00:18:00,688 epoch 83 - iter 180/362 - loss 0.79744590 - samples/sec: 842.65 - lr: 0.001563\n",
            "2021-07-02 00:18:02,053 epoch 83 - iter 216/362 - loss 0.79888963 - samples/sec: 846.11 - lr: 0.001563\n",
            "2021-07-02 00:18:03,425 epoch 83 - iter 252/362 - loss 0.80304627 - samples/sec: 841.45 - lr: 0.001563\n",
            "2021-07-02 00:18:04,794 epoch 83 - iter 288/362 - loss 0.80539339 - samples/sec: 843.48 - lr: 0.001563\n",
            "2021-07-02 00:18:06,181 epoch 83 - iter 324/362 - loss 0.80120401 - samples/sec: 832.63 - lr: 0.001563\n",
            "2021-07-02 00:18:07,563 epoch 83 - iter 360/362 - loss 0.80283322 - samples/sec: 835.69 - lr: 0.001563\n",
            "2021-07-02 00:18:07,650 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:07,652 EPOCH 83 done: loss 0.8014 - lr 0.0015625\n",
            "2021-07-02 00:18:09,108 DEV : loss 1.16774582862854 - score 0.6488\n",
            "Epoch    83: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2021-07-02 00:18:09,197 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:18:09,199 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:10,582 epoch 84 - iter 36/362 - loss 0.78993759 - samples/sec: 835.90 - lr: 0.000781\n",
            "2021-07-02 00:18:12,010 epoch 84 - iter 72/362 - loss 0.80488004 - samples/sec: 808.83 - lr: 0.000781\n",
            "2021-07-02 00:18:13,394 epoch 84 - iter 108/362 - loss 0.79177899 - samples/sec: 834.28 - lr: 0.000781\n",
            "2021-07-02 00:18:14,797 epoch 84 - iter 144/362 - loss 0.79701898 - samples/sec: 822.89 - lr: 0.000781\n",
            "2021-07-02 00:18:16,126 epoch 84 - iter 180/362 - loss 0.79890830 - samples/sec: 869.52 - lr: 0.000781\n",
            "2021-07-02 00:18:17,528 epoch 84 - iter 216/362 - loss 0.80060838 - samples/sec: 823.44 - lr: 0.000781\n",
            "2021-07-02 00:18:18,919 epoch 84 - iter 252/362 - loss 0.80056433 - samples/sec: 830.59 - lr: 0.000781\n",
            "2021-07-02 00:18:20,273 epoch 84 - iter 288/362 - loss 0.79727171 - samples/sec: 853.00 - lr: 0.000781\n",
            "2021-07-02 00:18:21,649 epoch 84 - iter 324/362 - loss 0.79508724 - samples/sec: 839.02 - lr: 0.000781\n",
            "2021-07-02 00:18:22,996 epoch 84 - iter 360/362 - loss 0.79142057 - samples/sec: 857.04 - lr: 0.000781\n",
            "2021-07-02 00:18:23,085 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:23,086 EPOCH 84 done: loss 0.7910 - lr 0.0007813\n",
            "2021-07-02 00:18:24,530 DEV : loss 1.169289231300354 - score 0.6465\n",
            "2021-07-02 00:18:24,621 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:18:24,623 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:25,983 epoch 85 - iter 36/362 - loss 0.80901897 - samples/sec: 849.87 - lr: 0.000781\n",
            "2021-07-02 00:18:27,374 epoch 85 - iter 72/362 - loss 0.84854413 - samples/sec: 830.52 - lr: 0.000781\n",
            "2021-07-02 00:18:28,803 epoch 85 - iter 108/362 - loss 0.83440481 - samples/sec: 808.14 - lr: 0.000781\n",
            "2021-07-02 00:18:30,185 epoch 85 - iter 144/362 - loss 0.81633924 - samples/sec: 835.50 - lr: 0.000781\n",
            "2021-07-02 00:18:31,567 epoch 85 - iter 180/362 - loss 0.80953858 - samples/sec: 835.77 - lr: 0.000781\n",
            "2021-07-02 00:18:32,922 epoch 85 - iter 216/362 - loss 0.80917066 - samples/sec: 852.03 - lr: 0.000781\n",
            "2021-07-02 00:18:34,268 epoch 85 - iter 252/362 - loss 0.81107410 - samples/sec: 858.37 - lr: 0.000781\n",
            "2021-07-02 00:18:35,608 epoch 85 - iter 288/362 - loss 0.81082548 - samples/sec: 861.71 - lr: 0.000781\n",
            "2021-07-02 00:18:36,978 epoch 85 - iter 324/362 - loss 0.80630696 - samples/sec: 842.45 - lr: 0.000781\n",
            "2021-07-02 00:18:38,415 epoch 85 - iter 360/362 - loss 0.80097802 - samples/sec: 803.88 - lr: 0.000781\n",
            "2021-07-02 00:18:38,508 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:38,509 EPOCH 85 done: loss 0.8006 - lr 0.0007813\n",
            "2021-07-02 00:18:39,952 DEV : loss 1.1679019927978516 - score 0.6472\n",
            "2021-07-02 00:18:40,044 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:18:40,046 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:41,422 epoch 86 - iter 36/362 - loss 0.79784114 - samples/sec: 840.18 - lr: 0.000781\n",
            "2021-07-02 00:18:42,860 epoch 86 - iter 72/362 - loss 0.79397054 - samples/sec: 803.30 - lr: 0.000781\n",
            "2021-07-02 00:18:44,255 epoch 86 - iter 108/362 - loss 0.78823042 - samples/sec: 827.39 - lr: 0.000781\n",
            "2021-07-02 00:18:45,632 epoch 86 - iter 144/362 - loss 0.78799559 - samples/sec: 839.16 - lr: 0.000781\n",
            "2021-07-02 00:18:47,000 epoch 86 - iter 180/362 - loss 0.79703350 - samples/sec: 843.94 - lr: 0.000781\n",
            "2021-07-02 00:18:48,377 epoch 86 - iter 216/362 - loss 0.79750008 - samples/sec: 838.29 - lr: 0.000781\n",
            "2021-07-02 00:18:49,761 epoch 86 - iter 252/362 - loss 0.79879808 - samples/sec: 834.30 - lr: 0.000781\n",
            "2021-07-02 00:18:51,172 epoch 86 - iter 288/362 - loss 0.80055535 - samples/sec: 818.68 - lr: 0.000781\n",
            "2021-07-02 00:18:52,548 epoch 86 - iter 324/362 - loss 0.79994372 - samples/sec: 839.23 - lr: 0.000781\n",
            "2021-07-02 00:18:53,941 epoch 86 - iter 360/362 - loss 0.79559930 - samples/sec: 829.24 - lr: 0.000781\n",
            "2021-07-02 00:18:54,030 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:54,031 EPOCH 86 done: loss 0.7965 - lr 0.0007813\n",
            "2021-07-02 00:18:55,476 DEV : loss 1.1676411628723145 - score 0.6457\n",
            "2021-07-02 00:18:55,566 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:18:55,568 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:18:56,963 epoch 87 - iter 36/362 - loss 0.77554489 - samples/sec: 829.53 - lr: 0.000781\n",
            "2021-07-02 00:18:58,337 epoch 87 - iter 72/362 - loss 0.75086918 - samples/sec: 840.34 - lr: 0.000781\n",
            "2021-07-02 00:18:59,705 epoch 87 - iter 108/362 - loss 0.77797645 - samples/sec: 844.67 - lr: 0.000781\n",
            "2021-07-02 00:19:01,066 epoch 87 - iter 144/362 - loss 0.78324585 - samples/sec: 848.10 - lr: 0.000781\n",
            "2021-07-02 00:19:02,466 epoch 87 - iter 180/362 - loss 0.78315182 - samples/sec: 825.80 - lr: 0.000781\n",
            "2021-07-02 00:19:03,883 epoch 87 - iter 216/362 - loss 0.79226928 - samples/sec: 814.82 - lr: 0.000781\n",
            "2021-07-02 00:19:05,241 epoch 87 - iter 252/362 - loss 0.78613934 - samples/sec: 850.78 - lr: 0.000781\n",
            "2021-07-02 00:19:06,638 epoch 87 - iter 288/362 - loss 0.79153484 - samples/sec: 826.70 - lr: 0.000781\n",
            "2021-07-02 00:19:08,033 epoch 87 - iter 324/362 - loss 0.78546559 - samples/sec: 828.43 - lr: 0.000781\n",
            "2021-07-02 00:19:09,443 epoch 87 - iter 360/362 - loss 0.78405514 - samples/sec: 818.90 - lr: 0.000781\n",
            "2021-07-02 00:19:09,528 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:09,529 EPOCH 87 done: loss 0.7852 - lr 0.0007813\n",
            "2021-07-02 00:19:10,972 DEV : loss 1.1698545217514038 - score 0.6465\n",
            "2021-07-02 00:19:11,063 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:19:11,064 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:12,403 epoch 88 - iter 36/362 - loss 0.84226469 - samples/sec: 864.34 - lr: 0.000781\n",
            "2021-07-02 00:19:13,808 epoch 88 - iter 72/362 - loss 0.81438764 - samples/sec: 821.60 - lr: 0.000781\n",
            "2021-07-02 00:19:15,180 epoch 88 - iter 108/362 - loss 0.80411691 - samples/sec: 841.51 - lr: 0.000781\n",
            "2021-07-02 00:19:16,508 epoch 88 - iter 144/362 - loss 0.79473316 - samples/sec: 869.60 - lr: 0.000781\n",
            "2021-07-02 00:19:18,021 epoch 88 - iter 180/362 - loss 0.79409334 - samples/sec: 763.57 - lr: 0.000781\n",
            "2021-07-02 00:19:19,395 epoch 88 - iter 216/362 - loss 0.78455055 - samples/sec: 840.31 - lr: 0.000781\n",
            "2021-07-02 00:19:20,746 epoch 88 - iter 252/362 - loss 0.79755493 - samples/sec: 854.80 - lr: 0.000781\n",
            "2021-07-02 00:19:22,137 epoch 88 - iter 288/362 - loss 0.79337077 - samples/sec: 830.31 - lr: 0.000781\n",
            "2021-07-02 00:19:23,515 epoch 88 - iter 324/362 - loss 0.79823605 - samples/sec: 837.74 - lr: 0.000781\n",
            "2021-07-02 00:19:24,937 epoch 88 - iter 360/362 - loss 0.79492719 - samples/sec: 812.58 - lr: 0.000781\n",
            "2021-07-02 00:19:25,014 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:25,016 EPOCH 88 done: loss 0.7952 - lr 0.0007813\n",
            "2021-07-02 00:19:26,471 DEV : loss 1.1687594652175903 - score 0.6449\n",
            "2021-07-02 00:19:26,560 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:19:26,564 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:27,950 epoch 89 - iter 36/362 - loss 0.79012324 - samples/sec: 834.80 - lr: 0.000781\n",
            "2021-07-02 00:19:29,344 epoch 89 - iter 72/362 - loss 0.80385436 - samples/sec: 828.18 - lr: 0.000781\n",
            "2021-07-02 00:19:30,791 epoch 89 - iter 108/362 - loss 0.78327692 - samples/sec: 798.36 - lr: 0.000781\n",
            "2021-07-02 00:19:32,179 epoch 89 - iter 144/362 - loss 0.77910777 - samples/sec: 832.12 - lr: 0.000781\n",
            "2021-07-02 00:19:33,566 epoch 89 - iter 180/362 - loss 0.77709777 - samples/sec: 832.51 - lr: 0.000781\n",
            "2021-07-02 00:19:34,916 epoch 89 - iter 216/362 - loss 0.77643037 - samples/sec: 855.27 - lr: 0.000781\n",
            "2021-07-02 00:19:36,303 epoch 89 - iter 252/362 - loss 0.77175914 - samples/sec: 832.29 - lr: 0.000781\n",
            "2021-07-02 00:19:37,696 epoch 89 - iter 288/362 - loss 0.77481635 - samples/sec: 829.39 - lr: 0.000781\n",
            "2021-07-02 00:19:39,052 epoch 89 - iter 324/362 - loss 0.77801320 - samples/sec: 851.63 - lr: 0.000781\n",
            "2021-07-02 00:19:40,380 epoch 89 - iter 360/362 - loss 0.78399746 - samples/sec: 869.65 - lr: 0.000781\n",
            "2021-07-02 00:19:40,459 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:40,460 EPOCH 89 done: loss 0.7843 - lr 0.0007813\n",
            "2021-07-02 00:19:41,925 DEV : loss 1.1673504114151 - score 0.6465\n",
            "Epoch    89: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2021-07-02 00:19:42,027 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:19:42,029 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:43,422 epoch 90 - iter 36/362 - loss 0.80225919 - samples/sec: 830.56 - lr: 0.000391\n",
            "2021-07-02 00:19:44,797 epoch 90 - iter 72/362 - loss 0.79378201 - samples/sec: 839.85 - lr: 0.000391\n",
            "2021-07-02 00:19:46,193 epoch 90 - iter 108/362 - loss 0.78895847 - samples/sec: 827.02 - lr: 0.000391\n",
            "2021-07-02 00:19:47,572 epoch 90 - iter 144/362 - loss 0.78102168 - samples/sec: 837.30 - lr: 0.000391\n",
            "2021-07-02 00:19:48,903 epoch 90 - iter 180/362 - loss 0.78761334 - samples/sec: 867.81 - lr: 0.000391\n",
            "2021-07-02 00:19:50,314 epoch 90 - iter 216/362 - loss 0.79128786 - samples/sec: 818.08 - lr: 0.000391\n",
            "2021-07-02 00:19:51,811 epoch 90 - iter 252/362 - loss 0.78642044 - samples/sec: 771.61 - lr: 0.000391\n",
            "2021-07-02 00:19:53,129 epoch 90 - iter 288/362 - loss 0.78278895 - samples/sec: 876.02 - lr: 0.000391\n",
            "2021-07-02 00:19:54,486 epoch 90 - iter 324/362 - loss 0.78579399 - samples/sec: 851.00 - lr: 0.000391\n",
            "2021-07-02 00:19:55,853 epoch 90 - iter 360/362 - loss 0.79342529 - samples/sec: 844.68 - lr: 0.000391\n",
            "2021-07-02 00:19:55,949 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:55,950 EPOCH 90 done: loss 0.7926 - lr 0.0003906\n",
            "2021-07-02 00:19:57,393 DEV : loss 1.1688783168792725 - score 0.6457\n",
            "2021-07-02 00:19:57,483 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:19:57,484 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:19:58,833 epoch 91 - iter 36/362 - loss 0.81344948 - samples/sec: 857.67 - lr: 0.000391\n",
            "2021-07-02 00:20:00,227 epoch 91 - iter 72/362 - loss 0.77536943 - samples/sec: 829.11 - lr: 0.000391\n",
            "2021-07-02 00:20:01,590 epoch 91 - iter 108/362 - loss 0.79774319 - samples/sec: 847.08 - lr: 0.000391\n",
            "2021-07-02 00:20:02,945 epoch 91 - iter 144/362 - loss 0.78715683 - samples/sec: 852.19 - lr: 0.000391\n",
            "2021-07-02 00:20:04,321 epoch 91 - iter 180/362 - loss 0.78512391 - samples/sec: 839.52 - lr: 0.000391\n",
            "2021-07-02 00:20:05,738 epoch 91 - iter 216/362 - loss 0.78292960 - samples/sec: 815.00 - lr: 0.000391\n",
            "2021-07-02 00:20:07,104 epoch 91 - iter 252/362 - loss 0.78302412 - samples/sec: 845.39 - lr: 0.000391\n",
            "2021-07-02 00:20:09,527 epoch 91 - iter 288/362 - loss 0.78467292 - samples/sec: 476.12 - lr: 0.000391\n",
            "2021-07-02 00:20:10,859 epoch 91 - iter 324/362 - loss 0.78348473 - samples/sec: 866.40 - lr: 0.000391\n",
            "2021-07-02 00:20:12,249 epoch 91 - iter 360/362 - loss 0.78515589 - samples/sec: 831.18 - lr: 0.000391\n",
            "2021-07-02 00:20:12,337 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:12,339 EPOCH 91 done: loss 0.7847 - lr 0.0003906\n",
            "2021-07-02 00:20:13,788 DEV : loss 1.1689900159835815 - score 0.6472\n",
            "2021-07-02 00:20:13,879 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:20:13,880 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:15,274 epoch 92 - iter 36/362 - loss 0.86296531 - samples/sec: 829.74 - lr: 0.000391\n",
            "2021-07-02 00:20:16,621 epoch 92 - iter 72/362 - loss 0.80739263 - samples/sec: 857.66 - lr: 0.000391\n",
            "2021-07-02 00:20:18,008 epoch 92 - iter 108/362 - loss 0.78424404 - samples/sec: 832.80 - lr: 0.000391\n",
            "2021-07-02 00:20:19,365 epoch 92 - iter 144/362 - loss 0.78602674 - samples/sec: 851.14 - lr: 0.000391\n",
            "2021-07-02 00:20:20,749 epoch 92 - iter 180/362 - loss 0.78568290 - samples/sec: 833.98 - lr: 0.000391\n",
            "2021-07-02 00:20:22,094 epoch 92 - iter 216/362 - loss 0.78417671 - samples/sec: 858.83 - lr: 0.000391\n",
            "2021-07-02 00:20:23,468 epoch 92 - iter 252/362 - loss 0.78026313 - samples/sec: 840.25 - lr: 0.000391\n",
            "2021-07-02 00:20:24,831 epoch 92 - iter 288/362 - loss 0.78578254 - samples/sec: 847.46 - lr: 0.000391\n",
            "2021-07-02 00:20:26,217 epoch 92 - iter 324/362 - loss 0.78276331 - samples/sec: 833.51 - lr: 0.000391\n",
            "2021-07-02 00:20:27,617 epoch 92 - iter 360/362 - loss 0.78406941 - samples/sec: 824.38 - lr: 0.000391\n",
            "2021-07-02 00:20:27,704 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:27,705 EPOCH 92 done: loss 0.7842 - lr 0.0003906\n",
            "2021-07-02 00:20:29,145 DEV : loss 1.1701278686523438 - score 0.6472\n",
            "2021-07-02 00:20:29,233 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:20:29,235 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:30,638 epoch 93 - iter 36/362 - loss 0.79717086 - samples/sec: 823.60 - lr: 0.000391\n",
            "2021-07-02 00:20:32,007 epoch 93 - iter 72/362 - loss 0.78135187 - samples/sec: 843.94 - lr: 0.000391\n",
            "2021-07-02 00:20:33,393 epoch 93 - iter 108/362 - loss 0.79838575 - samples/sec: 833.28 - lr: 0.000391\n",
            "2021-07-02 00:20:34,852 epoch 93 - iter 144/362 - loss 0.79001201 - samples/sec: 792.02 - lr: 0.000391\n",
            "2021-07-02 00:20:36,224 epoch 93 - iter 180/362 - loss 0.79112457 - samples/sec: 841.44 - lr: 0.000391\n",
            "2021-07-02 00:20:37,593 epoch 93 - iter 216/362 - loss 0.79201876 - samples/sec: 843.80 - lr: 0.000391\n",
            "2021-07-02 00:20:38,943 epoch 93 - iter 252/362 - loss 0.79693684 - samples/sec: 855.56 - lr: 0.000391\n",
            "2021-07-02 00:20:40,323 epoch 93 - iter 288/362 - loss 0.79242263 - samples/sec: 836.63 - lr: 0.000391\n",
            "2021-07-02 00:20:41,699 epoch 93 - iter 324/362 - loss 0.79175827 - samples/sec: 839.73 - lr: 0.000391\n",
            "2021-07-02 00:20:43,134 epoch 93 - iter 360/362 - loss 0.78429041 - samples/sec: 804.59 - lr: 0.000391\n",
            "2021-07-02 00:20:43,231 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:43,232 EPOCH 93 done: loss 0.7846 - lr 0.0003906\n",
            "2021-07-02 00:20:44,663 DEV : loss 1.1710203886032104 - score 0.6465\n",
            "2021-07-02 00:20:44,755 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:20:44,757 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:46,155 epoch 94 - iter 36/362 - loss 0.77870593 - samples/sec: 828.87 - lr: 0.000391\n",
            "2021-07-02 00:20:47,540 epoch 94 - iter 72/362 - loss 0.78712724 - samples/sec: 833.69 - lr: 0.000391\n",
            "2021-07-02 00:20:48,935 epoch 94 - iter 108/362 - loss 0.78754081 - samples/sec: 827.74 - lr: 0.000391\n",
            "2021-07-02 00:20:50,316 epoch 94 - iter 144/362 - loss 0.79005785 - samples/sec: 836.68 - lr: 0.000391\n",
            "2021-07-02 00:20:51,705 epoch 94 - iter 180/362 - loss 0.80320451 - samples/sec: 831.41 - lr: 0.000391\n",
            "2021-07-02 00:20:53,072 epoch 94 - iter 216/362 - loss 0.81426642 - samples/sec: 844.40 - lr: 0.000391\n",
            "2021-07-02 00:20:54,435 epoch 94 - iter 252/362 - loss 0.81365527 - samples/sec: 847.42 - lr: 0.000391\n",
            "2021-07-02 00:20:55,818 epoch 94 - iter 288/362 - loss 0.80482378 - samples/sec: 834.98 - lr: 0.000391\n",
            "2021-07-02 00:20:57,237 epoch 94 - iter 324/362 - loss 0.80067596 - samples/sec: 813.74 - lr: 0.000391\n",
            "2021-07-02 00:20:58,612 epoch 94 - iter 360/362 - loss 0.79588507 - samples/sec: 840.14 - lr: 0.000391\n",
            "2021-07-02 00:20:58,693 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:20:58,693 EPOCH 94 done: loss 0.7974 - lr 0.0003906\n",
            "2021-07-02 00:21:00,148 DEV : loss 1.1710556745529175 - score 0.6457\n",
            "2021-07-02 00:21:00,237 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:21:00,239 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:01,593 epoch 95 - iter 36/362 - loss 0.80074806 - samples/sec: 854.71 - lr: 0.000391\n",
            "2021-07-02 00:21:02,943 epoch 95 - iter 72/362 - loss 0.80283434 - samples/sec: 855.41 - lr: 0.000391\n",
            "2021-07-02 00:21:04,336 epoch 95 - iter 108/362 - loss 0.78710759 - samples/sec: 829.04 - lr: 0.000391\n",
            "2021-07-02 00:21:05,710 epoch 95 - iter 144/362 - loss 0.80058522 - samples/sec: 840.44 - lr: 0.000391\n",
            "2021-07-02 00:21:07,057 epoch 95 - iter 180/362 - loss 0.81014070 - samples/sec: 857.96 - lr: 0.000391\n",
            "2021-07-02 00:21:08,441 epoch 95 - iter 216/362 - loss 0.79640809 - samples/sec: 834.44 - lr: 0.000391\n",
            "2021-07-02 00:21:09,787 epoch 95 - iter 252/362 - loss 0.78874038 - samples/sec: 857.67 - lr: 0.000391\n",
            "2021-07-02 00:21:11,182 epoch 95 - iter 288/362 - loss 0.78511196 - samples/sec: 827.75 - lr: 0.000391\n",
            "2021-07-02 00:21:12,562 epoch 95 - iter 324/362 - loss 0.78715190 - samples/sec: 836.72 - lr: 0.000391\n",
            "2021-07-02 00:21:13,958 epoch 95 - iter 360/362 - loss 0.79047224 - samples/sec: 827.30 - lr: 0.000391\n",
            "2021-07-02 00:21:14,040 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:14,042 EPOCH 95 done: loss 0.7910 - lr 0.0003906\n",
            "2021-07-02 00:21:15,480 DEV : loss 1.1696001291275024 - score 0.6465\n",
            "Epoch    95: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2021-07-02 00:21:15,570 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:21:15,572 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:16,925 epoch 96 - iter 36/362 - loss 0.83147299 - samples/sec: 854.74 - lr: 0.000195\n",
            "2021-07-02 00:21:18,334 epoch 96 - iter 72/362 - loss 0.82018479 - samples/sec: 819.59 - lr: 0.000195\n",
            "2021-07-02 00:21:19,731 epoch 96 - iter 108/362 - loss 0.80049287 - samples/sec: 826.43 - lr: 0.000195\n",
            "2021-07-02 00:21:21,141 epoch 96 - iter 144/362 - loss 0.79652225 - samples/sec: 819.57 - lr: 0.000195\n",
            "2021-07-02 00:21:22,489 epoch 96 - iter 180/362 - loss 0.78229177 - samples/sec: 856.43 - lr: 0.000195\n",
            "2021-07-02 00:21:23,823 epoch 96 - iter 216/362 - loss 0.78077901 - samples/sec: 866.01 - lr: 0.000195\n",
            "2021-07-02 00:21:25,213 epoch 96 - iter 252/362 - loss 0.77647606 - samples/sec: 830.60 - lr: 0.000195\n",
            "2021-07-02 00:21:26,555 epoch 96 - iter 288/362 - loss 0.78190793 - samples/sec: 860.41 - lr: 0.000195\n",
            "2021-07-02 00:21:27,931 epoch 96 - iter 324/362 - loss 0.78325107 - samples/sec: 839.50 - lr: 0.000195\n",
            "2021-07-02 00:21:29,369 epoch 96 - iter 360/362 - loss 0.78290762 - samples/sec: 803.16 - lr: 0.000195\n",
            "2021-07-02 00:21:29,451 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:29,453 EPOCH 96 done: loss 0.7819 - lr 0.0001953\n",
            "2021-07-02 00:21:30,926 DEV : loss 1.1703288555145264 - score 0.6472\n",
            "2021-07-02 00:21:31,013 BAD EPOCHS (no improvement): 1\n",
            "2021-07-02 00:21:31,015 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:32,418 epoch 97 - iter 36/362 - loss 0.77900169 - samples/sec: 824.43 - lr: 0.000195\n",
            "2021-07-02 00:21:33,809 epoch 97 - iter 72/362 - loss 0.78705594 - samples/sec: 830.36 - lr: 0.000195\n",
            "2021-07-02 00:21:35,145 epoch 97 - iter 108/362 - loss 0.78099363 - samples/sec: 864.06 - lr: 0.000195\n",
            "2021-07-02 00:21:36,480 epoch 97 - iter 144/362 - loss 0.78103668 - samples/sec: 865.17 - lr: 0.000195\n",
            "2021-07-02 00:21:37,870 epoch 97 - iter 180/362 - loss 0.78098322 - samples/sec: 831.62 - lr: 0.000195\n",
            "2021-07-02 00:21:39,225 epoch 97 - iter 216/362 - loss 0.77653855 - samples/sec: 852.36 - lr: 0.000195\n",
            "2021-07-02 00:21:40,576 epoch 97 - iter 252/362 - loss 0.77757423 - samples/sec: 855.10 - lr: 0.000195\n",
            "2021-07-02 00:21:41,924 epoch 97 - iter 288/362 - loss 0.78586160 - samples/sec: 856.88 - lr: 0.000195\n",
            "2021-07-02 00:21:43,338 epoch 97 - iter 324/362 - loss 0.79017246 - samples/sec: 816.97 - lr: 0.000195\n",
            "2021-07-02 00:21:44,703 epoch 97 - iter 360/362 - loss 0.79077120 - samples/sec: 846.23 - lr: 0.000195\n",
            "2021-07-02 00:21:44,787 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:44,788 EPOCH 97 done: loss 0.7914 - lr 0.0001953\n",
            "2021-07-02 00:21:46,223 DEV : loss 1.1707202196121216 - score 0.6465\n",
            "2021-07-02 00:21:46,313 BAD EPOCHS (no improvement): 2\n",
            "2021-07-02 00:21:46,316 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:21:47,676 epoch 98 - iter 36/362 - loss 0.82005683 - samples/sec: 849.83 - lr: 0.000195\n",
            "2021-07-02 00:21:49,090 epoch 98 - iter 72/362 - loss 0.80137982 - samples/sec: 816.36 - lr: 0.000195\n",
            "2021-07-02 00:21:50,462 epoch 98 - iter 108/362 - loss 0.81659009 - samples/sec: 841.63 - lr: 0.000195\n",
            "2021-07-02 00:21:51,833 epoch 98 - iter 144/362 - loss 0.80676114 - samples/sec: 842.54 - lr: 0.000195\n",
            "2021-07-02 00:21:53,173 epoch 98 - iter 180/362 - loss 0.78141241 - samples/sec: 861.65 - lr: 0.000195\n",
            "2021-07-02 00:21:54,538 epoch 98 - iter 216/362 - loss 0.78007354 - samples/sec: 846.77 - lr: 0.000195\n",
            "2021-07-02 00:21:55,923 epoch 98 - iter 252/362 - loss 0.78980743 - samples/sec: 835.68 - lr: 0.000195\n",
            "2021-07-02 00:21:57,292 epoch 98 - iter 288/362 - loss 0.79693785 - samples/sec: 843.72 - lr: 0.000195\n",
            "2021-07-02 00:21:58,677 epoch 98 - iter 324/362 - loss 0.79693412 - samples/sec: 833.63 - lr: 0.000195\n",
            "2021-07-02 00:22:00,067 epoch 98 - iter 360/362 - loss 0.79424784 - samples/sec: 830.61 - lr: 0.000195\n",
            "2021-07-02 00:22:00,150 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:00,151 EPOCH 98 done: loss 0.7949 - lr 0.0001953\n",
            "2021-07-02 00:22:01,630 DEV : loss 1.1703978776931763 - score 0.648\n",
            "2021-07-02 00:22:01,721 BAD EPOCHS (no improvement): 3\n",
            "2021-07-02 00:22:01,723 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:03,222 epoch 99 - iter 36/362 - loss 0.76177629 - samples/sec: 771.86 - lr: 0.000195\n",
            "2021-07-02 00:22:04,627 epoch 99 - iter 72/362 - loss 0.76340892 - samples/sec: 822.10 - lr: 0.000195\n",
            "2021-07-02 00:22:06,019 epoch 99 - iter 108/362 - loss 0.76741533 - samples/sec: 829.37 - lr: 0.000195\n",
            "2021-07-02 00:22:07,388 epoch 99 - iter 144/362 - loss 0.78046229 - samples/sec: 843.52 - lr: 0.000195\n",
            "2021-07-02 00:22:08,782 epoch 99 - iter 180/362 - loss 0.78860169 - samples/sec: 828.57 - lr: 0.000195\n",
            "2021-07-02 00:22:10,160 epoch 99 - iter 216/362 - loss 0.79275010 - samples/sec: 837.93 - lr: 0.000195\n",
            "2021-07-02 00:22:11,529 epoch 99 - iter 252/362 - loss 0.79559553 - samples/sec: 843.43 - lr: 0.000195\n",
            "2021-07-02 00:22:12,910 epoch 99 - iter 288/362 - loss 0.79334323 - samples/sec: 836.27 - lr: 0.000195\n",
            "2021-07-02 00:22:14,292 epoch 99 - iter 324/362 - loss 0.79283510 - samples/sec: 835.85 - lr: 0.000195\n",
            "2021-07-02 00:22:15,710 epoch 99 - iter 360/362 - loss 0.79327174 - samples/sec: 814.22 - lr: 0.000195\n",
            "2021-07-02 00:22:15,788 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:15,789 EPOCH 99 done: loss 0.7916 - lr 0.0001953\n",
            "2021-07-02 00:22:17,252 DEV : loss 1.1701288223266602 - score 0.6465\n",
            "2021-07-02 00:22:17,341 BAD EPOCHS (no improvement): 4\n",
            "2021-07-02 00:22:17,342 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:18,722 epoch 100 - iter 36/362 - loss 0.78628191 - samples/sec: 837.30 - lr: 0.000195\n",
            "2021-07-02 00:22:20,127 epoch 100 - iter 72/362 - loss 0.79107804 - samples/sec: 821.89 - lr: 0.000195\n",
            "2021-07-02 00:22:21,522 epoch 100 - iter 108/362 - loss 0.80080063 - samples/sec: 827.83 - lr: 0.000195\n",
            "2021-07-02 00:22:22,907 epoch 100 - iter 144/362 - loss 0.78889514 - samples/sec: 833.52 - lr: 0.000195\n",
            "2021-07-02 00:22:24,269 epoch 100 - iter 180/362 - loss 0.78444681 - samples/sec: 848.15 - lr: 0.000195\n",
            "2021-07-02 00:22:25,644 epoch 100 - iter 216/362 - loss 0.78522938 - samples/sec: 839.74 - lr: 0.000195\n",
            "2021-07-02 00:22:26,980 epoch 100 - iter 252/362 - loss 0.78573090 - samples/sec: 864.63 - lr: 0.000195\n",
            "2021-07-02 00:22:28,310 epoch 100 - iter 288/362 - loss 0.78344535 - samples/sec: 868.24 - lr: 0.000195\n",
            "2021-07-02 00:22:29,676 epoch 100 - iter 324/362 - loss 0.79094956 - samples/sec: 845.46 - lr: 0.000195\n",
            "2021-07-02 00:22:31,071 epoch 100 - iter 360/362 - loss 0.78969430 - samples/sec: 828.66 - lr: 0.000195\n",
            "2021-07-02 00:22:31,150 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:31,152 EPOCH 100 done: loss 0.7890 - lr 0.0001953\n",
            "2021-07-02 00:22:32,592 DEV : loss 1.1703237295150757 - score 0.6457\n",
            "2021-07-02 00:22:32,683 BAD EPOCHS (no improvement): 5\n",
            "2021-07-02 00:22:32,685 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:34,082 epoch 101 - iter 36/362 - loss 0.79610822 - samples/sec: 827.70 - lr: 0.000195\n",
            "2021-07-02 00:22:35,505 epoch 101 - iter 72/362 - loss 0.78100093 - samples/sec: 811.55 - lr: 0.000195\n",
            "2021-07-02 00:22:36,876 epoch 101 - iter 108/362 - loss 0.78279390 - samples/sec: 842.65 - lr: 0.000195\n",
            "2021-07-02 00:22:38,277 epoch 101 - iter 144/362 - loss 0.78099886 - samples/sec: 825.10 - lr: 0.000195\n",
            "2021-07-02 00:22:39,656 epoch 101 - iter 180/362 - loss 0.79659350 - samples/sec: 837.01 - lr: 0.000195\n",
            "2021-07-02 00:22:41,008 epoch 101 - iter 216/362 - loss 0.80192298 - samples/sec: 854.54 - lr: 0.000195\n",
            "2021-07-02 00:22:42,445 epoch 101 - iter 252/362 - loss 0.80130872 - samples/sec: 803.79 - lr: 0.000195\n",
            "2021-07-02 00:22:43,815 epoch 101 - iter 288/362 - loss 0.80561372 - samples/sec: 842.84 - lr: 0.000195\n",
            "2021-07-02 00:22:45,185 epoch 101 - iter 324/362 - loss 0.80012809 - samples/sec: 843.00 - lr: 0.000195\n",
            "2021-07-02 00:22:46,534 epoch 101 - iter 360/362 - loss 0.79822702 - samples/sec: 856.17 - lr: 0.000195\n",
            "2021-07-02 00:22:46,607 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:46,608 EPOCH 101 done: loss 0.7994 - lr 0.0001953\n",
            "2021-07-02 00:22:48,053 DEV : loss 1.170668601989746 - score 0.648\n",
            "Epoch   101: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2021-07-02 00:22:48,142 BAD EPOCHS (no improvement): 6\n",
            "2021-07-02 00:22:48,144 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:48,146 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:48,148 learning rate too small - quitting training!\n",
            "2021-07-02 00:22:48,150 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:56,780 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-02 00:22:56,782 Testing using best model ...\n",
            "2021-07-02 00:22:56,785 loading file result2/type_disease_trans_more2/best-model.pt\n",
            "2021-07-02 00:23:02,818 \t0.6348\n",
            "2021-07-02 00:23:02,819 \n",
            "Results:\n",
            "- F-score (micro) 0.6348\n",
            "- F-score (macro) 0.5558\n",
            "- Accuracy 0.6348\n",
            "\n",
            "By class:\n",
            "                                   precision    recall  f1-score   support\n",
            "\n",
            "          heart disease treatment     0.6760    0.8349    0.7471       842\n",
            "            heart attack symptoms     0.5897    0.5247    0.5553       263\n",
            "Coronary artery disease treatment     0.4868    0.2846    0.3592       130\n",
            "          Coronary artery disease     0.6294    0.4925    0.5526       469\n",
            "             heart disease causes     0.6680    0.7277    0.6966       224\n",
            "           heart disease symptoms     0.6616    0.7160    0.6877       486\n",
            "                    heart disease     0.5049    0.5419    0.5227       382\n",
            "                     heart attack     0.7372    0.5519    0.6312       183\n",
            " Coronary artery disease symptoms     0.5800    0.2959    0.3919        98\n",
            "              heart attack causes     0.7117    0.6583    0.6840       120\n",
            "           heart attack treatment     0.2727    0.3000    0.2857        20\n",
            "\n",
            "                        micro avg     0.6348    0.6348    0.6348      3217\n",
            "                        macro avg     0.5926    0.5390    0.5558      3217\n",
            "                     weighted avg     0.6308    0.6348    0.6256      3217\n",
            "                      samples avg     0.6348    0.6348    0.6348      3217\n",
            "\n",
            "2021-07-02 00:23:02,820 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [1.9398726224899292,\n",
              "  1.746006965637207,\n",
              "  1.6646513938903809,\n",
              "  2.0038962364196777,\n",
              "  1.5489041805267334,\n",
              "  1.483956217765808,\n",
              "  1.4494092464447021,\n",
              "  1.348284125328064,\n",
              "  1.355925440788269,\n",
              "  1.298179030418396,\n",
              "  1.246789813041687,\n",
              "  1.253495454788208,\n",
              "  1.2359247207641602,\n",
              "  1.1955465078353882,\n",
              "  1.2415273189544678,\n",
              "  1.1884955167770386,\n",
              "  1.1972590684890747,\n",
              "  1.2240028381347656,\n",
              "  1.2093459367752075,\n",
              "  1.1689499616622925,\n",
              "  1.197001576423645,\n",
              "  1.167676329612732,\n",
              "  1.1566675901412964,\n",
              "  1.1460100412368774,\n",
              "  1.1691254377365112,\n",
              "  1.1636170148849487,\n",
              "  1.1686890125274658,\n",
              "  1.1462483406066895,\n",
              "  1.16313636302948,\n",
              "  1.1826997995376587,\n",
              "  1.147223711013794,\n",
              "  1.1191024780273438,\n",
              "  1.1130013465881348,\n",
              "  1.1397002935409546,\n",
              "  1.1224716901779175,\n",
              "  1.1221801042556763,\n",
              "  1.1188210248947144,\n",
              "  1.1723276376724243,\n",
              "  1.141560673713684,\n",
              "  1.1323083639144897,\n",
              "  1.1455167531967163,\n",
              "  1.1808514595031738,\n",
              "  1.1256544589996338,\n",
              "  1.1510930061340332,\n",
              "  1.1402772665023804,\n",
              "  1.1540648937225342,\n",
              "  1.1321563720703125,\n",
              "  1.1503472328186035,\n",
              "  1.1398735046386719,\n",
              "  1.135258436203003,\n",
              "  1.1634728908538818,\n",
              "  1.1731055974960327,\n",
              "  1.1510170698165894,\n",
              "  1.1426982879638672,\n",
              "  1.1627602577209473,\n",
              "  1.157585620880127,\n",
              "  1.1286332607269287,\n",
              "  1.1356871128082275,\n",
              "  1.1374859809875488,\n",
              "  1.1539416313171387,\n",
              "  1.1460933685302734,\n",
              "  1.164973497390747,\n",
              "  1.1521670818328857,\n",
              "  1.157860279083252,\n",
              "  1.1699578762054443,\n",
              "  1.1522645950317383,\n",
              "  1.1660536527633667,\n",
              "  1.168677568435669,\n",
              "  1.169755458831787,\n",
              "  1.1643801927566528,\n",
              "  1.1717743873596191,\n",
              "  1.1665174961090088,\n",
              "  1.1655527353286743,\n",
              "  1.1639947891235352,\n",
              "  1.1715048551559448,\n",
              "  1.1679376363754272,\n",
              "  1.1627451181411743,\n",
              "  1.1650129556655884,\n",
              "  1.167668342590332,\n",
              "  1.1693185567855835,\n",
              "  1.1701351404190063,\n",
              "  1.1702378988265991,\n",
              "  1.16774582862854,\n",
              "  1.169289231300354,\n",
              "  1.1679019927978516,\n",
              "  1.1676411628723145,\n",
              "  1.1698545217514038,\n",
              "  1.1687594652175903,\n",
              "  1.1673504114151,\n",
              "  1.1688783168792725,\n",
              "  1.1689900159835815,\n",
              "  1.1701278686523438,\n",
              "  1.1710203886032104,\n",
              "  1.1710556745529175,\n",
              "  1.1696001291275024,\n",
              "  1.1703288555145264,\n",
              "  1.1707202196121216,\n",
              "  1.1703978776931763,\n",
              "  1.1701288223266602,\n",
              "  1.1703237295150757,\n",
              "  1.170668601989746],\n",
              " 'dev_score_history': [0.3232,\n",
              "  0.4126,\n",
              "  0.4343,\n",
              "  0.3504,\n",
              "  0.4887,\n",
              "  0.5035,\n",
              "  0.5315,\n",
              "  0.5664,\n",
              "  0.5392,\n",
              "  0.5843,\n",
              "  0.6014,\n",
              "  0.5921,\n",
              "  0.6014,\n",
              "  0.6099,\n",
              "  0.6076,\n",
              "  0.6045,\n",
              "  0.6169,\n",
              "  0.6037,\n",
              "  0.6115,\n",
              "  0.6232,\n",
              "  0.6154,\n",
              "  0.6348,\n",
              "  0.6309,\n",
              "  0.6317,\n",
              "  0.6278,\n",
              "  0.6263,\n",
              "  0.627,\n",
              "  0.6356,\n",
              "  0.6301,\n",
              "  0.6247,\n",
              "  0.6441,\n",
              "  0.6333,\n",
              "  0.6356,\n",
              "  0.6278,\n",
              "  0.641,\n",
              "  0.6441,\n",
              "  0.6395,\n",
              "  0.6263,\n",
              "  0.6418,\n",
              "  0.6457,\n",
              "  0.655,\n",
              "  0.6309,\n",
              "  0.6511,\n",
              "  0.6371,\n",
              "  0.6519,\n",
              "  0.6348,\n",
              "  0.6402,\n",
              "  0.6441,\n",
              "  0.6519,\n",
              "  0.6457,\n",
              "  0.641,\n",
              "  0.6519,\n",
              "  0.6434,\n",
              "  0.6503,\n",
              "  0.648,\n",
              "  0.6472,\n",
              "  0.6418,\n",
              "  0.6488,\n",
              "  0.6519,\n",
              "  0.648,\n",
              "  0.6496,\n",
              "  0.648,\n",
              "  0.6488,\n",
              "  0.6449,\n",
              "  0.648,\n",
              "  0.6472,\n",
              "  0.6519,\n",
              "  0.6449,\n",
              "  0.648,\n",
              "  0.6488,\n",
              "  0.6434,\n",
              "  0.6488,\n",
              "  0.6488,\n",
              "  0.648,\n",
              "  0.6472,\n",
              "  0.6457,\n",
              "  0.6434,\n",
              "  0.6449,\n",
              "  0.6472,\n",
              "  0.6441,\n",
              "  0.648,\n",
              "  0.6465,\n",
              "  0.6488,\n",
              "  0.6465,\n",
              "  0.6472,\n",
              "  0.6457,\n",
              "  0.6465,\n",
              "  0.6449,\n",
              "  0.6465,\n",
              "  0.6457,\n",
              "  0.6472,\n",
              "  0.6472,\n",
              "  0.6465,\n",
              "  0.6457,\n",
              "  0.6465,\n",
              "  0.6472,\n",
              "  0.6465,\n",
              "  0.648,\n",
              "  0.6465,\n",
              "  0.6457,\n",
              "  0.648],\n",
              " 'test_score': 0.6348,\n",
              " 'train_loss_history': [2.053618489708031,\n",
              "  1.9145373932564456,\n",
              "  1.823848623597161,\n",
              "  1.7533492617185604,\n",
              "  1.6837693459421232,\n",
              "  1.6232224284614647,\n",
              "  1.5277892031722307,\n",
              "  1.4634541197376356,\n",
              "  1.4241970023397583,\n",
              "  1.3904891172166687,\n",
              "  1.3646454577287916,\n",
              "  1.3351938349107353,\n",
              "  1.3248536372711646,\n",
              "  1.3043656699894541,\n",
              "  1.2798837783916222,\n",
              "  1.279211560171612,\n",
              "  1.2569981614199792,\n",
              "  1.2506382015857906,\n",
              "  1.2373425613121434,\n",
              "  1.2286134894052263,\n",
              "  1.2171681294454395,\n",
              "  1.2024934369226845,\n",
              "  1.1882096896184742,\n",
              "  1.188973256237599,\n",
              "  1.1715214886388725,\n",
              "  1.1681531657830129,\n",
              "  1.1620109527479878,\n",
              "  1.1491720674775583,\n",
              "  1.143751073772736,\n",
              "  1.1314802252126661,\n",
              "  1.1179126991751445,\n",
              "  1.1145302923344775,\n",
              "  1.0956751419365076,\n",
              "  1.1000490511319914,\n",
              "  1.0920247931177445,\n",
              "  1.0809990890447605,\n",
              "  1.0724893926915542,\n",
              "  1.0706728169931232,\n",
              "  1.0571366349307214,\n",
              "  1.040263121299322,\n",
              "  1.0409055737500692,\n",
              "  1.0443755144572389,\n",
              "  1.0234614930100203,\n",
              "  1.0173020461646234,\n",
              "  1.0154768072109854,\n",
              "  1.0032955398217092,\n",
              "  1.0053075713347335,\n",
              "  0.9490329867733117,\n",
              "  0.9385709447261378,\n",
              "  0.9316849078756669,\n",
              "  0.9310815153200982,\n",
              "  0.903376898548221,\n",
              "  0.9011910030854999,\n",
              "  0.8872355306675421,\n",
              "  0.8643415294464122,\n",
              "  0.8574742276365586,\n",
              "  0.8627245562017293,\n",
              "  0.8635729454169616,\n",
              "  0.8590454797553753,\n",
              "  0.8457416436784175,\n",
              "  0.832099138043862,\n",
              "  0.8329064513438315,\n",
              "  0.8347641871779005,\n",
              "  0.8299374824070799,\n",
              "  0.8205829615092409,\n",
              "  0.8133042357573852,\n",
              "  0.7985538616364832,\n",
              "  0.8123645184777718,\n",
              "  0.804489961727548,\n",
              "  0.8068850980608503,\n",
              "  0.8011738932923059,\n",
              "  0.8041202165803857,\n",
              "  0.8008463068232352,\n",
              "  0.8096959985257512,\n",
              "  0.7949899710838307,\n",
              "  0.7940493674732704,\n",
              "  0.8002913293752881,\n",
              "  0.7941223376363681,\n",
              "  0.8041109401547448,\n",
              "  0.7901888380228486,\n",
              "  0.7989400043178,\n",
              "  0.7942476193549225,\n",
              "  0.8014129643940794,\n",
              "  0.7909710705280304,\n",
              "  0.8006250584981718,\n",
              "  0.7964824368117264,\n",
              "  0.7852154515724814,\n",
              "  0.7952082672501137,\n",
              "  0.784339451658133,\n",
              "  0.7925690085683739,\n",
              "  0.7847119851336295,\n",
              "  0.7842078181343842,\n",
              "  0.7845732111133923,\n",
              "  0.7973519304345326,\n",
              "  0.7910199183456147,\n",
              "  0.7819412782047335,\n",
              "  0.7914447877453177,\n",
              "  0.7949448874148216,\n",
              "  0.7915506828885052,\n",
              "  0.7890287147042501,\n",
              "  0.7993942085879943]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odyNbeKfCX0D"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmsGAyQCX0X",
        "outputId": "3a00d160-c6d2-4869-81ab-94abcabe85a1"
      },
      "source": [
        "from torch.optim.adam import Adam\n",
        "\n",
        "from flair.data import Corpus\n",
        "#from flair.datasets import TREC_6\n",
        "from flair.embeddings import TransformerDocumentEmbeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 2. create the label dictionary\n",
        "label_dict = corpus.make_label_dictionary()\n",
        "#word_embeddings = [TransformerWordEmbeddings('monologg/biobert_v1.1_pubmed')]\n",
        "# 3. initialize transformer document embeddings (many models are available)\n",
        "document_embeddings = TransformerDocumentEmbeddings('dmis-lab/biobert-v1.1', fine_tune=True)\n",
        "\n",
        "# 4. create the text classifier\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "\n",
        "# 5. initialize the text classifier trainer with Adam optimizer\n",
        "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
        "\n",
        "# 6. start the training\n",
        "trainer.train('result/type_disease_trans_more',\n",
        "              learning_rate=3e-5, # use very small learning rate\n",
        "              mini_batch_size=32,\n",
        "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
        "              max_epochs=5, # terminate after 5 epochs\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:20:40,025 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14796/14796 [00:00<00:00, 42195.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:20:40,382 [b'heart disease treatment', b'heart attack symptoms', b'Coronary artery disease treatment', b'Coronary artery disease', b'heart disease causes', b'heart disease symptoms', b'heart disease', b'heart attack', b'Coronary artery disease symptoms', b'heart attack causes', b'heart attack treatment']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:20:50,067 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:20:50,069 Model: \"TextClassifier(\n",
            "  (document_embeddings): TransformerDocumentEmbeddings(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Linear(in_features=768, out_features=11, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-07-01 23:20:50,071 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:20:50,072 Corpus: \"Corpus: 11579 train + 1287 dev + 3217 test sentences\"\n",
            "2021-07-01 23:20:50,074 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:20:50,075 Parameters:\n",
            "2021-07-01 23:20:50,077  - learning_rate: \"3e-05\"\n",
            "2021-07-01 23:20:50,078  - mini_batch_size: \"32\"\n",
            "2021-07-01 23:20:50,080  - patience: \"3\"\n",
            "2021-07-01 23:20:50,081  - anneal_factor: \"0.5\"\n",
            "2021-07-01 23:20:50,082  - max_epochs: \"5\"\n",
            "2021-07-01 23:20:50,085  - shuffle: \"True\"\n",
            "2021-07-01 23:20:50,088  - train_with_dev: \"False\"\n",
            "2021-07-01 23:20:50,089  - batch_growth_annealing: \"False\"\n",
            "2021-07-01 23:20:50,090 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:20:50,091 Model training base path: \"result/type_disease_trans_more\"\n",
            "2021-07-01 23:20:50,093 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:20:50,094 Device: cuda:0\n",
            "2021-07-01 23:20:50,095 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:20:50,096 Embeddings storage mode: cpu\n",
            "2021-07-01 23:20:50,102 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:21:21,510 epoch 1 - iter 36/362 - loss 2.14129840 - samples/sec: 36.69 - lr: 0.000030\n",
            "2021-07-01 23:21:52,216 epoch 1 - iter 72/362 - loss 1.79324942 - samples/sec: 37.52 - lr: 0.000030\n",
            "2021-07-01 23:22:24,275 epoch 1 - iter 108/362 - loss 1.63892098 - samples/sec: 35.94 - lr: 0.000030\n",
            "2021-07-01 23:22:58,571 epoch 1 - iter 144/362 - loss 1.53888387 - samples/sec: 33.59 - lr: 0.000030\n",
            "2021-07-01 23:23:31,429 epoch 1 - iter 180/362 - loss 1.47604091 - samples/sec: 35.06 - lr: 0.000030\n",
            "2021-07-01 23:24:02,163 epoch 1 - iter 216/362 - loss 1.42652607 - samples/sec: 37.49 - lr: 0.000030\n",
            "2021-07-01 23:24:32,589 epoch 1 - iter 252/362 - loss 1.37012472 - samples/sec: 37.87 - lr: 0.000030\n",
            "2021-07-01 23:25:03,185 epoch 1 - iter 288/362 - loss 1.31243169 - samples/sec: 37.66 - lr: 0.000030\n",
            "2021-07-01 23:25:33,791 epoch 1 - iter 324/362 - loss 1.27702315 - samples/sec: 37.64 - lr: 0.000030\n",
            "2021-07-01 23:26:04,245 epoch 1 - iter 360/362 - loss 1.24764069 - samples/sec: 37.83 - lr: 0.000030\n",
            "2021-07-01 23:26:05,808 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:26:05,809 EPOCH 1 done: loss 1.2477 - lr 0.0000300\n",
            "2021-07-01 23:26:19,151 DEV : loss 1.0175752639770508 - score 0.6612\n",
            "2021-07-01 23:26:19,191 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:26:20,472 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:26:53,208 epoch 2 - iter 36/362 - loss 0.82020262 - samples/sec: 35.20 - lr: 0.000030\n",
            "2021-07-01 23:27:25,615 epoch 2 - iter 72/362 - loss 0.74052155 - samples/sec: 35.55 - lr: 0.000030\n",
            "2021-07-01 23:27:58,105 epoch 2 - iter 108/362 - loss 0.79690762 - samples/sec: 35.46 - lr: 0.000030\n",
            "2021-07-01 23:28:30,686 epoch 2 - iter 144/362 - loss 0.82743671 - samples/sec: 35.36 - lr: 0.000030\n",
            "2021-07-01 23:29:02,966 epoch 2 - iter 180/362 - loss 0.79733533 - samples/sec: 35.69 - lr: 0.000030\n",
            "2021-07-01 23:29:35,549 epoch 2 - iter 216/362 - loss 0.78030481 - samples/sec: 35.36 - lr: 0.000030\n",
            "2021-07-01 23:30:09,020 epoch 2 - iter 252/362 - loss 0.75237674 - samples/sec: 34.42 - lr: 0.000030\n",
            "2021-07-01 23:30:42,264 epoch 2 - iter 288/362 - loss 0.76922556 - samples/sec: 34.66 - lr: 0.000030\n",
            "2021-07-01 23:31:14,878 epoch 2 - iter 324/362 - loss 0.75957685 - samples/sec: 35.33 - lr: 0.000030\n",
            "2021-07-01 23:31:47,234 epoch 2 - iter 360/362 - loss 0.75945613 - samples/sec: 35.61 - lr: 0.000030\n",
            "2021-07-01 23:31:48,875 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:31:48,876 EPOCH 2 done: loss 0.7578 - lr 0.0000300\n",
            "2021-07-01 23:32:03,417 DEV : loss 0.9552109241485596 - score 0.7016\n",
            "2021-07-01 23:32:03,458 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:32:05,320 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:32:38,372 epoch 3 - iter 36/362 - loss 0.40150485 - samples/sec: 34.86 - lr: 0.000030\n",
            "2021-07-01 23:33:11,709 epoch 3 - iter 72/362 - loss 0.41017142 - samples/sec: 34.56 - lr: 0.000030\n",
            "2021-07-01 23:33:44,450 epoch 3 - iter 108/362 - loss 0.38400842 - samples/sec: 35.19 - lr: 0.000030\n",
            "2021-07-01 23:34:17,059 epoch 3 - iter 144/362 - loss 0.36655327 - samples/sec: 35.33 - lr: 0.000030\n",
            "2021-07-01 23:34:49,975 epoch 3 - iter 180/362 - loss 0.36729478 - samples/sec: 35.00 - lr: 0.000030\n",
            "2021-07-01 23:35:22,803 epoch 3 - iter 216/362 - loss 0.36724740 - samples/sec: 35.10 - lr: 0.000030\n",
            "2021-07-01 23:35:55,620 epoch 3 - iter 252/362 - loss 0.37684758 - samples/sec: 35.11 - lr: 0.000030\n",
            "2021-07-01 23:36:29,532 epoch 3 - iter 288/362 - loss 0.36777415 - samples/sec: 33.97 - lr: 0.000030\n",
            "2021-07-01 23:37:03,977 epoch 3 - iter 324/362 - loss 0.37157619 - samples/sec: 33.45 - lr: 0.000030\n",
            "2021-07-01 23:37:36,822 epoch 3 - iter 360/362 - loss 0.37804148 - samples/sec: 35.08 - lr: 0.000030\n",
            "2021-07-01 23:37:38,434 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:37:38,436 EPOCH 3 done: loss 0.3787 - lr 0.0000300\n",
            "2021-07-01 23:37:51,654 DEV : loss 1.0968012809753418 - score 0.6946\n",
            "2021-07-01 23:37:51,695 BAD EPOCHS (no improvement): 1\n",
            "2021-07-01 23:37:51,697 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:38:23,139 epoch 4 - iter 36/362 - loss 0.24472021 - samples/sec: 36.65 - lr: 0.000030\n",
            "2021-07-01 23:38:54,756 epoch 4 - iter 72/362 - loss 0.20759309 - samples/sec: 36.44 - lr: 0.000030\n",
            "2021-07-01 23:39:26,283 epoch 4 - iter 108/362 - loss 0.21427909 - samples/sec: 36.54 - lr: 0.000030\n",
            "2021-07-01 23:39:57,638 epoch 4 - iter 144/362 - loss 0.19584496 - samples/sec: 36.75 - lr: 0.000030\n",
            "2021-07-01 23:40:29,313 epoch 4 - iter 180/362 - loss 0.18102183 - samples/sec: 36.37 - lr: 0.000030\n",
            "2021-07-01 23:41:00,823 epoch 4 - iter 216/362 - loss 0.18182932 - samples/sec: 36.56 - lr: 0.000030\n",
            "2021-07-01 23:41:32,203 epoch 4 - iter 252/362 - loss 0.17420436 - samples/sec: 36.72 - lr: 0.000030\n",
            "2021-07-01 23:42:04,047 epoch 4 - iter 288/362 - loss 0.17096298 - samples/sec: 36.18 - lr: 0.000030\n",
            "2021-07-01 23:42:35,352 epoch 4 - iter 324/362 - loss 0.18076046 - samples/sec: 36.80 - lr: 0.000030\n",
            "2021-07-01 23:43:07,334 epoch 4 - iter 360/362 - loss 0.17614374 - samples/sec: 36.02 - lr: 0.000030\n",
            "2021-07-01 23:43:08,950 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:43:08,951 EPOCH 4 done: loss 0.1758 - lr 0.0000300\n",
            "2021-07-01 23:43:22,180 DEV : loss 1.1822303533554077 - score 0.7148\n",
            "2021-07-01 23:43:22,221 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-07-01 23:43:23,561 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:43:55,279 epoch 5 - iter 36/362 - loss 0.14025184 - samples/sec: 36.33 - lr: 0.000030\n",
            "2021-07-01 23:44:26,991 epoch 5 - iter 72/362 - loss 0.12780130 - samples/sec: 36.33 - lr: 0.000030\n",
            "2021-07-01 23:44:59,197 epoch 5 - iter 108/362 - loss 0.11723941 - samples/sec: 35.77 - lr: 0.000030\n",
            "2021-07-01 23:45:31,763 epoch 5 - iter 144/362 - loss 0.10508845 - samples/sec: 35.38 - lr: 0.000030\n",
            "2021-07-01 23:46:03,845 epoch 5 - iter 180/362 - loss 0.10466522 - samples/sec: 35.91 - lr: 0.000030\n",
            "2021-07-01 23:46:35,401 epoch 5 - iter 216/362 - loss 0.10700579 - samples/sec: 36.51 - lr: 0.000030\n",
            "2021-07-01 23:47:07,252 epoch 5 - iter 252/362 - loss 0.09994720 - samples/sec: 36.17 - lr: 0.000030\n",
            "2021-07-01 23:47:38,964 epoch 5 - iter 288/362 - loss 0.09992483 - samples/sec: 36.33 - lr: 0.000030\n",
            "2021-07-01 23:48:10,568 epoch 5 - iter 324/362 - loss 0.09733149 - samples/sec: 36.46 - lr: 0.000030\n",
            "2021-07-01 23:48:43,059 epoch 5 - iter 360/362 - loss 0.09774524 - samples/sec: 35.46 - lr: 0.000030\n",
            "2021-07-01 23:48:44,779 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:48:44,780 EPOCH 5 done: loss 0.0972 - lr 0.0000300\n",
            "2021-07-01 23:48:59,507 DEV : loss 1.5024904012680054 - score 0.7032\n",
            "2021-07-01 23:48:59,547 BAD EPOCHS (no improvement): 1\n",
            "2021-07-01 23:49:00,827 ----------------------------------------------------------------------------------------------------\n",
            "2021-07-01 23:49:00,828 Testing using best model ...\n",
            "2021-07-01 23:49:00,831 loading file result/type_disease_trans_more/best-model.pt\n",
            "2021-07-01 23:49:38,169 \t0.709\n",
            "2021-07-01 23:49:38,170 \n",
            "Results:\n",
            "- F-score (micro) 0.709\n",
            "- F-score (macro) 0.6433\n",
            "- Accuracy 0.709\n",
            "\n",
            "By class:\n",
            "                                   precision    recall  f1-score   support\n",
            "\n",
            "          heart disease treatment     0.8293    0.8135    0.8213       842\n",
            "            heart attack symptoms     0.7235    0.5970    0.6542       263\n",
            "Coronary artery disease treatment     0.6989    0.5000    0.5830       130\n",
            "          Coronary artery disease     0.6333    0.6887    0.6599       469\n",
            "             heart disease causes     0.8010    0.7366    0.7674       224\n",
            "           heart disease symptoms     0.7192    0.7798    0.7483       486\n",
            "                    heart disease     0.5604    0.6675    0.6093       382\n",
            "                     heart attack     0.8074    0.5956    0.6855       183\n",
            " Coronary artery disease symptoms     0.4945    0.4592    0.4762        98\n",
            "              heart attack causes     0.6547    0.7583    0.7027       120\n",
            "           heart attack treatment     0.3889    0.3500    0.3684        20\n",
            "\n",
            "                        micro avg     0.7090    0.7090    0.7090      3217\n",
            "                        macro avg     0.6646    0.6315    0.6433      3217\n",
            "                     weighted avg     0.7156    0.7090    0.7090      3217\n",
            "                      samples avg     0.7090    0.7090    0.7090      3217\n",
            "\n",
            "2021-07-01 23:49:38,171 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [1.0175752639770508,\n",
              "  0.9552109241485596,\n",
              "  1.0968012809753418,\n",
              "  1.1822303533554077,\n",
              "  1.5024904012680054],\n",
              " 'dev_score_history': [0.6612, 0.7016, 0.6946, 0.7148, 0.7032],\n",
              " 'test_score': 0.709,\n",
              " 'train_loss_history': [1.2477397737787903,\n",
              "  0.7578434164234493,\n",
              "  0.3787053029010463,\n",
              "  0.1758029050638646,\n",
              "  0.09723164076747717]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}