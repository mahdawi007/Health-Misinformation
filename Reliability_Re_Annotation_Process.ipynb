{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reliability Re-Annotation Process.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOy/fUdlrJ1HzbgqqqmRfZw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_T6XFWOHxYL"
      },
      "source": [
        "#Reliability Re-Annotation Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "Irmkjk0nbSeV",
        "outputId": "914bc15a-2da8-4aaa-bf24-a60a9b7dfcc9"
      },
      "source": [
        "#load GOLD Standard Corpus\n",
        "trainDF['text'] = trainDF['text'].replace('\\n','', regex=True)\n",
        "trainDF['text'] = trainDF['text'].replace('\\n',' ', regex=True)\n",
        "trainDF['text'] = trainDF['text'].replace(r'\\\\n',' ', regex=True)\n",
        "\n",
        "trainDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.Its not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?Pretty much the same risk...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. So there.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>Some tests can diagnose coronary heart disease</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>A treadmill test (or exercise stress test) can help diagnose atherosclerosis, or the narrowing of the heart's arteries.</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>A treadmill test (or exercise stress test) can not help diagnose atherosclerosis, or the narrowing of the heart's arteries.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>Other tests include a radionucleotide myocardial perfusion stress test, This can also help diagnose a narrowing of the arteries in your heart.</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>the gold standard test is a cardiac catheterization (coronary angiogram), This test lets your healthcare provider see any blockages in your heart's arteries.</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>475 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                              text label\n",
              "0                                                      Sustained effort, adequate thinking on the ice will go a long way.Its not open heart surgery for Gods sake.  FAKE\n",
              "1                                                                                         Are those all choices 100%? Heart disease is a choice? Why not go furth   FAKE\n",
              "2                                                                                 How about if she died of a heart attack from Pfizer?Pretty much the same risk...  FAKE\n",
              "3                                                        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. So there.  FAKE\n",
              "4                                                            but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   FAKE\n",
              "..                                                                                                                                                             ...   ...\n",
              "470                                                                                                                 Some tests can diagnose coronary heart disease  TRUE\n",
              "471                                        A treadmill test (or exercise stress test) can help diagnose atherosclerosis, or the narrowing of the heart's arteries.  TRUE\n",
              "472                                    A treadmill test (or exercise stress test) can not help diagnose atherosclerosis, or the narrowing of the heart's arteries.  FAKE\n",
              "473                Other tests include a radionucleotide myocardial perfusion stress test, This can also help diagnose a narrowing of the arteries in your heart.   TRUE\n",
              "474  the gold standard test is a cardiac catheterization (coronary angiogram), This test lets your healthcare provider see any blockages in your heart's arteries.  TRUE\n",
              "\n",
              "[475 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhCpgfSsIDei"
      },
      "source": [
        "##Train Gold Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-FWDcG4oI3",
        "outputId": "9c73a95b-30e6-4f36-ed0e-34671eb2e970"
      },
      "source": [
        "from sklearn import model_selection\n",
        "train_x,test_x,train_y,test_y = model_selection.train_test_split(trainDF,trainDF,test_size=0.15,random_state=11)\n",
        "train_x.reset_index(drop=True,inplace=True)\n",
        "test_x.reset_index(drop=True,inplace=True)\n",
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmJgIHL5IKs3"
      },
      "source": [
        "###Build Flair GOLD *Corpus*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpZIKOzCmaxP",
        "outputId": "ade9377b-13cf-4a39-afcc-0bb633590757"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import SentenceDataset\n",
        "from flair.data import Sentence\n",
        "\n",
        "train_labeled=[]\n",
        "for i in range(len(train_x['text'])):\n",
        "    sentence = Sentence(train_x['text'][i]).add_label('reliability', train_x['label'][i])\n",
        "    train_labeled.append(sentence)\n",
        "\n",
        "test_labeled=[]\n",
        "for i in range(len(test_x['text'])):\n",
        "    sentence = Sentence(test_x['text'][i]).add_label('reliability', test_x['label'][i])\n",
        "    test_labeled.append(sentence)\n",
        "\n",
        "\n",
        "# training dataset consisting of four sentences (2 labeled as \"food\" and 2 labeled as \"drink\")\n",
        "train = SentenceDataset(train_labeled)\n",
        "test = SentenceDataset(test_labeled)\n",
        "\n",
        "# make a corpus with train and test split\n",
        "corpus = Corpus(train=train, test=test)\n",
        "\n",
        "print(len(corpus.test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg2IX4qm3VlZ",
        "outputId": "dc3709a1-3401-4896-fb90-75a45153ff14"
      },
      "source": [
        "print(len(corpus.test))\n",
        "print(len(corpus.train))\n",
        "\n",
        "print(len(test_labeled))\n",
        "print(len(train_labeled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n",
            "363\n",
            "72\n",
            "403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCQ05fLNyale"
      },
      "source": [
        "###Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg15j9qzyqP-"
      },
      "source": [
        "from flair.data import Corpus\n",
        "#from flair.datasets import TREC_6\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJhqsEQBYpF5"
      },
      "source": [
        "#this code is used in this notebook of gold training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48e27d25164945448c70dcf662b656a9",
            "4e816ba4498c416297fcd8a28a77884b",
            "a7b9f07c65164aac8703e4b9625e9de3",
            "d6fb37290391444da6c59d1ddde13b3d",
            "3c5f27e166444374ba7dd34b2e68d2d7",
            "e0e4467524384df7aa73940654480ebf",
            "3ebf459376024a5e8ba166e4ebbcbf47",
            "a9bfa4d7d7dc4c6fadcabf41681adcea",
            "edac7d556d84406e8c2aef4d1949c4f5",
            "a0338b3d6e474fb5bf3b32ac78aa5851",
            "77032abcbbf943ffa7073e181716a7fa",
            "37097841c3b84b99a0d8a2dfcb3dd801",
            "bf8ca08a0e2f40cc8dcbd955868b601a",
            "73fa88b2b2ca411590a50cb1934f9b84",
            "c1630e90ab8140a68ed69f30f9ef16a4",
            "b077a6d979504cc58d560e3ce5cbec32",
            "63105838c82b4c8eac40d4eff11f1217",
            "74e9a1d7176a43b1b7aeaa730e7bc301",
            "d6d04e50b725434c9aa823ca57dae917",
            "5d679a82eb0448ea8ef026f38d87d61c",
            "22eebe9b30014c56954cb85e1ca51122",
            "4bdde4d593344339aa37b327c0b1a4f0",
            "42f93b2d9001481d91a3a29c3d16f39b",
            "bda7165dc8f44b7a81b44dd57f2a67db"
          ]
        },
        "id": "yz3Q6sSZ52WC",
        "outputId": "0db98700-4ead-4c24-eea6-556170231d66"
      },
      "source": [
        "from flair.trainers import ModelTrainer\n",
        "from flair.models.text_classification_model import TARSClassifier\n",
        "\n",
        "\n",
        "# 1. load base TARS\n",
        "tars = TARSClassifier.load('tars-base')\n",
        "\n",
        "# 2. make the model aware of the desired set of labels from the new corpus\n",
        "tars.add_and_switch_to_new_task(\"TRUE_FAKE\", label_dictionary=corpus.make_label_dictionary())\n",
        "\n",
        "# 3. initialize the text classifier trainer with your corpus\n",
        "trainer = ModelTrainer(tars, corpus)\n",
        "\n",
        "# 4. train model\n",
        "trainer.train(base_path='result/gold', # path to store the model artifacts\n",
        "              learning_rate=0.02, # use very small learning rate\n",
        "              mini_batch_size=1, # small mini-batch size since corpus is tiny\n",
        "              max_epochs=10, # terminate after 10 epochs\n",
        "              train_with_dev=True,\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:24:45,485 https://nlp.informatik.hu-berlin.de/resources/models/tars-base/tars-base-v8.pt not found in cache, downloading to /tmp/tmpub16jujd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 438064585/438064585 [00:11<00:00, 37026305.95B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:24:57,393 copying /tmp/tmpub16jujd to cache at /root/.flair/models/tars-base-v8.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:24:59,097 removing temp file /tmp/tmpub16jujd\n",
            "2021-05-11 20:24:59,322 loading file /root/.flair/models/tars-base-v8.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e27d25164945448c70dcf662b656a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edac7d556d84406e8c2aef4d1949c4f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63105838c82b4c8eac40d4eff11f1217",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "init TARS\n",
            "2021-05-11 20:25:08,525 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 284/284 [00:00<00:00, 17606.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:25:08,557 [b'TRUE', b'FAKE']\n",
            "2021-05-11 20:25:08,562 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,569 Model: \"TARSClassifier(\n",
            "  (document_embeddings): None\n",
            "  (decoder): None\n",
            "  (loss_function): None\n",
            "  (tars_model): TextClassifier(\n",
            "    (document_embeddings): TransformerDocumentEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
            "    (loss_function): CrossEntropyLoss()\n",
            "  )\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-05-11 20:25:08,574 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,578 Corpus: \"Corpus: 237 train + 26 dev + 47 test sentences\"\n",
            "2021-05-11 20:25:08,581 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,583 Parameters:\n",
            "2021-05-11 20:25:08,584  - learning_rate: \"0.02\"\n",
            "2021-05-11 20:25:08,586  - mini_batch_size: \"1\"\n",
            "2021-05-11 20:25:08,587  - patience: \"3\"\n",
            "2021-05-11 20:25:08,588  - anneal_factor: \"0.5\"\n",
            "2021-05-11 20:25:08,590  - max_epochs: \"10\"\n",
            "2021-05-11 20:25:08,591  - shuffle: \"True\"\n",
            "2021-05-11 20:25:08,592  - train_with_dev: \"True\"\n",
            "2021-05-11 20:25:08,593  - batch_growth_annealing: \"False\"\n",
            "2021-05-11 20:25:08,594 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,595 Model training base path: \"result/gold\"\n",
            "2021-05-11 20:25:08,596 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,597 Device: cpu\n",
            "2021-05-11 20:25:08,598 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,599 Embeddings storage mode: cpu\n",
            "2021-05-11 20:25:08,605 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:26:10,507 epoch 1 - iter 26/263 - loss 1.25209515 - samples/sec: 0.42 - lr: 0.020000\n",
            "2021-05-11 20:26:59,774 epoch 1 - iter 52/263 - loss 1.04188734 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 20:27:51,533 epoch 1 - iter 78/263 - loss 0.87507077 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 20:28:39,133 epoch 1 - iter 104/263 - loss 1.00379624 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:29:27,389 epoch 1 - iter 130/263 - loss 0.98903180 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 20:30:12,427 epoch 1 - iter 156/263 - loss 0.99714494 - samples/sec: 0.58 - lr: 0.020000\n",
            "2021-05-11 20:31:09,433 epoch 1 - iter 182/263 - loss 0.94946873 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 20:31:59,022 epoch 1 - iter 208/263 - loss 0.87785259 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:32:53,282 epoch 1 - iter 234/263 - loss 0.81895495 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 20:33:58,793 epoch 1 - iter 260/263 - loss 0.80726215 - samples/sec: 0.40 - lr: 0.020000\n",
            "2021-05-11 20:34:04,257 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:34:04,258 EPOCH 1 done: loss 0.8221 - lr 0.0200000\n",
            "2021-05-11 20:34:04,260 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 20:34:04,263 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:34:48,668 epoch 2 - iter 26/263 - loss 0.41550438 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 20:35:48,343 epoch 2 - iter 52/263 - loss 0.40084854 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 20:36:35,907 epoch 2 - iter 78/263 - loss 0.39114281 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:37:23,350 epoch 2 - iter 104/263 - loss 0.45945674 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:38:21,567 epoch 2 - iter 130/263 - loss 0.37194284 - samples/sec: 0.45 - lr: 0.020000\n",
            "2021-05-11 20:39:05,283 epoch 2 - iter 156/263 - loss 0.43592518 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 20:39:54,372 epoch 2 - iter 182/263 - loss 0.43813154 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 20:40:53,291 epoch 2 - iter 208/263 - loss 0.40120108 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 20:42:00,844 epoch 2 - iter 234/263 - loss 0.41046017 - samples/sec: 0.38 - lr: 0.020000\n",
            "2021-05-11 20:42:53,811 epoch 2 - iter 260/263 - loss 0.47857698 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 20:42:59,104 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:42:59,106 EPOCH 2 done: loss 0.4733 - lr 0.0200000\n",
            "2021-05-11 20:42:59,112 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 20:42:59,117 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:43:48,997 epoch 3 - iter 26/263 - loss 0.33018198 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:44:40,438 epoch 3 - iter 52/263 - loss 0.16833537 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 20:45:30,546 epoch 3 - iter 78/263 - loss 0.31309342 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:46:25,419 epoch 3 - iter 104/263 - loss 0.30456548 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 20:47:26,128 epoch 3 - iter 130/263 - loss 0.24482062 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 20:48:15,696 epoch 3 - iter 156/263 - loss 0.23866216 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:49:16,168 epoch 3 - iter 182/263 - loss 0.26472490 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 20:50:11,724 epoch 3 - iter 208/263 - loss 0.25571606 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 20:51:02,946 epoch 3 - iter 234/263 - loss 0.22769192 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 20:51:54,159 epoch 3 - iter 260/263 - loss 0.25600066 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 20:52:03,985 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:52:03,987 EPOCH 3 done: loss 0.2531 - lr 0.0200000\n",
            "2021-05-11 20:52:03,991 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 20:52:03,995 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:53:00,523 epoch 4 - iter 26/263 - loss 0.00251375 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 20:53:47,821 epoch 4 - iter 52/263 - loss 0.07061355 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:54:39,735 epoch 4 - iter 78/263 - loss 0.05268680 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 20:55:38,966 epoch 4 - iter 104/263 - loss 0.09629693 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 20:56:24,804 epoch 4 - iter 130/263 - loss 0.15061098 - samples/sec: 0.57 - lr: 0.020000\n",
            "2021-05-11 20:57:17,958 epoch 4 - iter 156/263 - loss 0.13182858 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 20:58:06,656 epoch 4 - iter 182/263 - loss 0.13629400 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 20:59:09,166 epoch 4 - iter 208/263 - loss 0.12352515 - samples/sec: 0.42 - lr: 0.020000\n",
            "2021-05-11 21:00:00,141 epoch 4 - iter 234/263 - loss 0.11642057 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:00:51,000 epoch 4 - iter 260/263 - loss 0.12885740 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:00:56,622 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:00:56,628 EPOCH 4 done: loss 0.1274 - lr 0.0200000\n",
            "2021-05-11 21:00:56,632 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:00:56,636 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:01:47,280 epoch 5 - iter 26/263 - loss 0.12569430 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:02:35,540 epoch 5 - iter 52/263 - loss 0.07184875 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:03:24,778 epoch 5 - iter 78/263 - loss 0.06852884 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 21:04:22,537 epoch 5 - iter 104/263 - loss 0.05523529 - samples/sec: 0.45 - lr: 0.020000\n",
            "2021-05-11 21:05:06,434 epoch 5 - iter 130/263 - loss 0.04443033 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 21:06:01,439 epoch 5 - iter 156/263 - loss 0.03707130 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:06:54,227 epoch 5 - iter 182/263 - loss 0.06471938 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:07:47,192 epoch 5 - iter 208/263 - loss 0.05677731 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:08:34,641 epoch 5 - iter 234/263 - loss 0.05075000 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 21:09:35,126 epoch 5 - iter 260/263 - loss 0.06497072 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 21:09:42,046 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:09:42,047 EPOCH 5 done: loss 0.0642 - lr 0.0200000\n",
            "2021-05-11 21:09:42,055 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:09:42,057 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:10:26,467 epoch 6 - iter 26/263 - loss 0.00030764 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 21:11:23,171 epoch 6 - iter 52/263 - loss 0.00055405 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:12:18,226 epoch 6 - iter 78/263 - loss 0.00060343 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:13:18,848 epoch 6 - iter 104/263 - loss 0.00051476 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 21:14:10,678 epoch 6 - iter 130/263 - loss 0.00044712 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:14:57,107 epoch 6 - iter 156/263 - loss 0.00041211 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:15:44,766 epoch 6 - iter 182/263 - loss 0.00037966 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 21:16:38,317 epoch 6 - iter 208/263 - loss 0.00034995 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:17:40,110 epoch 6 - iter 234/263 - loss 0.04691937 - samples/sec: 0.42 - lr: 0.020000\n",
            "2021-05-11 21:18:32,858 epoch 6 - iter 260/263 - loss 0.04227601 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:18:37,093 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:18:37,095 EPOCH 6 done: loss 0.0571 - lr 0.0200000\n",
            "2021-05-11 21:18:37,100 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:18:37,104 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:19:36,076 epoch 7 - iter 26/263 - loss 0.00124800 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 21:20:22,520 epoch 7 - iter 52/263 - loss 0.10891341 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:21:19,311 epoch 7 - iter 78/263 - loss 0.07273471 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:22:08,933 epoch 7 - iter 104/263 - loss 0.05472356 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 21:23:03,194 epoch 7 - iter 130/263 - loss 0.06994943 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 21:23:50,310 epoch 7 - iter 156/263 - loss 0.05834309 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 21:24:46,445 epoch 7 - iter 182/263 - loss 0.05022713 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:25:35,822 epoch 7 - iter 208/263 - loss 0.05353057 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 21:26:21,230 epoch 7 - iter 234/263 - loss 0.04779260 - samples/sec: 0.57 - lr: 0.020000\n",
            "2021-05-11 21:27:17,314 epoch 7 - iter 260/263 - loss 0.04330869 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:27:23,361 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:27:23,362 EPOCH 7 done: loss 0.0428 - lr 0.0200000\n",
            "2021-05-11 21:27:23,370 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:27:23,372 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:28:15,154 epoch 8 - iter 26/263 - loss 0.00202740 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:29:03,543 epoch 8 - iter 52/263 - loss 0.00121759 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:29:55,356 epoch 8 - iter 78/263 - loss 0.00086242 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:30:50,565 epoch 8 - iter 104/263 - loss 0.00691679 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:31:42,676 epoch 8 - iter 130/263 - loss 0.00575330 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:32:33,687 epoch 8 - iter 156/263 - loss 0.00482930 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:33:24,728 epoch 8 - iter 182/263 - loss 0.04086556 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:34:16,856 epoch 8 - iter 208/263 - loss 0.06841002 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:35:15,238 epoch 8 - iter 234/263 - loss 0.06084811 - samples/sec: 0.45 - lr: 0.020000\n",
            "2021-05-11 21:36:08,767 epoch 8 - iter 260/263 - loss 0.05971094 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:36:14,842 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:36:14,844 EPOCH 8 done: loss 0.0590 - lr 0.0200000\n",
            "2021-05-11 21:36:14,845 BAD EPOCHS (no improvement): 1\n",
            "2021-05-11 21:36:14,855 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:37:09,073 epoch 9 - iter 26/263 - loss 0.00491901 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 21:37:54,936 epoch 9 - iter 52/263 - loss 0.00959805 - samples/sec: 0.57 - lr: 0.020000\n",
            "2021-05-11 21:38:41,048 epoch 9 - iter 78/263 - loss 0.07165660 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:39:34,995 epoch 9 - iter 104/263 - loss 0.05384531 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 21:40:25,621 epoch 9 - iter 130/263 - loss 0.04380700 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:41:15,453 epoch 9 - iter 156/263 - loss 0.06928451 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 21:42:11,484 epoch 9 - iter 182/263 - loss 0.05944393 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:42:54,489 epoch 9 - iter 208/263 - loss 0.05308990 - samples/sec: 0.60 - lr: 0.020000\n",
            "2021-05-11 21:43:38,758 epoch 9 - iter 234/263 - loss 0.04724161 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 21:44:30,216 epoch 9 - iter 260/263 - loss 0.04255130 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:44:35,260 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:44:35,262 EPOCH 9 done: loss 0.0421 - lr 0.0200000\n",
            "2021-05-11 21:44:35,269 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:44:35,275 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:45:18,589 epoch 10 - iter 26/263 - loss 0.23005015 - samples/sec: 0.60 - lr: 0.020000\n",
            "2021-05-11 21:46:13,580 epoch 10 - iter 52/263 - loss 0.11545169 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:47:01,988 epoch 10 - iter 78/263 - loss 0.07705201 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:47:48,601 epoch 10 - iter 104/263 - loss 0.05788394 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:48:47,536 epoch 10 - iter 130/263 - loss 0.04651112 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 21:49:36,798 epoch 10 - iter 156/263 - loss 0.07857736 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 21:50:23,066 epoch 10 - iter 182/263 - loss 0.06744298 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:51:18,452 epoch 10 - iter 208/263 - loss 0.05903324 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:52:03,231 epoch 10 - iter 234/263 - loss 0.05250131 - samples/sec: 0.58 - lr: 0.020000\n",
            "2021-05-11 21:52:51,753 epoch 10 - iter 260/263 - loss 0.04727646 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:52:56,195 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:52:56,196 EPOCH 10 done: loss 0.0467 - lr 0.0200000\n",
            "2021-05-11 21:52:56,198 BAD EPOCHS (no improvement): 1\n",
            "2021-05-11 21:52:58,168 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:52:58,173 Testing using best model ...\n",
            "2021-05-11 21:53:28,626 \t0.8723\n",
            "2021-05-11 21:53:28,628 \n",
            "Results:\n",
            "- F-score (micro) 0.8723\n",
            "- F-score (macro) 0.8709\n",
            "- Accuracy 0.8723\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        TRUE     0.8846    0.8846    0.8846        26\n",
            "        FAKE     0.8571    0.8571    0.8571        21\n",
            "\n",
            "   micro avg     0.8723    0.8723    0.8723        47\n",
            "   macro avg     0.8709    0.8709    0.8709        47\n",
            "weighted avg     0.8723    0.8723    0.8723        47\n",
            " samples avg     0.8723    0.8723    0.8723        47\n",
            "\n",
            "2021-05-11 21:53:28,630 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [],\n",
              " 'dev_score_history': [],\n",
              " 'test_score': 0.8723,\n",
              " 'train_loss_history': [0.8221295834562127,\n",
              "  0.473281289617286,\n",
              "  0.2530965366117597,\n",
              "  0.12739053387276347,\n",
              "  0.06423078877861879,\n",
              "  0.057067517836428744,\n",
              "  0.04281600573784145,\n",
              "  0.0590338192364401,\n",
              "  0.04207156732331118,\n",
              "  0.04674250481638282]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9deraKpkHjt"
      },
      "source": [
        "# annotate sample curpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "48ek7imWmgLv",
        "outputId": "a239ef57-61ae-4f3c-8076-66751ea8be80"
      },
      "source": [
        "trainDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>take your prescribed medicines every day, even when you’re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4806</th>\n",
              "      <td>you should keep your blood pressure under control – that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4810 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                text label\n",
              "0      Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.  FAKE\n",
              "1                                           Are those all choices 100%? Heart disease is a choice? Why not go furth   FAKE\n",
              "2                             How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n  FAKE\n",
              "3        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.  FAKE\n",
              "4              but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   FAKE\n",
              "...                                                                                                              ...   ...\n",
              "4805                                        take your prescribed medicines every day, even when you’re feeling great  TRUE\n",
              "4806                               you should keep your blood pressure under control – that is less than 130/80 mmHg  TRUE\n",
              "4807                                                     effects of alcohol consumption on heart health are variable  TRUE\n",
              "4808                         littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  TRUE\n",
              "4809           alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  TRUE\n",
              "\n",
              "[4810 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qv9VL2_sofz"
      },
      "source": [
        "sample_sent=[]\n",
        "for i in range(len(trainDF['text'])):\n",
        "    sentence = Sentence(trainDF['text'][i])\n",
        "    sample_sent.append(sentence)\n",
        "    \n",
        "sample_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qb6rJTSkS6z"
      },
      "source": [
        "sample_annotated=[]\n",
        "for i in range(len(trainDF['text'])):\n",
        "    classifier.predict(sample_sent[i])\n",
        "    sample_annotated.append(sample_sent[i].labels)\n",
        "\n",
        "sample_annotated\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2-qG0wr9Iirq",
        "outputId": "667f57ca-d762-46a2-b063-2477f16e099f"
      },
      "source": [
        "trainDF['sample_annotated']=sample_annotated\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sample_annotated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.3262)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9945)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>take your prescribed medicines every day, even when you’re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4806</th>\n",
              "      <td>you should keep your blood pressure under control – that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4810 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                text  ... sample_annotated\n",
              "0      Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.  ...  [FAKE (0.9999)]\n",
              "1                                           Are those all choices 100%? Heart disease is a choice? Why not go furth   ...  [FAKE (0.3262)]\n",
              "2                             How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n  ...     [FAKE (1.0)]\n",
              "3        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.  ...  [FAKE (0.9945)]\n",
              "4              but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   ...  [FAKE (0.9999)]\n",
              "...                                                                                                              ...  ...              ...\n",
              "4805                                        take your prescribed medicines every day, even when you’re feeling great  ...  [TRUE (0.9998)]\n",
              "4806                               you should keep your blood pressure under control – that is less than 130/80 mmHg  ...     [TRUE (1.0)]\n",
              "4807                                                     effects of alcohol consumption on heart health are variable  ...  [TRUE (0.9998)]\n",
              "4808                         littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  ...  [TRUE (0.9999)]\n",
              "4809           alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  ...  [TRUE (0.9999)]\n",
              "\n",
              "[4810 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITnyvuYwRpg2",
        "outputId": "05c1eee1-4b17-4c12-97d0-fb8b873aaf46"
      },
      "source": [
        "    \n",
        "sample_sent[0].labels[0].to_dict()['value']\n",
        "sample_sent[0].labels[0].to_dict()['confidence']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999387264251709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "WOYBVv27TJcu",
        "outputId": "b6a596c4-ef87-4b56-e320-6b3c7ba7ee95"
      },
      "source": [
        "scory=[]\n",
        "labelnew=[]\n",
        "for i in range(len(trainDF['text'])):\n",
        "    scory.append(sample_sent[i].labels[0].to_dict()['confidence'])\n",
        "    labelnew.append(sample_sent[i].labels[0].to_dict()['value'])\n",
        "\n",
        "trainDF['labelnew']=labelnew\n",
        "trainDF['scory']=scory\n",
        "trainDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sample_annotated</th>\n",
              "      <th>labelnew</th>\n",
              "      <th>scory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.3262)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.326175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9945)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.994510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>take your prescribed medicines every day, even when you’re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4806</th>\n",
              "      <td>you should keep your blood pressure under control – that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4810 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                text  ...     scory\n",
              "0      Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.  ...  0.999939\n",
              "1                                           Are those all choices 100%? Heart disease is a choice? Why not go furth   ...  0.326175\n",
              "2                             How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n  ...  0.999960\n",
              "3        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.  ...  0.994510\n",
              "4              but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   ...  0.999936\n",
              "...                                                                                                              ...  ...       ...\n",
              "4805                                        take your prescribed medicines every day, even when you’re feeling great  ...  0.999840\n",
              "4806                               you should keep your blood pressure under control – that is less than 130/80 mmHg  ...  0.999965\n",
              "4807                                                     effects of alcohol consumption on heart health are variable  ...  0.999820\n",
              "4808                         littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  ...  0.999938\n",
              "4809           alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  ...  0.999857\n",
              "\n",
              "[4810 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgs1AF6eXdJ_",
        "outputId": "449b17bd-2a74-4d95-f890-ea09cddebc7c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cm = confusion_matrix(trainDF['label'], trainDF['labelnew'])\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(trainDF['label'], trainDF['labelnew'])\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1709  606]\n",
            " [  53 2442]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.97      0.74      0.84      2315\n",
            "        TRUE       0.80      0.98      0.88      2495\n",
            "\n",
            "    accuracy                           0.86      4810\n",
            "   macro avg       0.89      0.86      0.86      4810\n",
            "weighted avg       0.88      0.86      0.86      4810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}