{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reliability Re-Annotation Process.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOy/fUdlrJ1HzbgqqqmRfZw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_T6XFWOHxYL"
      },
      "source": [
        "#Reliability Re-Annotation Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "Irmkjk0nbSeV",
        "outputId": "914bc15a-2da8-4aaa-bf24-a60a9b7dfcc9"
      },
      "source": [
        "#load GOLD Standard Corpus\n",
        "trainDF['text'] = trainDF['text'].replace('\\n','', regex=True)\n",
        "trainDF['text'] = trainDF['text'].replace('\\n',' ', regex=True)\n",
        "trainDF['text'] = trainDF['text'].replace(r'\\\\n',' ', regex=True)\n",
        "\n",
        "trainDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.Its not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?Pretty much the same risk...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. So there.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>Some tests can diagnose coronary heart disease</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>A treadmill test (or exercise stress test) can help diagnose atherosclerosis, or the narrowing of the heart's arteries.</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>A treadmill test (or exercise stress test) can not help diagnose atherosclerosis, or the narrowing of the heart's arteries.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>Other tests include a radionucleotide myocardial perfusion stress test, This can also help diagnose a narrowing of the arteries in your heart.</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>the gold standard test is a cardiac catheterization (coronary angiogram), This test lets your healthcare provider see any blockages in your heart's arteries.</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>475 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                              text label\n",
              "0                                                      Sustained effort, adequate thinking on the ice will go a long way.Its not open heart surgery for Gods sake.  FAKE\n",
              "1                                                                                         Are those all choices 100%? Heart disease is a choice? Why not go furth   FAKE\n",
              "2                                                                                 How about if she died of a heart attack from Pfizer?Pretty much the same risk...  FAKE\n",
              "3                                                        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. So there.  FAKE\n",
              "4                                                            but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   FAKE\n",
              "..                                                                                                                                                             ...   ...\n",
              "470                                                                                                                 Some tests can diagnose coronary heart disease  TRUE\n",
              "471                                        A treadmill test (or exercise stress test) can help diagnose atherosclerosis, or the narrowing of the heart's arteries.  TRUE\n",
              "472                                    A treadmill test (or exercise stress test) can not help diagnose atherosclerosis, or the narrowing of the heart's arteries.  FAKE\n",
              "473                Other tests include a radionucleotide myocardial perfusion stress test, This can also help diagnose a narrowing of the arteries in your heart.   TRUE\n",
              "474  the gold standard test is a cardiac catheterization (coronary angiogram), This test lets your healthcare provider see any blockages in your heart's arteries.  TRUE\n",
              "\n",
              "[475 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhCpgfSsIDei"
      },
      "source": [
        "##Train Gold Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-FWDcG4oI3",
        "outputId": "9c73a95b-30e6-4f36-ed0e-34671eb2e970"
      },
      "source": [
        "from sklearn import model_selection\n",
        "train_x,test_x,train_y,test_y = model_selection.train_test_split(trainDF,trainDF,test_size=0.15,random_state=11)\n",
        "train_x.reset_index(drop=True,inplace=True)\n",
        "test_x.reset_index(drop=True,inplace=True)\n",
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmJgIHL5IKs3"
      },
      "source": [
        "###Build Flair GOLD *Corpus*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpZIKOzCmaxP",
        "outputId": "ade9377b-13cf-4a39-afcc-0bb633590757"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import SentenceDataset\n",
        "from flair.data import Sentence\n",
        "\n",
        "train_labeled=[]\n",
        "for i in range(len(train_x['text'])):\n",
        "    sentence = Sentence(train_x['text'][i]).add_label('reliability', train_x['label'][i])\n",
        "    train_labeled.append(sentence)\n",
        "\n",
        "test_labeled=[]\n",
        "for i in range(len(test_x['text'])):\n",
        "    sentence = Sentence(test_x['text'][i]).add_label('reliability', test_x['label'][i])\n",
        "    test_labeled.append(sentence)\n",
        "\n",
        "\n",
        "# training dataset consisting of four sentences (2 labeled as \"food\" and 2 labeled as \"drink\")\n",
        "train = SentenceDataset(train_labeled)\n",
        "test = SentenceDataset(test_labeled)\n",
        "\n",
        "# make a corpus with train and test split\n",
        "corpus = Corpus(train=train, test=test)\n",
        "\n",
        "print(len(corpus.test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg2IX4qm3VlZ",
        "outputId": "dc3709a1-3401-4896-fb90-75a45153ff14"
      },
      "source": [
        "print(len(corpus.test))\n",
        "print(len(corpus.train))\n",
        "\n",
        "print(len(test_labeled))\n",
        "print(len(train_labeled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n",
            "363\n",
            "72\n",
            "403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCQ05fLNyale"
      },
      "source": [
        "###Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg15j9qzyqP-"
      },
      "source": [
        "from flair.data import Corpus\n",
        "#from flair.datasets import TREC_6\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJhqsEQBYpF5"
      },
      "source": [
        "#this code is used in this notebook of gold training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48e27d25164945448c70dcf662b656a9",
            "4e816ba4498c416297fcd8a28a77884b",
            "a7b9f07c65164aac8703e4b9625e9de3",
            "d6fb37290391444da6c59d1ddde13b3d",
            "3c5f27e166444374ba7dd34b2e68d2d7",
            "e0e4467524384df7aa73940654480ebf",
            "3ebf459376024a5e8ba166e4ebbcbf47",
            "a9bfa4d7d7dc4c6fadcabf41681adcea",
            "edac7d556d84406e8c2aef4d1949c4f5",
            "a0338b3d6e474fb5bf3b32ac78aa5851",
            "77032abcbbf943ffa7073e181716a7fa",
            "37097841c3b84b99a0d8a2dfcb3dd801",
            "bf8ca08a0e2f40cc8dcbd955868b601a",
            "73fa88b2b2ca411590a50cb1934f9b84",
            "c1630e90ab8140a68ed69f30f9ef16a4",
            "b077a6d979504cc58d560e3ce5cbec32",
            "63105838c82b4c8eac40d4eff11f1217",
            "74e9a1d7176a43b1b7aeaa730e7bc301",
            "d6d04e50b725434c9aa823ca57dae917",
            "5d679a82eb0448ea8ef026f38d87d61c",
            "22eebe9b30014c56954cb85e1ca51122",
            "4bdde4d593344339aa37b327c0b1a4f0",
            "42f93b2d9001481d91a3a29c3d16f39b",
            "bda7165dc8f44b7a81b44dd57f2a67db"
          ]
        },
        "id": "yz3Q6sSZ52WC",
        "outputId": "0db98700-4ead-4c24-eea6-556170231d66"
      },
      "source": [
        "from flair.trainers import ModelTrainer\n",
        "from flair.models.text_classification_model import TARSClassifier\n",
        "\n",
        "\n",
        "# 1. load base TARS\n",
        "tars = TARSClassifier.load('tars-base')\n",
        "\n",
        "# 2. make the model aware of the desired set of labels from the new corpus\n",
        "tars.add_and_switch_to_new_task(\"TRUE_FAKE\", label_dictionary=corpus.make_label_dictionary())\n",
        "\n",
        "# 3. initialize the text classifier trainer with your corpus\n",
        "trainer = ModelTrainer(tars, corpus)\n",
        "\n",
        "# 4. train model\n",
        "trainer.train(base_path='result/gold', # path to store the model artifacts\n",
        "              learning_rate=0.02, # use very small learning rate\n",
        "              mini_batch_size=1, # small mini-batch size since corpus is tiny\n",
        "              max_epochs=10, # terminate after 10 epochs\n",
        "              train_with_dev=True,\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:24:45,485 https://nlp.informatik.hu-berlin.de/resources/models/tars-base/tars-base-v8.pt not found in cache, downloading to /tmp/tmpub16jujd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438064585/438064585 [00:11<00:00, 37026305.95B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:24:57,393 copying /tmp/tmpub16jujd to cache at /root/.flair/models/tars-base-v8.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:24:59,097 removing temp file /tmp/tmpub16jujd\n",
            "2021-05-11 20:24:59,322 loading file /root/.flair/models/tars-base-v8.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e27d25164945448c70dcf662b656a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edac7d556d84406e8c2aef4d1949c4f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63105838c82b4c8eac40d4eff11f1217",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "init TARS\n",
            "2021-05-11 20:25:08,525 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 284/284 [00:00<00:00, 17606.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:25:08,557 [b'TRUE', b'FAKE']\n",
            "2021-05-11 20:25:08,562 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,569 Model: \"TARSClassifier(\n",
            "  (document_embeddings): None\n",
            "  (decoder): None\n",
            "  (loss_function): None\n",
            "  (tars_model): TextClassifier(\n",
            "    (document_embeddings): TransformerDocumentEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
            "    (loss_function): CrossEntropyLoss()\n",
            "  )\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-05-11 20:25:08,574 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,578 Corpus: \"Corpus: 237 train + 26 dev + 47 test sentences\"\n",
            "2021-05-11 20:25:08,581 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,583 Parameters:\n",
            "2021-05-11 20:25:08,584  - learning_rate: \"0.02\"\n",
            "2021-05-11 20:25:08,586  - mini_batch_size: \"1\"\n",
            "2021-05-11 20:25:08,587  - patience: \"3\"\n",
            "2021-05-11 20:25:08,588  - anneal_factor: \"0.5\"\n",
            "2021-05-11 20:25:08,590  - max_epochs: \"10\"\n",
            "2021-05-11 20:25:08,591  - shuffle: \"True\"\n",
            "2021-05-11 20:25:08,592  - train_with_dev: \"True\"\n",
            "2021-05-11 20:25:08,593  - batch_growth_annealing: \"False\"\n",
            "2021-05-11 20:25:08,594 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,595 Model training base path: \"result/gold\"\n",
            "2021-05-11 20:25:08,596 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,597 Device: cpu\n",
            "2021-05-11 20:25:08,598 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:25:08,599 Embeddings storage mode: cpu\n",
            "2021-05-11 20:25:08,605 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 20:26:10,507 epoch 1 - iter 26/263 - loss 1.25209515 - samples/sec: 0.42 - lr: 0.020000\n",
            "2021-05-11 20:26:59,774 epoch 1 - iter 52/263 - loss 1.04188734 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 20:27:51,533 epoch 1 - iter 78/263 - loss 0.87507077 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 20:28:39,133 epoch 1 - iter 104/263 - loss 1.00379624 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:29:27,389 epoch 1 - iter 130/263 - loss 0.98903180 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 20:30:12,427 epoch 1 - iter 156/263 - loss 0.99714494 - samples/sec: 0.58 - lr: 0.020000\n",
            "2021-05-11 20:31:09,433 epoch 1 - iter 182/263 - loss 0.94946873 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 20:31:59,022 epoch 1 - iter 208/263 - loss 0.87785259 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:32:53,282 epoch 1 - iter 234/263 - loss 0.81895495 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 20:33:58,793 epoch 1 - iter 260/263 - loss 0.80726215 - samples/sec: 0.40 - lr: 0.020000\n",
            "2021-05-11 20:34:04,257 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:34:04,258 EPOCH 1 done: loss 0.8221 - lr 0.0200000\n",
            "2021-05-11 20:34:04,260 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 20:34:04,263 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:34:48,668 epoch 2 - iter 26/263 - loss 0.41550438 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 20:35:48,343 epoch 2 - iter 52/263 - loss 0.40084854 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 20:36:35,907 epoch 2 - iter 78/263 - loss 0.39114281 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:37:23,350 epoch 2 - iter 104/263 - loss 0.45945674 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:38:21,567 epoch 2 - iter 130/263 - loss 0.37194284 - samples/sec: 0.45 - lr: 0.020000\n",
            "2021-05-11 20:39:05,283 epoch 2 - iter 156/263 - loss 0.43592518 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 20:39:54,372 epoch 2 - iter 182/263 - loss 0.43813154 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 20:40:53,291 epoch 2 - iter 208/263 - loss 0.40120108 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 20:42:00,844 epoch 2 - iter 234/263 - loss 0.41046017 - samples/sec: 0.38 - lr: 0.020000\n",
            "2021-05-11 20:42:53,811 epoch 2 - iter 260/263 - loss 0.47857698 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 20:42:59,104 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:42:59,106 EPOCH 2 done: loss 0.4733 - lr 0.0200000\n",
            "2021-05-11 20:42:59,112 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 20:42:59,117 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:43:48,997 epoch 3 - iter 26/263 - loss 0.33018198 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:44:40,438 epoch 3 - iter 52/263 - loss 0.16833537 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 20:45:30,546 epoch 3 - iter 78/263 - loss 0.31309342 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:46:25,419 epoch 3 - iter 104/263 - loss 0.30456548 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 20:47:26,128 epoch 3 - iter 130/263 - loss 0.24482062 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 20:48:15,696 epoch 3 - iter 156/263 - loss 0.23866216 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 20:49:16,168 epoch 3 - iter 182/263 - loss 0.26472490 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 20:50:11,724 epoch 3 - iter 208/263 - loss 0.25571606 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 20:51:02,946 epoch 3 - iter 234/263 - loss 0.22769192 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 20:51:54,159 epoch 3 - iter 260/263 - loss 0.25600066 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 20:52:03,985 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:52:03,987 EPOCH 3 done: loss 0.2531 - lr 0.0200000\n",
            "2021-05-11 20:52:03,991 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 20:52:03,995 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 20:53:00,523 epoch 4 - iter 26/263 - loss 0.00251375 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 20:53:47,821 epoch 4 - iter 52/263 - loss 0.07061355 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 20:54:39,735 epoch 4 - iter 78/263 - loss 0.05268680 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 20:55:38,966 epoch 4 - iter 104/263 - loss 0.09629693 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 20:56:24,804 epoch 4 - iter 130/263 - loss 0.15061098 - samples/sec: 0.57 - lr: 0.020000\n",
            "2021-05-11 20:57:17,958 epoch 4 - iter 156/263 - loss 0.13182858 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 20:58:06,656 epoch 4 - iter 182/263 - loss 0.13629400 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 20:59:09,166 epoch 4 - iter 208/263 - loss 0.12352515 - samples/sec: 0.42 - lr: 0.020000\n",
            "2021-05-11 21:00:00,141 epoch 4 - iter 234/263 - loss 0.11642057 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:00:51,000 epoch 4 - iter 260/263 - loss 0.12885740 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:00:56,622 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:00:56,628 EPOCH 4 done: loss 0.1274 - lr 0.0200000\n",
            "2021-05-11 21:00:56,632 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:00:56,636 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:01:47,280 epoch 5 - iter 26/263 - loss 0.12569430 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:02:35,540 epoch 5 - iter 52/263 - loss 0.07184875 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:03:24,778 epoch 5 - iter 78/263 - loss 0.06852884 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 21:04:22,537 epoch 5 - iter 104/263 - loss 0.05523529 - samples/sec: 0.45 - lr: 0.020000\n",
            "2021-05-11 21:05:06,434 epoch 5 - iter 130/263 - loss 0.04443033 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 21:06:01,439 epoch 5 - iter 156/263 - loss 0.03707130 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:06:54,227 epoch 5 - iter 182/263 - loss 0.06471938 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:07:47,192 epoch 5 - iter 208/263 - loss 0.05677731 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:08:34,641 epoch 5 - iter 234/263 - loss 0.05075000 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 21:09:35,126 epoch 5 - iter 260/263 - loss 0.06497072 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 21:09:42,046 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:09:42,047 EPOCH 5 done: loss 0.0642 - lr 0.0200000\n",
            "2021-05-11 21:09:42,055 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:09:42,057 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:10:26,467 epoch 6 - iter 26/263 - loss 0.00030764 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 21:11:23,171 epoch 6 - iter 52/263 - loss 0.00055405 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:12:18,226 epoch 6 - iter 78/263 - loss 0.00060343 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:13:18,848 epoch 6 - iter 104/263 - loss 0.00051476 - samples/sec: 0.43 - lr: 0.020000\n",
            "2021-05-11 21:14:10,678 epoch 6 - iter 130/263 - loss 0.00044712 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:14:57,107 epoch 6 - iter 156/263 - loss 0.00041211 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:15:44,766 epoch 6 - iter 182/263 - loss 0.00037966 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 21:16:38,317 epoch 6 - iter 208/263 - loss 0.00034995 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:17:40,110 epoch 6 - iter 234/263 - loss 0.04691937 - samples/sec: 0.42 - lr: 0.020000\n",
            "2021-05-11 21:18:32,858 epoch 6 - iter 260/263 - loss 0.04227601 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:18:37,093 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:18:37,095 EPOCH 6 done: loss 0.0571 - lr 0.0200000\n",
            "2021-05-11 21:18:37,100 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:18:37,104 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:19:36,076 epoch 7 - iter 26/263 - loss 0.00124800 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 21:20:22,520 epoch 7 - iter 52/263 - loss 0.10891341 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:21:19,311 epoch 7 - iter 78/263 - loss 0.07273471 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:22:08,933 epoch 7 - iter 104/263 - loss 0.05472356 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 21:23:03,194 epoch 7 - iter 130/263 - loss 0.06994943 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 21:23:50,310 epoch 7 - iter 156/263 - loss 0.05834309 - samples/sec: 0.55 - lr: 0.020000\n",
            "2021-05-11 21:24:46,445 epoch 7 - iter 182/263 - loss 0.05022713 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:25:35,822 epoch 7 - iter 208/263 - loss 0.05353057 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 21:26:21,230 epoch 7 - iter 234/263 - loss 0.04779260 - samples/sec: 0.57 - lr: 0.020000\n",
            "2021-05-11 21:27:17,314 epoch 7 - iter 260/263 - loss 0.04330869 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:27:23,361 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:27:23,362 EPOCH 7 done: loss 0.0428 - lr 0.0200000\n",
            "2021-05-11 21:27:23,370 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:27:23,372 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:28:15,154 epoch 8 - iter 26/263 - loss 0.00202740 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:29:03,543 epoch 8 - iter 52/263 - loss 0.00121759 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:29:55,356 epoch 8 - iter 78/263 - loss 0.00086242 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:30:50,565 epoch 8 - iter 104/263 - loss 0.00691679 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:31:42,676 epoch 8 - iter 130/263 - loss 0.00575330 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:32:33,687 epoch 8 - iter 156/263 - loss 0.00482930 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:33:24,728 epoch 8 - iter 182/263 - loss 0.04086556 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:34:16,856 epoch 8 - iter 208/263 - loss 0.06841002 - samples/sec: 0.50 - lr: 0.020000\n",
            "2021-05-11 21:35:15,238 epoch 8 - iter 234/263 - loss 0.06084811 - samples/sec: 0.45 - lr: 0.020000\n",
            "2021-05-11 21:36:08,767 epoch 8 - iter 260/263 - loss 0.05971094 - samples/sec: 0.49 - lr: 0.020000\n",
            "2021-05-11 21:36:14,842 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:36:14,844 EPOCH 8 done: loss 0.0590 - lr 0.0200000\n",
            "2021-05-11 21:36:14,845 BAD EPOCHS (no improvement): 1\n",
            "2021-05-11 21:36:14,855 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:37:09,073 epoch 9 - iter 26/263 - loss 0.00491901 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 21:37:54,936 epoch 9 - iter 52/263 - loss 0.00959805 - samples/sec: 0.57 - lr: 0.020000\n",
            "2021-05-11 21:38:41,048 epoch 9 - iter 78/263 - loss 0.07165660 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:39:34,995 epoch 9 - iter 104/263 - loss 0.05384531 - samples/sec: 0.48 - lr: 0.020000\n",
            "2021-05-11 21:40:25,621 epoch 9 - iter 130/263 - loss 0.04380700 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:41:15,453 epoch 9 - iter 156/263 - loss 0.06928451 - samples/sec: 0.52 - lr: 0.020000\n",
            "2021-05-11 21:42:11,484 epoch 9 - iter 182/263 - loss 0.05944393 - samples/sec: 0.46 - lr: 0.020000\n",
            "2021-05-11 21:42:54,489 epoch 9 - iter 208/263 - loss 0.05308990 - samples/sec: 0.60 - lr: 0.020000\n",
            "2021-05-11 21:43:38,758 epoch 9 - iter 234/263 - loss 0.04724161 - samples/sec: 0.59 - lr: 0.020000\n",
            "2021-05-11 21:44:30,216 epoch 9 - iter 260/263 - loss 0.04255130 - samples/sec: 0.51 - lr: 0.020000\n",
            "2021-05-11 21:44:35,260 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:44:35,262 EPOCH 9 done: loss 0.0421 - lr 0.0200000\n",
            "2021-05-11 21:44:35,269 BAD EPOCHS (no improvement): 0\n",
            "2021-05-11 21:44:35,275 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:45:18,589 epoch 10 - iter 26/263 - loss 0.23005015 - samples/sec: 0.60 - lr: 0.020000\n",
            "2021-05-11 21:46:13,580 epoch 10 - iter 52/263 - loss 0.11545169 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:47:01,988 epoch 10 - iter 78/263 - loss 0.07705201 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:47:48,601 epoch 10 - iter 104/263 - loss 0.05788394 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:48:47,536 epoch 10 - iter 130/263 - loss 0.04651112 - samples/sec: 0.44 - lr: 0.020000\n",
            "2021-05-11 21:49:36,798 epoch 10 - iter 156/263 - loss 0.07857736 - samples/sec: 0.53 - lr: 0.020000\n",
            "2021-05-11 21:50:23,066 epoch 10 - iter 182/263 - loss 0.06744298 - samples/sec: 0.56 - lr: 0.020000\n",
            "2021-05-11 21:51:18,452 epoch 10 - iter 208/263 - loss 0.05903324 - samples/sec: 0.47 - lr: 0.020000\n",
            "2021-05-11 21:52:03,231 epoch 10 - iter 234/263 - loss 0.05250131 - samples/sec: 0.58 - lr: 0.020000\n",
            "2021-05-11 21:52:51,753 epoch 10 - iter 260/263 - loss 0.04727646 - samples/sec: 0.54 - lr: 0.020000\n",
            "2021-05-11 21:52:56,195 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:52:56,196 EPOCH 10 done: loss 0.0467 - lr 0.0200000\n",
            "2021-05-11 21:52:56,198 BAD EPOCHS (no improvement): 1\n",
            "2021-05-11 21:52:58,168 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-11 21:52:58,173 Testing using best model ...\n",
            "2021-05-11 21:53:28,626 \t0.8723\n",
            "2021-05-11 21:53:28,628 \n",
            "Results:\n",
            "- F-score (micro) 0.8723\n",
            "- F-score (macro) 0.8709\n",
            "- Accuracy 0.8723\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        TRUE     0.8846    0.8846    0.8846        26\n",
            "        FAKE     0.8571    0.8571    0.8571        21\n",
            "\n",
            "   micro avg     0.8723    0.8723    0.8723        47\n",
            "   macro avg     0.8709    0.8709    0.8709        47\n",
            "weighted avg     0.8723    0.8723    0.8723        47\n",
            " samples avg     0.8723    0.8723    0.8723        47\n",
            "\n",
            "2021-05-11 21:53:28,630 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [],\n",
              " 'dev_score_history': [],\n",
              " 'test_score': 0.8723,\n",
              " 'train_loss_history': [0.8221295834562127,\n",
              "  0.473281289617286,\n",
              "  0.2530965366117597,\n",
              "  0.12739053387276347,\n",
              "  0.06423078877861879,\n",
              "  0.057067517836428744,\n",
              "  0.04281600573784145,\n",
              "  0.0590338192364401,\n",
              "  0.04207156732331118,\n",
              "  0.04674250481638282]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9deraKpkHjt"
      },
      "source": [
        "# annotate sample curpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "48ek7imWmgLv",
        "outputId": "a239ef57-61ae-4f3c-8076-66751ea8be80"
      },
      "source": [
        "trainDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>take your prescribed medicines every day, even when youâ€™re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4806</th>\n",
              "      <td>you should keep your blood pressure under control â€“ that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4810 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                text label\n",
              "0      Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.  FAKE\n",
              "1                                           Are those all choices 100%? Heart disease is a choice? Why not go furth   FAKE\n",
              "2                             How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n  FAKE\n",
              "3        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.  FAKE\n",
              "4              but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   FAKE\n",
              "...                                                                                                              ...   ...\n",
              "4805                                        take your prescribed medicines every day, even when youâ€™re feeling great  TRUE\n",
              "4806                               you should keep your blood pressure under control â€“ that is less than 130/80 mmHg  TRUE\n",
              "4807                                                     effects of alcohol consumption on heart health are variable  TRUE\n",
              "4808                         littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  TRUE\n",
              "4809           alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  TRUE\n",
              "\n",
              "[4810 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qv9VL2_sofz"
      },
      "source": [
        "sample_sent=[]\n",
        "for i in range(len(trainDF['text'])):\n",
        "    sentence = Sentence(trainDF['text'][i])\n",
        "    sample_sent.append(sentence)\n",
        "    \n",
        "sample_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qb6rJTSkS6z"
      },
      "source": [
        "sample_annotated=[]\n",
        "for i in range(len(trainDF['text'])):\n",
        "    classifier.predict(sample_sent[i])\n",
        "    sample_annotated.append(sample_sent[i].labels)\n",
        "\n",
        "sample_annotated\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "2-qG0wr9Iirq",
        "outputId": "667f57ca-d762-46a2-b063-2477f16e099f"
      },
      "source": [
        "trainDF['sample_annotated']=sample_annotated\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sample_annotated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.3262)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9945)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>take your prescribed medicines every day, even when youâ€™re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4806</th>\n",
              "      <td>you should keep your blood pressure under control â€“ that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4810 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                text  ... sample_annotated\n",
              "0      Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.  ...  [FAKE (0.9999)]\n",
              "1                                           Are those all choices 100%? Heart disease is a choice? Why not go furth   ...  [FAKE (0.3262)]\n",
              "2                             How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n  ...     [FAKE (1.0)]\n",
              "3        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.  ...  [FAKE (0.9945)]\n",
              "4              but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   ...  [FAKE (0.9999)]\n",
              "...                                                                                                              ...  ...              ...\n",
              "4805                                        take your prescribed medicines every day, even when youâ€™re feeling great  ...  [TRUE (0.9998)]\n",
              "4806                               you should keep your blood pressure under control â€“ that is less than 130/80 mmHg  ...     [TRUE (1.0)]\n",
              "4807                                                     effects of alcohol consumption on heart health are variable  ...  [TRUE (0.9998)]\n",
              "4808                         littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  ...  [TRUE (0.9999)]\n",
              "4809           alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  ...  [TRUE (0.9999)]\n",
              "\n",
              "[4810 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITnyvuYwRpg2",
        "outputId": "05c1eee1-4b17-4c12-97d0-fb8b873aaf46"
      },
      "source": [
        "    \n",
        "sample_sent[0].labels[0].to_dict()['value']\n",
        "sample_sent[0].labels[0].to_dict()['confidence']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999387264251709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "WOYBVv27TJcu",
        "outputId": "b6a596c4-ef87-4b56-e320-6b3c7ba7ee95"
      },
      "source": [
        "scory=[]\n",
        "labelnew=[]\n",
        "for i in range(len(trainDF['text'])):\n",
        "    scory.append(sample_sent[i].labels[0].to_dict()['confidence'])\n",
        "    labelnew.append(sample_sent[i].labels[0].to_dict()['value'])\n",
        "\n",
        "trainDF['labelnew']=labelnew\n",
        "trainDF['scory']=scory\n",
        "trainDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sample_annotated</th>\n",
              "      <th>labelnew</th>\n",
              "      <th>scory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Are those all choices 100%? Heart disease is a choice? Why not go furth</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.3262)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.326175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (1.0)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9945)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.994510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>[FAKE (0.9999)]</td>\n",
              "      <td>FAKE</td>\n",
              "      <td>0.999936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>take your prescribed medicines every day, even when youâ€™re feeling great</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4806</th>\n",
              "      <td>you should keep your blood pressure under control â€“ that is less than 130/80 mmHg</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (1.0)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>effects of alcohol consumption on heart health are variable</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9998)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>[TRUE (0.9999)]</td>\n",
              "      <td>TRUE</td>\n",
              "      <td>0.999857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4810 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                text  ...     scory\n",
              "0      Sustained effort, adequate thinking on the ice will go a long way.\\nIts not open heart surgery for Gods sake.  ...  0.999939\n",
              "1                                           Are those all choices 100%? Heart disease is a choice? Why not go furth   ...  0.326175\n",
              "2                             How about if she died of a heart attack from Pfizer?\\nPretty much the same risk...\\n\\n  ...  0.999960\n",
              "3        Brushing your teeth 3x per day [statistically] significantly reduces your risk of heart attack. \\nSo there.  ...  0.994510\n",
              "4              but hey, bo burnham. and his hands i had just had my heart surgery like a month before but i was SPR   ...  0.999936\n",
              "...                                                                                                              ...  ...       ...\n",
              "4805                                        take your prescribed medicines every day, even when youâ€™re feeling great  ...  0.999840\n",
              "4806                               you should keep your blood pressure under control â€“ that is less than 130/80 mmHg  ...  0.999965\n",
              "4807                                                     effects of alcohol consumption on heart health are variable  ...  0.999820\n",
              "4808                         littlee alcohol drinking reduces your risk of having a heart attack by about 25 percent  ...  0.999938\n",
              "4809           alcohol can increase your blood pressure, which can lead to problems such as stroke and heart failure  ...  0.999857\n",
              "\n",
              "[4810 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgs1AF6eXdJ_",
        "outputId": "449b17bd-2a74-4d95-f890-ea09cddebc7c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cm = confusion_matrix(trainDF['label'], trainDF['labelnew'])\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(trainDF['label'], trainDF['labelnew'])\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1709  606]\n",
            " [  53 2442]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.97      0.74      0.84      2315\n",
            "        TRUE       0.80      0.98      0.88      2495\n",
            "\n",
            "    accuracy                           0.86      4810\n",
            "   macro avg       0.89      0.86      0.86      4810\n",
            "weighted avg       0.88      0.86      0.86      4810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}